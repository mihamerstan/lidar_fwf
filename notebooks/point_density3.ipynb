{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from laspy.file import File\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0,'..') # So we can import point_density_functions from parent directory\n",
    "from point_density_functions import *\n",
    "%load_ext autoreload\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laefer\n",
    "file_dir = '../../Data/parking_lot/'\n",
    "filenames =list(pd.read_csv(file_dir+\"filenames.txt\",header=None)[0])\n",
    "pt_files = list(pd.read_csv(file_dir+\"pt_files.txt\",header=None)[0])\n",
    "# NYC\n",
    "nyc_file_dir = '../../Data/NYC_topo/'\n",
    "nyc_pt_file = ['las_points_NYC_flightid_975172.lz']\n",
    "# USGS\n",
    "usgs_file_dir = '../../Data/USGS/'\n",
    "usgs_pt_files = ['las_points_flight_id_18TWK820985.lz']\n",
    "\n",
    "\n",
    "# Corresponds to LAS 1.2 Point Data Record Format 1\n",
    "columns_dublin_pt_cloud = [\n",
    "    'X',\n",
    "    'Y',\n",
    "    'Z',\n",
    "    'intensity',\n",
    "    'return_number_byte',\n",
    "    'classification_byte',\n",
    "    'scan_angle',\n",
    "    'user_data',\n",
    "    'pt_src_id',\n",
    "    'gps_time']\n",
    "\n",
    "columns_point_cloud = [\n",
    "    'X','Y','Z',\n",
    "    'intensity',\n",
    "    'flag_byte',\n",
    "    'classification_flags',\n",
    "    'classification_byte',\n",
    "    'user_data',\n",
    "    'scan_angle',\n",
    "    'pt_src_id',\n",
    "    'gps_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works\n",
    "# for filename in filenames:\n",
    "#     create_df_hd5(file_dir,filename,columns_point_cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supporting Functions for Horizontal Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Big parking lot rectangle\n",
    "def rectangle(pt1,pt2,y_length,x_length):\n",
    "    '''\n",
    "    Function returns uv_inv and w, for use in selecting points within the rectangle\n",
    "    Note: This function only works in 2D (horizontal plane)\n",
    "    Inputs:\n",
    "    pt1 - 2x1 numpy array with x and y coordinate for bottom point\n",
    "    pt2 - 2xy numpy array with x and y coordinate for top point\n",
    "    y_length - bottom-to-top length (positive is in direction of top from bottom point)\n",
    "    x_length - left-to-right length (positive means pts are on left border, negative means they're on right)\n",
    "    Outputs:\n",
    "    uv_inv: 2xy numpy array - u and v are the sides of the rectangle.  uv = [u v] is a matrix with u and v as columns.\n",
    "    w: 2x1 numpy array with (x,y) coordinates of reference (bottom) point.\n",
    "    \n",
    "    Reference: https://math.stackexchange.com/questions/190111/how-to-check-if-a-point-is-inside-a-rectangle\n",
    "    '''\n",
    "    unit_u = (pt2 - pt1)/np.linalg.norm(pt2-pt1)\n",
    "    unit_v = np.array([unit_u[1],-1*unit_u[0]])\n",
    "    u = unit_u*y_length\n",
    "    v = unit_v*x_length\n",
    "    uv = np.array([u,v]).T\n",
    "    uv_inv = np.linalg.inv(uv)\n",
    "    w = pt1\n",
    "    return uv_inv,w,unit_u,unit_v\n",
    "\n",
    "# rectangle_points_laefer = grab_points_big_rect(pt_files,file_dir,uv_inv,w)\n",
    "# rectangle_points_nyc = grab_points_big_rect(nyc_pt_file,nyc_file_dir,uv_inv,w)\n",
    "# rectangle_points_usgs = grab_points_big_rect(usgs_pt_files,usgs_file_dir,uv_inv,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(SampleFlightList,pt_density_laefer_list,pt_density_nyc_list,pt_density_usgs_list,feet_from_point):\n",
    "    # Laefer\n",
    "    sd_laefer_total = np.mean([ss.flight_list_laefer[0].sd_dist for ss in SampleFlightList])\n",
    "    sd_laefer_sample = np.mean([ss.flight_list_laefer[1].sd_dist for ss in SampleFlightList])\n",
    "    avg_flight_paths_laefer = np.mean([len(flight.flight_list_laefer) for flight in SampleFlightList])-2\n",
    "\n",
    "    phis_laefer_total = [ss.phi_laefer_total for ss in SampleFlightList]\n",
    "    phis_laefer_sample = [ss.phi_laefer_sample for ss in SampleFlightList]\n",
    "\n",
    "    print(\"2019 scan (Horizontal, {} samples): \\n\".format(len(SampleFlightList))+\"*\"*30)\n",
    "    print(\"Avg points per square: {:2.2f} points\".format((4 * feet_from_point**2)*np.mean(pt_density_laefer_list)))\n",
    "    print(\"Avg density: {:2.4f} pts/sqft (SD: {:2.4f})\".format(np.mean(pt_density_laefer_list),np.std(pt_density_laefer_list)))\n",
    "    print(\"Avg number of flight paths per square: {:2.2f}\".format(avg_flight_paths_laefer))\n",
    "    print(\"\\nphi_total: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_laefer_total),np.std(phis_laefer_total)))\n",
    "    print(\"phi_sample: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_laefer_sample),np.std(phis_laefer_sample)))\n",
    "    print(\"Total point dist from plane, SD: {:2.4f} feet\".format(sd_laefer_total))\n",
    "    print(\"Avg flight point dist from plane, SD: {:2.4f} feet\".format(sd_laefer_total/np.mean(phis_laefer_total)))\n",
    "\n",
    "    # NYC\n",
    "    phis_nyc_total = [ss.phi_nyc_total for ss in SampleFlightList]\n",
    "    phis_nyc_sample = [ss.phi_nyc_sample for ss in SampleFlightList]\n",
    "    avg_flight_paths_nyc = np.mean([len(flight.flight_list_nyc) for flight in SampleFlightList])-2\n",
    "\n",
    "    sd_nyc_total = np.mean([ss.flight_list_nyc[0].sd_dist for ss in SampleFlightList])\n",
    "    sd_nyc_sample = np.mean([ss.flight_list_nyc[1].sd_dist for ss in SampleFlightList])\n",
    "\n",
    "    print(\"\\n2017 scan (Horizontal, {} samples): \\n\".format(len(SampleFlightList))+\"*\"*30)\n",
    "    print(\"Avg points per square: {:2.2f} points\".format((4 * feet_from_point**2)*np.mean(pt_density_nyc_list)))\n",
    "    print(\"Avg density: {:2.4f} pts/sqft (SD: {:2.4f})\".format(np.mean(pt_density_nyc_list),np.std(pt_density_nyc_list)))\n",
    "    print(\"Avg number of flight paths per square: {:2.2f}\".format(avg_flight_paths_nyc))\n",
    "    print(\"\\nphi_total: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_nyc_total),np.std(phis_nyc_total)))\n",
    "    print(\"phi_sample: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_nyc_sample),np.std(phis_nyc_sample)))\n",
    "    print(\"Total point dist from plane, SD: {:2.4f} feet\".format(sd_nyc_total))\n",
    "    print(\"Avg flight point dist from plane, SD: {:2.4f} feet\".format(sd_nyc_total/np.mean(phis_nyc_total)))\n",
    "\n",
    "    # USGS\n",
    "    phis_usgs_total = [ss.phi_usgs_total for ss in SampleFlightList]\n",
    "    phis_usgs_sample = [ss.phi_usgs_sample for ss in SampleFlightList]\n",
    "    avg_flight_paths_usgs = np.mean([len(flight.flight_list_usgs) for flight in SampleFlightList])-2\n",
    "\n",
    "    sd_usgs_total = np.mean([ss.flight_list_usgs[0].sd_dist for ss in SampleFlightList])\n",
    "    sd_usgs_sample = np.mean([ss.flight_list_usgs[1].sd_dist for ss in SampleFlightList])\n",
    "\n",
    "    print(\"\\n2014 scan (Horizontal, {} samples): \\n\".format(len(SampleFlightList))+\"*\"*30)\n",
    "    print(\"Avg points per square: {:2.2f} points\".format((4 * feet_from_point**2)*np.mean(pt_density_usgs_list)))\n",
    "    print(\"Avg density: {:2.4f} pts/sqft (SD: {:2.4f})\".format(np.mean(pt_density_usgs_list),np.std(pt_density_usgs_list)))\n",
    "    print(\"Avg number of flight paths per square: {:2.2f}\".format(avg_flight_paths_usgs))\n",
    "    print(\"\\nphi_total: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_usgs_total),np.std(phis_usgs_total)))\n",
    "    print(\"phi_sample: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_usgs_sample),np.std(phis_usgs_sample)))\n",
    "    print(\"Total point dist from plane, SD: {:2.4f} feet\".format(sd_usgs_total))\n",
    "    print(\"Avg flight point dist from plane, SD: {:2.4f} feet\".format(sd_usgs_total/np.mean(phis_usgs_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling squares and Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregators\n",
    "pt_density_usgs_list, pt_density_nyc_list, pt_density_laefer_list = [],[],[]\n",
    "avg_height_diff = []\n",
    "sd_height_usgs, sd_height_nyc, sd_height_laefer = [],[],[]\n",
    "SampleFlightList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_length:  502.99914453207924\n"
     ]
    }
   ],
   "source": [
    "# Water front parking lot\n",
    "pt1 = np.array([976534.92, 173979.05,0])\n",
    "pt2 = np.array([976863.17, 174360.18,0])\n",
    "u_length = np.linalg.norm(pt2-pt1)\n",
    "v_length = 80\n",
    "print(\"u_length: \",u_length)\n",
    "pt3 = np.array([976595.53720051, 173926.84315177,0]) # Backed into from previous 2D v calculation\n",
    "uv_inv,w,unit_u,unit_v = rectangle(pt1[:2],pt2[:2],500,80)\n",
    "\n",
    "rectangle_points_laefer = pd.read_pickle(file_dir+\"rectangle_points_laefer.pkl\")\n",
    "rectangle_points_nyc = pd.read_pickle(file_dir+\"rectangle_points_nyc.pkl\")\n",
    "rectangle_points_usgs = pd.read_pickle(usgs_file_dir+\"rectangle_points_usgs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/python-virtual-environments/data/lib/python3.6/site-packages/pandas/core/indexing.py:376: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/home/michael/python-virtual-environments/data/lib/python3.6/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "../point_density_functions.py:447: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "../point_density_functions.py:445: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "../point_density_functions.py:447: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in double_scalars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create center_points\n",
    "feet_from_point = 3.281/np.sqrt(2)\n",
    "center_points = center_point_sample(5000,pt1,pt2,pt3,u_length=u_length,v_length=v_length,border=[0.05,0.05])\n",
    "mean_z = rectangle_points_laefer['z_scaled'].mean()\n",
    "pts_thrown_out = 0\n",
    "\n",
    "for center_point in center_points:\n",
    "    square_points_usgs = in_horizontal_square(rectangle_points_usgs,center_point[:2],feet_from_point)\n",
    "    square_points_nyc = in_horizontal_square(rectangle_points_nyc,center_point[:2],feet_from_point)\n",
    "    square_points_laefer = in_horizontal_square(rectangle_points_laefer,center_point[:2],feet_from_point)\n",
    "    \n",
    "    laefer_flight_count = len(square_points_laefer['flight_id'].unique())\n",
    "    nyc_flight_count = len(square_points_nyc['flight_id'].unique())\n",
    "    usgs_flight_count = len(square_points_usgs['flight_id'].unique())\n",
    "   \n",
    "    laefer_density = square_points_laefer.shape[0] / laefer_flight_count\n",
    "    try:\n",
    "        nyc_density = square_points_nyc.shape[0]/nyc_flight_count\n",
    "    except ZeroDivisionError:\n",
    "        nyc_density = 0\n",
    "        \n",
    "    try:\n",
    "        usgs_density = square_points_usgs.shape[0] / usgs_flight_count\n",
    "    except ZeroDivisionError:\n",
    "        usgs_density = 0\n",
    " \n",
    "    # If z_max > 10, <6 for any dataset, skip it\n",
    "    if (square_points_nyc['z_scaled'].max()<mean_z+3) & \\\n",
    "       (square_points_usgs['z_scaled'].max()<mean_z+3) & \\\n",
    "       (square_points_laefer['z_scaled'].max()<mean_z+3):\n",
    "        # Statistics!\n",
    "                \n",
    "        # Point density\n",
    "        num_points_nyc = square_points_nyc.shape[0]\n",
    "        pt_density_nyc_list.append(num_points_nyc / (4 * feet_from_point**2))        \n",
    "        num_points_usgs = square_points_usgs.shape[0]\n",
    "        pt_density_usgs_list.append(num_points_usgs / (4 * feet_from_point**2))        \n",
    "        num_points_laefer = square_points_laefer.shape[0]\n",
    "        pt_density_laefer_list.append(num_points_laefer / (4 * feet_from_point**2))        \n",
    "        \n",
    "        # Flight path specifics\n",
    "        laefer_flight_list = create_flight_list(square_points_laefer)\n",
    "        usgs_flight_list = create_flight_list(square_points_usgs)\n",
    "        nyc_flight_list = create_flight_list(square_points_nyc)\n",
    "        # Create SampleSquare from all flight passes\n",
    "        ss = SampleSquare(laefer_flight_list, nyc_flight_list,usgs_flight_list, x = center_point[0], \\\n",
    "                          y=center_point[1],feet_from_point=feet_from_point)\n",
    "        # Collect SampleSquares\n",
    "        SampleFlightList.append(ss)\n",
    "        \n",
    "    else:\n",
    "        pts_thrown_out +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 scan (Horizontal, 3469 samples): \n",
      "******************************\n",
      "Avg points per square: 1044.82 points\n",
      "Avg density: 48.5289 pts/sqft (SD: 1.7484)\n",
      "Avg number of flight paths per square: 19.83\n",
      "\n",
      "phi_total: 1.2887 (SD: 0.1848)\n",
      "phi_sample: 1.2078 (SD: 0.3374)\n",
      "Total point dist from plane, SD: 0.0339 feet\n",
      "Avg flight point dist from plane, SD: 0.0263 feet\n",
      "\n",
      "2017 scan (Horizontal, 3469 samples): \n",
      "******************************\n",
      "Avg points per square: 24.41 points\n",
      "Avg density: 1.1336 pts/sqft (SD: 0.1194)\n",
      "Avg number of flight paths per square: 3.00\n",
      "\n",
      "phi_total: 1.2574 (SD: 0.1955)\n",
      "phi_sample: 0.9985 (SD: 0.3567)\n",
      "Total point dist from plane, SD: 0.0629 feet\n",
      "Avg flight point dist from plane, SD: 0.0500 feet\n",
      "\n",
      "2014 scan (Horizontal, 3469 samples): \n",
      "******************************\n",
      "Avg points per square: 14.40 points\n",
      "Avg density: 0.6688 pts/sqft (SD: 0.3552)\n",
      "Avg number of flight paths per square: 2.65\n",
      "\n",
      "phi_total: nan (SD: nan)\n",
      "phi_sample: nan (SD: nan)\n",
      "Total point dist from plane, SD: 0.1460 feet\n",
      "Avg flight point dist from plane, SD: nan feet\n"
     ]
    }
   ],
   "source": [
    "print_out(SampleFlightList,pt_density_laefer_list,pt_density_nyc_list,pt_density_usgs_list,feet_from_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back parking lot\n",
    "u_length = 200\n",
    "v_length = 40\n",
    "pt1 = np.array([977221.16,173403.09,0])\n",
    "pt2 = np.array([977345.97611538, 173559.36199794,0])\n",
    "uv_inv,w,unit_u,unit_v = rectangle(pt1[:2],pt2[:2],u_length,v_length)\n",
    "\n",
    "pt3 = np.concatenate((w + unit_v*v_length,np.zeros(1)))\n",
    "rectangle_points_laefer=pd.read_pickle(file_dir+\"rectangle_points_back_parking_laefer.pkl\")\n",
    "rectangle_points_nyc=pd.read_pickle(file_dir+\"rectangle_points_back_parking_nyc.pkl\")\n",
    "rectangle_points_usgs=pd.read_pickle(usgs_file_dir+\"rectangle_points_back_parking_usgs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/python-virtual-environments/data/lib/python3.6/site-packages/pandas/core/indexing.py:376: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/home/michael/python-virtual-environments/data/lib/python3.6/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create center_points\n",
    "feet_from_point = 3.281/np.sqrt(2)\n",
    "center_points = center_point_sample(5000,pt1,pt2,pt3,u_length=u_length,v_length=v_length,border=[0.05,0.05])\n",
    "mean_z = rectangle_points_laefer['z_scaled'].mean()\n",
    "pts_thrown_out = 0\n",
    "\n",
    "for center_point in center_points:\n",
    "    square_points_usgs = in_horizontal_square(rectangle_points_usgs,center_point[:2],feet_from_point)\n",
    "    square_points_nyc = in_horizontal_square(rectangle_points_nyc,center_point[:2],feet_from_point)\n",
    "    square_points_laefer = in_horizontal_square(rectangle_points_laefer,center_point[:2],feet_from_point)\n",
    "    \n",
    "    laefer_flight_count = len(square_points_laefer['flight_id'].unique())\n",
    "    nyc_flight_count = len(square_points_nyc['flight_id'].unique())\n",
    "    usgs_flight_count = len(square_points_usgs['flight_id'].unique())\n",
    "   \n",
    "    laefer_density = square_points_laefer.shape[0] / laefer_flight_count\n",
    "    try:\n",
    "        nyc_density = square_points_nyc.shape[0]/nyc_flight_count\n",
    "    except ZeroDivisionError:\n",
    "        nyc_density = 0\n",
    "    \n",
    "    try:\n",
    "        usgs_density = square_points_usgs.shape[0] / usgs_flight_count\n",
    "    except ZeroDivisionError:\n",
    "        usgs_density = 0\n",
    " \n",
    "    # If z_max > 10, <6 for any dataset, skip it\n",
    "    if (square_points_nyc['z_scaled'].max()<mean_z+3) & \\\n",
    "       (square_points_usgs['z_scaled'].max()<mean_z+3) & \\\n",
    "       (square_points_laefer['z_scaled'].max()<mean_z+3):\n",
    "        # Statistics!\n",
    "                \n",
    "        # Point density\n",
    "        num_points_nyc = square_points_nyc.shape[0]\n",
    "        pt_density_nyc_list.append(num_points_nyc / (4 * feet_from_point**2))        \n",
    "        num_points_usgs = square_points_usgs.shape[0]\n",
    "        pt_density_usgs_list.append(num_points_usgs / (4 * feet_from_point**2))        \n",
    "        num_points_laefer = square_points_laefer.shape[0]\n",
    "        pt_density_laefer_list.append(num_points_laefer / (4 * feet_from_point**2))        \n",
    "        \n",
    "        # Flight path specifics\n",
    "        laefer_flight_list = create_flight_list(square_points_laefer)\n",
    "        usgs_flight_list = create_flight_list(square_points_usgs)\n",
    "        nyc_flight_list = create_flight_list(square_points_nyc)\n",
    "        # Create SampleSquare from all flight passes\n",
    "        ss = SampleSquare(laefer_flight_list, nyc_flight_list,usgs_flight_list, x = center_point[0], \\\n",
    "                          y=center_point[1],feet_from_point=feet_from_point)\n",
    "        # Collect SampleSquares\n",
    "        SampleFlightList.append(ss)\n",
    "        \n",
    "    else:\n",
    "        pts_thrown_out +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 scan (Horizontal, 7970 samples): \n",
      "******************************\n",
      "Avg points per square: 1025.27 points\n",
      "Avg density: 47.6207 pts/sqft (SD: 2.1557)\n",
      "Avg number of flight paths per square: 19.78\n",
      "\n",
      "phi_total: 1.2272 (SD: 0.1656)\n",
      "phi_sample: 1.1586 (SD: 0.3210)\n",
      "Total point dist from plane, SD: 0.0314 feet\n",
      "Avg flight point dist from plane, SD: 0.0256 feet\n",
      "\n",
      "2017 scan (Horizontal, 7970 samples): \n",
      "******************************\n",
      "Avg points per square: 21.90 points\n",
      "Avg density: 1.0170 pts/sqft (SD: 0.2463)\n",
      "Avg number of flight paths per square: 3.00\n",
      "\n",
      "phi_total: 1.2220 (SD: 0.1847)\n",
      "phi_sample: 0.9148 (SD: 0.3600)\n",
      "Total point dist from plane, SD: 0.0518 feet\n",
      "Avg flight point dist from plane, SD: 0.0424 feet\n",
      "\n",
      "2014 scan (Horizontal, 7970 samples): \n",
      "******************************\n",
      "Avg points per square: 12.95 points\n",
      "Avg density: 0.6015 pts/sqft (SD: 0.2534)\n",
      "Avg number of flight paths per square: 2.83\n",
      "\n",
      "phi_total: nan (SD: nan)\n",
      "phi_sample: nan (SD: nan)\n",
      "Total point dist from plane, SD: 0.1295 feet\n",
      "Avg flight point dist from plane, SD: nan feet\n"
     ]
    }
   ],
   "source": [
    "print_out(SampleFlightList,pt_density_laefer_list,pt_density_nyc_list,pt_density_usgs_list,feet_from_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>laefer_C</th>\n",
       "      <th>laefer_W</th>\n",
       "      <th>laefer_rmse</th>\n",
       "      <th>nyc_C</th>\n",
       "      <th>nyc_W</th>\n",
       "      <th>nyc_rmse</th>\n",
       "      <th>usgs_C</th>\n",
       "      <th>usgs_W</th>\n",
       "      <th>usgs_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7970.000000</td>\n",
       "      <td>7970.000000</td>\n",
       "      <td>7970.000000</td>\n",
       "      <td>7970.000000</td>\n",
       "      <td>7970.000000</td>\n",
       "      <td>7970.000000</td>\n",
       "      <td>7970.000000</td>\n",
       "      <td>7970.000000</td>\n",
       "      <td>7970.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.008494</td>\n",
       "      <td>0.009563</td>\n",
       "      <td>0.007004</td>\n",
       "      <td>0.013778</td>\n",
       "      <td>0.015798</td>\n",
       "      <td>0.020280</td>\n",
       "      <td>0.032343</td>\n",
       "      <td>0.039460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004347</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>0.009336</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>0.013407</td>\n",
       "      <td>0.013960</td>\n",
       "      <td>0.011982</td>\n",
       "      <td>0.012894</td>\n",
       "      <td>0.014496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.004871</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.003188</td>\n",
       "      <td>0.006686</td>\n",
       "      <td>0.007676</td>\n",
       "      <td>0.004095</td>\n",
       "      <td>0.010545</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>0.025208</td>\n",
       "      <td>0.031547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.003924</td>\n",
       "      <td>0.007441</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>0.012130</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>0.018554</td>\n",
       "      <td>0.031178</td>\n",
       "      <td>0.037796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.008297</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>0.013990</td>\n",
       "      <td>0.016326</td>\n",
       "      <td>0.026525</td>\n",
       "      <td>0.037171</td>\n",
       "      <td>0.045013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.247841</td>\n",
       "      <td>0.212274</td>\n",
       "      <td>0.308197</td>\n",
       "      <td>0.098667</td>\n",
       "      <td>0.315029</td>\n",
       "      <td>0.315790</td>\n",
       "      <td>0.118160</td>\n",
       "      <td>0.241239</td>\n",
       "      <td>0.251262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          laefer_C     laefer_W  laefer_rmse        nyc_C        nyc_W  \\\n",
       "count  7970.000000  7970.000000  7970.000000  7970.000000  7970.000000   \n",
       "mean      0.004169     0.008494     0.009563     0.007004     0.013778   \n",
       "std       0.004347     0.008377     0.009336     0.005081     0.013407   \n",
       "min       0.001619     0.004871     0.005845     0.000057     0.003375   \n",
       "25%       0.003188     0.006686     0.007676     0.004095     0.010545   \n",
       "50%       0.003924     0.007441     0.008393     0.006185     0.012130   \n",
       "75%       0.004683     0.008297     0.009275     0.008870     0.013990   \n",
       "max       0.247841     0.212274     0.308197     0.098667     0.315029   \n",
       "\n",
       "          nyc_rmse       usgs_C       usgs_W    usgs_rmse  \n",
       "count  7970.000000  7970.000000  7970.000000  7970.000000  \n",
       "mean      0.015798     0.020280     0.032343     0.039460  \n",
       "std       0.013960     0.011982     0.012894     0.014496  \n",
       "min       0.004981     0.000000     0.000000     0.000000  \n",
       "25%       0.012002     0.011715     0.025208     0.031547  \n",
       "50%       0.013963     0.018554     0.031178     0.037796  \n",
       "75%       0.016326     0.026525     0.037171     0.045013  \n",
       "max       0.315790     0.118160     0.241239     0.251262  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw_df = pd.DataFrame([flight.error_decomp_laefer for flight in SampleFlightList],columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "cw_df['nyc_C'] = [flight.error_decomp_nyc[0] for flight in SampleFlightList]\n",
    "cw_df['nyc_W'] = [flight.error_decomp_nyc[1] for flight in SampleFlightList]\n",
    "cw_df['nyc_rmse'] = [flight.error_decomp_nyc[2] for flight in SampleFlightList]\n",
    "\n",
    "cw_df['usgs_C'] = [flight.error_decomp_usgs[0] for flight in SampleFlightList]\n",
    "cw_df['usgs_W'] = [flight.error_decomp_usgs[1] for flight in SampleFlightList]\n",
    "cw_df['usgs_rmse'] = [flight.error_decomp_usgs[2] for flight in SampleFlightList]\n",
    "\n",
    "(cw_df/3.28084).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164239: 0.0096\n",
      "164445: 0.0061\n",
      "164640: 0.0182\n",
      "164845: 0.0199\n",
      "165019: 0.0344\n",
      "172007: 0.0079\n",
      "172201: 0.0079\n",
      "172416: 0.0094\n",
      "172558: 0.0037\n",
      "172753: 0.0098\n",
      "180428: 0.0084\n",
      "180632: 0.0043\n",
      "180819: 0.0102\n",
      "181004: 0.0189\n",
      "181155: 0.0350\n",
      "195634: 0.0084\n",
      "195833: 0.0115\n",
      "200024: 0.0127\n",
      "200212: 0.0100\n",
      "200348: 0.0132\n",
      "200600: 0.0217\n",
      "172928: 0.0199\n",
      "164039: 0.0050\n",
      "200742: 0.0177\n",
      "195235: 0.0201\n",
      "163824: 0.0060\n",
      "171553: 0.0131\n",
      "171754: 0.0129\n",
      "175659: 0.0125\n",
      "175842: 0.0080\n",
      "180048: 0.0048\n",
      "180231: 0.0074\n",
      "163425: 0.0116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Distribution of flight passes')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Collect all heights by flight id\n",
    "from collections import defaultdict\n",
    "\n",
    "flight_id_dict = defaultdict(list)\n",
    "\n",
    "for sample_num in range(len(SampleFlightList)):\n",
    "    try:\n",
    "        dd = dict([(fp.flight_id,fp.h) for fp in SampleFlightList[sample_num].flight_list_laefer[2:]])\n",
    "        for key in dd.keys():\n",
    "            flight_id_dict[key].append(dd[key])\n",
    "    except AttributeError: \n",
    "        pass\n",
    "\n",
    "h_dist = []\n",
    "for key in flight_id_dict.keys():\n",
    "    mean_h = np.mean([abs(v) for v in flight_id_dict[key]])\n",
    "    h_dist.append(1000*mean_h)\n",
    "    print(\"{:2}: {:2.4f}\".format(key,mean_h))\n",
    "\n",
    "# Plot distribution of mean abs(heights)\n",
    "plt.hist(h_dist)\n",
    "plt.title(\"Dublin Horizontal Surfaces\",fontsize=12)\n",
    "plt.xlabel(\"Mean absolute height (mm)\",fontsize=12)\n",
    "plt.ylabel(\"Distribution of flight passes\",fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rmse = [ss.flight_list_laefer[0].square_dist \\\n",
    "/ss.flight_list_laefer[0].num_points for ss in SampleFlightList]\n",
    "np.sqrt(l_rmse).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df['laefer_rmse'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df['nyc_rmse'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Distance from plane\\n\"+\"*\"*30)\n",
    "print(\"2019: {:2.4f} (SD: {:2.4f})\".format(np.mean([ss.delta_h_mean_laefer for ss in SampleFlightList]),np.mean([ss.delta_h_sd_laefer for ss in SampleFlightList])))\n",
    "print(\"2017: {:2.4f} (SD: {:2.4f})\".format(np.mean([ss.delta_h_mean_nyc for ss in SampleFlightList]),np.mean([ss.delta_h_sd_nyc for ss in SampleFlightList])))\n",
    "print(\"2014: {:2.4f} (SD: {:2.4f})\".format(np.mean([ss.delta_h_mean_usgs for ss in SampleFlightList]),np.mean([ss.delta_h_sd_usgs for ss in SampleFlightList])))\n",
    "\n",
    "print(\"\\nCosine Similarity\\n\"+\"*\"*30)\n",
    "print(\"{:2.4f}\".format(np.mean([np.mean(ss.cosine_sim_matrix_laefer) for ss in SampleFlightList])))\n",
    "print(\"{:2.4f}\".format(np.mean([np.mean(ss.cosine_sim_matrix_nyc) for ss in SampleFlightList])))\n",
    "print(\"{:2.4f}\".format(np.mean([np.mean(ss.cosine_sim_matrix_usgs) for ss in SampleFlightList])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Parking lot in between army terminal buildings\n",
    "# u_length = 200\n",
    "# v_length = 40\n",
    "# pt1 = np.array([976975.96, 173882.3,0])\n",
    "# pt2 = np.array([977107.27980512, 174033.14796579,0])\n",
    "# uv_inv,w,unit_u,unit_v = rectangle(pt1[:2],pt2[:2],u_length,v_length)\n",
    "\n",
    "# pt3 = np.concatenate((w + unit_v*v_length,np.zeros(1)))\n",
    "\n",
    "# rectangle_points_laefer = pd.read_pickle(file_dir+\"rectangle_points_middle_parking_laefer.pkl\")\n",
    "# rectangle_points_nyc = pd.read_pickle(file_dir+\"rectangle_points_middle_parking_nyc.pkl\")\n",
    "# rectangle_points_usgs = pd.read_pickle(usgs_file_dir+\"rectangle_points_middle_parking_usgs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical density\n",
    "Identifying point at corner of building to quantify the vertical point density.  \n",
    "Center point: \t40.645854, \t-74.025299  \n",
    "Easting - 977229.375  \n",
    "Northing - 174579.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Southern wall of Army Terminal Bldg\n",
    "# middle_pt = np.array([976617.27,173802.86,58])\n",
    "# Extract from all files, the points within feet_from_pt in the xy-plane of the middle wall point\n",
    "# square_points_vertical_laefer = grab_points(pt_files,file_dir,middle_pt[0],middle_pt[1],9)\n",
    "# square_points_vertical_nyc = grab_points(nyc_pt_file,nyc_file_dir,middle_pt[0],middle_pt[1],9)\n",
    "# square_points_vertical_usgs = grab_points(usgs_pt_files,usgs_file_dir,middle_pt[0],middle_pt[1],9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vert_density(square_points_list, \n",
    "                 middle_pt, \n",
    "                 right_pt, \n",
    "                 left_pt, \n",
    "                 bottom_left_pt, \n",
    "                 feet_from_pt,\n",
    "                 SampleFlightList=[],\n",
    "                 pt_density_list=[[],[],[]],\n",
    "                 sd_wall_list=[[],[],[]],\n",
    "                 wall_face_list=None\n",
    "                 ):\n",
    "    # Unzip the list\n",
    "    square_points_laefer,square_points_nyc,square_points_usgs = \\\n",
    "    square_points_list[0],square_points_list[1],square_points_list[2]\n",
    "    \n",
    "    pt_density_laefer_list,pt_density_nyc_list,pt_density_usgs_list = \\\n",
    "    pt_density_list[0],pt_density_list[1],pt_density_list[2]\n",
    "    \n",
    "    sd_wall_dist_laefer,sd_wall_dist_nyc,sd_wall_dist_usgs = \\\n",
    "    sd_wall_list[0],sd_wall_list[1],sd_wall_list[2] \n",
    "    # Create aggregators if not provided\n",
    "    \n",
    "    \n",
    "    # Calculate norm_vector from 3 points, to define plane and extract the wall face\n",
    "    norm = np.cross(middle_pt - right_pt,(left_pt-right_pt))\n",
    "    norm = norm / np.linalg.norm(norm)\n",
    "\n",
    "    # Extract the wall face, above 15ft and below 120ft to avoid roof and grouund points\n",
    "    wall_face_laefer = grab_wall_face(square_points_laefer,norm, middle_pt,15,110,5e-1)\n",
    "    wall_face_nyc = grab_wall_face(square_points_nyc,norm, middle_pt,15,110,5e-1)\n",
    "    wall_face_usgs = grab_wall_face(square_points_usgs,norm, middle_pt,15,110,5e-1)\n",
    "\n",
    "    # Fit a plane, create norm_vector, calculate dist_from_plane\n",
    "    norm_vector_laefer,_,wall_face_laefer,_ = plane_fit(wall_face_laefer) \n",
    "    norm_vector_nyc,_,wall_face_nyc,_ = plane_fit(wall_face_nyc) \n",
    "    norm_vector_usgs,_,wall_face_usgs,_ = plane_fit(wall_face_usgs) \n",
    "    \n",
    "    # Calculate the rectangle side length, based on points\n",
    "    u_length = np.linalg.norm(bottom_left_pt-top_left_pt)\n",
    "    v_length = np.linalg.norm(bottom_left_pt-bottom_right_pt)\n",
    "    print(\"u_length: {:2.2f}m\".format(u_length/3.28084))\n",
    "    print(\"v_length: {:2.2f}m\".format(v_length/3.28084))\n",
    "\n",
    "    # Sample points in wall\n",
    "    #Note 0.28 border_v comes from: (3.5/2) (half-meter feet_from_point) / v_length (with some buffer)\n",
    "    feet_from_pt_v = 3.5\n",
    "    feet_from_pt_u = 3.5\n",
    "    border = [0,0]\n",
    "    border[0] = 1.08*(feet_from_pt_u / u_length)\n",
    "    border[1] = 1.08*(feet_from_pt_v / v_length)\n",
    "    # For density up the wall below\n",
    "    try:\n",
    "        center_points_old = center_points\n",
    "    except:\n",
    "        pass\n",
    "    center_points = center_point_sample(2500,\n",
    "                        bottom_left_pt,top_left_pt,bottom_right_pt,\n",
    "                        u_length=u_length,v_length=v_length,border=border)\n",
    "    \n",
    "    # Main Loop through the sample points\n",
    "    pts_thrown_out = 0\n",
    "\n",
    "    for center_point in center_points:\n",
    "        square_points_usgs,pt_density_usgs = in_vertical_square(wall_face_usgs,\n",
    "                                                    norm_vector_usgs,\n",
    "                                                    center_point,\n",
    "                                                    feet_from_pt_v,\n",
    "                                                    feet_from_pt_u)\n",
    "        square_points_nyc,pt_density_nyc = in_vertical_square(wall_face_nyc,\n",
    "                                                    norm_vector_nyc,\n",
    "                                                    center_point,\n",
    "                                                    feet_from_pt_v,\n",
    "                                                    feet_from_pt_u)\n",
    "        square_points_laefer,pt_density_laefer = in_vertical_square(wall_face_laefer,\n",
    "                                                    norm_vector_laefer,\n",
    "                                                    center_point,\n",
    "                                                    feet_from_pt_v,\n",
    "                                                    feet_from_pt_u)\n",
    "        laefer_flight_count = len(square_points_laefer['flight_id'].unique())\n",
    "        nyc_flight_count = len(square_points_nyc['flight_id'].unique())\n",
    "        usgs_flight_count = len(square_points_usgs['flight_id'].unique())\n",
    "\n",
    "        # Statistics!\n",
    "\n",
    "        # Point density\n",
    "        num_points_laefer = square_points_laefer.shape[0]\n",
    "        pt_density_laefer_list.append(pt_density_laefer)        \n",
    "        num_points_usgs = square_points_usgs.shape[0]\n",
    "        pt_density_usgs_list.append(pt_density_usgs)        \n",
    "        num_points_nyc = square_points_nyc.shape[0]\n",
    "        pt_density_nyc_list.append(pt_density_nyc)        \n",
    "        \n",
    "\n",
    "        # Fit a plane\n",
    "        if square_points_laefer.shape[0] > 0:\n",
    "            norm_vector_laefer,_,square_points_laefer,_ = plane_fit(square_points_laefer)\n",
    "            laefer_flight_list = create_flight_list(square_points_laefer)\n",
    "        else:\n",
    "            laefer_flight_list=None\n",
    "\n",
    "        if square_points_nyc.shape[0] > 0:\n",
    "            norm_vector_nyc,_,square_points_nyc,_ = plane_fit(square_points_nyc)\n",
    "            nyc_flight_list = create_flight_list(square_points_nyc)\n",
    "        else:\n",
    "            nyc_flight_list=None\n",
    "\n",
    "        if square_points_usgs.shape[0] > 0:\n",
    "            norm_vector_usgs,_,square_points_usgs,_ = plane_fit(square_points_usgs)\n",
    "            usgs_flight_list = create_flight_list(square_points_usgs)\n",
    "        else:\n",
    "            usgs_flight_list=None\n",
    "        # Flight path specifics\n",
    "        ss = SampleSquare(laefer_flight_list, nyc_flight_list,usgs_flight_list, x = center_point[0], \\\n",
    "                          y=center_point[1],z=center_point[2],feet_from_point=[feet_from_pt_v,feet_from_pt_u])\n",
    "        SampleFlightList.append(ss)    \n",
    "    \n",
    "    # Print outs\n",
    "    print(\"Pts in Laefer: {}\".format(wall_face_laefer.shape[0]))\n",
    "    print(\"Pts in NYC: {}\".format(wall_face_nyc.shape[0]))\n",
    "    print(\"Pts in USGS: {}\".format(wall_face_usgs.shape[0]))\n",
    "\n",
    "    print(\"Vertical face point density over {:d} samples\".format(len(pt_density_laefer_list)))\n",
    "    print(\"*\"*30)\n",
    "    print(\"USGS avg density: {:2.4f} (SD: {:2.4f})\".format(np.mean(pt_density_usgs_list),np.std(pt_density_usgs_list)))\n",
    "    print(\"NYC avg density: {:2.4f} (SD: {:2.4f})\".format(np.mean(pt_density_nyc_list),np.std(pt_density_nyc_list)))\n",
    "    print(\"Laefer avg density: {:2.4f} (SD: {:2.4f})\".format(np.mean(pt_density_laefer_list),np.std(pt_density_laefer_list)))\n",
    "    \n",
    "    # Output\n",
    "    wall_face_list = [wall_face_laefer,wall_face_nyc,wall_face_usgs]\n",
    "    pt_density_list = [pt_density_laefer_list,pt_density_nyc_list,pt_density_usgs_list]\n",
    "    sd_wall_list = [sd_wall_dist_laefer,sd_wall_dist_nyc,sd_wall_dist_usgs]\n",
    "    \n",
    "    return SampleFlightList, wall_face_list, pt_density_list, sd_wall_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregators\n",
    "pt_density_list= [[],[],[]]\n",
    "sd_wall_list=[[],[],[]]\n",
    "SampleFlightList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other side of the windows\n",
    "middle_pt = np.array([977214.86,174562.64,58.762])\n",
    "right_pt = np.array([977213.577,174561.01,111.614])\n",
    "left_pt = np.array([977217.294, 174565.64, 33.483])\n",
    "bottom_left_pt= np.array([977217.09,174565.64,25.809])\n",
    "top_left_pt = np.array([977217.09,174565.64,115.80])\n",
    "bottom_right_pt = np.array([977213.026,174560.064,25.809])\n",
    "feet_from_pt = 3.5\n",
    "\n",
    "# Right vertical wall\n",
    "square_points_vertical_laefer = pd.read_pickle(\"../../Data/parking_lot/right_wall_vertical_laefer.pkl\")\n",
    "square_points_vertical_nyc = pd.read_pickle(\"../../Data/parking_lot/right_wall_vertical_nyc.pkl\")\n",
    "square_points_vertical_usgs = pd.read_pickle(\"../../Data/parking_lot/right_wall_vertical_usgs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "square_points_list = [square_points_vertical_laefer,square_points_vertical_nyc,square_points_vertical_usgs]\n",
    "SampleFlightList, wall_face_list, pt_density_list, sd_wall_list = \\\n",
    "vert_density(square_points_list, \n",
    "                 middle_pt, \n",
    "                 right_pt, \n",
    "                 left_pt, \n",
    "                 bottom_left_pt, \n",
    "                 feet_from_pt,\n",
    "                 SampleFlightList,    \n",
    "                 pt_density_list,\n",
    "                 sd_wall_list\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wall_face_nyc = wall_face_list[2]\n",
    "flight_ids = wall_face_nyc['flight_id'].unique()\n",
    "wall_face_nyc['pts_bins'] = pd.cut((wall_face_nyc['z_scaled']-9)/3.28084, \\\n",
    "                                      bins=range(0,40,3), \\\n",
    "                                      labels=range(3,40,3))\n",
    "\n",
    "for f in flight_ids:\n",
    "    flight_pts = wall_face_nyc[wall_face_nyc['flight_id']==f]\n",
    "    # Num of points\n",
    "    print(\"\\n\\nDensity for flight id {}:\".format(f),flight_pts.groupby('pts_bins')['X'].count()/(3*2.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer wall (B)\n",
    "middle_pt = np.array([977223.71,174573.7,75.141])\n",
    "right_pt = np.array([977221.44, 174571.037, 68.44])\n",
    "left_pt = np.array([977226.47, 174577.23, 36.958])\n",
    "bottom_left_pt = np.array([977225.752, 174576.37, 25.393])\n",
    "top_left_pt = np.array([977225.752, 174576.37, 117.937])\n",
    "bottom_right_pt = np.array([977221.605,174571.074,25.393])\n",
    "feet_from_pt = 3.5\n",
    "\n",
    "# Left vertical wall\n",
    "square_points_vertical_laefer = pd.read_pickle(\"../../Data/parking_lot/left_wall_vertical_laefer.pkl\")\n",
    "square_points_vertical_nyc = pd.read_pickle(\"../../Data/parking_lot/left_wall_vertical_nyc.pkl\")\n",
    "square_points_vertical_usgs = pd.read_pickle(\"../../Data/parking_lot/left_wall_vertical_usgs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "square_points_list = [square_points_vertical_laefer,square_points_vertical_nyc,square_points_vertical_usgs]\n",
    "SampleFlightList, wall_face_list, pt_density_list, sd_wall_list = \\\n",
    "vert_density(square_points_list, \n",
    "                 middle_pt, \n",
    "                 right_pt, \n",
    "                 left_pt, \n",
    "                 bottom_left_pt, \n",
    "                 feet_from_pt,\n",
    "                 SampleFlightList,  \n",
    "                 pt_density_list,\n",
    "                 sd_wall_list\n",
    "                 )\n",
    "\n",
    "# # Append wall_face to wall_face_laefer_total\n",
    "# wall_face_laefer_total = wall_face_laefer_total.append(wall_face_list[0])\n",
    "# wall_face_laefer_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_face_nyc = wall_face_list[2]\n",
    "flight_ids = wall_face_nyc['flight_id'].unique()\n",
    "wall_face_nyc['pts_bins'] = pd.cut((wall_face_nyc['z_scaled']-9)/3.28084, \\\n",
    "                                      bins=range(0,40,3), \\\n",
    "                                      labels=range(3,40,3))\n",
    "\n",
    "for f in flight_ids:\n",
    "    flight_pts = wall_face_nyc[wall_face_nyc['flight_id']==f]\n",
    "    # Num of points\n",
    "    print(\"\\n\\nDensity for flight id {}:\".format(f),flight_pts.groupby('pts_bins')['X'].count()/(3*2.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wall at other end of Army Terminal Bldg (C)\n",
    "middle_pt = np.array([976665.066,173867.613,75.54])\n",
    "right_pt = np.array([976663.22,173865.13,28.945])\n",
    "left_pt = np.array([976666.636,173869.511,54.121])\n",
    "bottom_left_pt= np.array([976665.002991,173867.726,13.903])\n",
    "top_left_pt = np.array([976665.002991,173867.726,110.903])\n",
    "bottom_right_pt = np.array([976662.514,173864.906,15.875])\n",
    "\n",
    "feet_from_pt = 3.5\n",
    "\n",
    "square_points_vertical_laefer = pd.read_pickle(\"../../Data/parking_lot/wall_c_laefer.pkl\")\n",
    "square_points_vertical_nyc = pd.read_pickle(\"../../Data/parking_lot/wall_c_nyc.pkl\")\n",
    "square_points_vertical_usgs = pd.read_pickle(\"../../Data/parking_lot/wall_c_usgs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_points_list = [square_points_vertical_laefer,square_points_vertical_nyc,square_points_vertical_usgs]\n",
    "SampleFlightList, wall_face_list, pt_density_list, sd_wall_list = \\\n",
    "vert_density(square_points_list, \n",
    "                 middle_pt, \n",
    "                 right_pt, \n",
    "                 left_pt, \n",
    "                 bottom_left_pt, \n",
    "                 feet_from_pt,\n",
    "                 SampleFlightList,      \n",
    "                 pt_density_list,\n",
    "                 sd_wall_list\n",
    "                 )\n",
    "# # Append wall_face to wall_face_laefer_total\n",
    "# wall_face_laefer_total = wall_face_laefer_total.append(wall_face_list[0])\n",
    "# wall_face_laefer_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_face_nyc = wall_face_list[2]\n",
    "flight_ids = wall_face_nyc['flight_id'].unique()\n",
    "wall_face_nyc['pts_bins'] = pd.cut((wall_face_nyc['z_scaled']-9)/3.28084, \\\n",
    "                                      bins=range(0,40,3), \\\n",
    "                                      labels=range(3,40,3))\n",
    "\n",
    "for f in flight_ids:\n",
    "    flight_pts = wall_face_nyc[wall_face_nyc['flight_id']==f]\n",
    "    # Num of points\n",
    "    print(\"\\n\\nDensity for flight id {}:\".format(f),flight_pts.groupby('pts_bins')['X'].count()/(3*1.29))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wall in middle of Army Terminal Bldg (D)\n",
    "middle_pt = np.array([976763.544,173992.004,23.858])\n",
    "right_pt = np.array([976762.356,173990.422,101.224])\n",
    "left_pt = np.array([976765.87,173994.878,87.094])\n",
    "bottom_left_pt= np.array([976765.87,173994.878,13.9])\n",
    "top_left_pt = np.array([976765.87,173994.878,110.9])\n",
    "bottom_right_pt = np.array([976762.356,173990.422,13.9])\n",
    "\n",
    "feet_from_pt = 3.5/2\n",
    "\n",
    "square_points_vertical_laefer = pd.read_pickle(\"../../Data/parking_lot/wall_d_laefer.pkl\")\n",
    "square_points_vertical_nyc = pd.read_pickle(\"../../Data/parking_lot/wall_d_nyc.pkl\")\n",
    "square_points_vertical_usgs = pd.read_pickle(\"../../Data/parking_lot/wall_d_usgs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_points_list = [square_points_vertical_laefer,square_points_vertical_nyc,square_points_vertical_usgs]\n",
    "SampleFlightList, wall_face_list, pt_density_list, sd_wall_list = \\\n",
    "vert_density(square_points_list, \n",
    "                 middle_pt, \n",
    "                 right_pt, \n",
    "                 left_pt, \n",
    "                 bottom_left_pt, \n",
    "                 feet_from_pt,\n",
    "                 SampleFlightList,  \n",
    "                 pt_density_list,\n",
    "                 sd_wall_list\n",
    "                 )\n",
    "# # Append wall_face to wall_face_laefer_total\n",
    "# wall_face_laefer_total = wall_face_laefer_total.append(wall_face_list[0])\n",
    "# wall_face_laefer_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_face_nyc = wall_face_list[2]\n",
    "flight_ids = wall_face_nyc['flight_id'].unique()\n",
    "wall_face_nyc['pts_bins'] = pd.cut((wall_face_nyc['z_scaled']-9)/3.28084, \\\n",
    "                                      bins=range(0,40,3), \\\n",
    "                                      labels=range(3,40,3))\n",
    "\n",
    "for f in flight_ids:\n",
    "    flight_pts = wall_face_nyc[wall_face_nyc['flight_id']==f]\n",
    "    # Num of points\n",
    "    print(\"\\n\\nDensity for flight id {}:\".format(f),flight_pts.groupby('pts_bins')['X'].count()/(3*1.73))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # South wall!  For vertical density of NYC\n",
    "# middle_pt = np.array([976617.27,173802.86,58])\n",
    "# right_pt = np.array([976620.67,173800.14,50])\n",
    "# left_pt = np.array([976615.24,173804.53,62])\n",
    "# bottom_left_pt = np.array([976615.24,173804.53,21.98])\n",
    "# top_left_pt = np.array([976615.24,173804.53,115])\n",
    "# bottom_right_pt = np.array([976620.67,173800.14,21.98])\n",
    "# feet_from_pt = 3.5/2\n",
    "\n",
    "# square_points_vertical_laefer = pd.read_pickle(\"../../Data/parking_lot/south_outer_wall_vertical_laefer.pkl\")\n",
    "# square_points_vertical_nyc = pd.read_pickle(\"../../Data/parking_lot/south_outer_wall_vertical_nyc.pkl\")\n",
    "# square_points_vertical_usgs = pd.read_pickle(\"../../Data/parking_lot/south_outer_wall_vertical_usgs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square_points_list = [square_points_vertical_laefer,square_points_vertical_nyc,square_points_vertical_usgs]\n",
    "# SampleFlightList, wall_face_list, pt_density_list, sd_wall_list = \\\n",
    "# vert_density(square_points_list, \n",
    "#                  middle_pt, \n",
    "#                  right_pt, \n",
    "#                  left_pt, \n",
    "#                  bottom_left_pt, \n",
    "#                  feet_from_pt,\n",
    "#                  SampleFlightList,  \n",
    "#                  pt_density_list,\n",
    "#                  sd_wall_list\n",
    "#                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wall density for NYC flight pass\n",
    "wall_face_nyc = wall_face_list[1]\n",
    "flight_ids = ['181004','180819']\n",
    "wall_face_nyc['pts_bins'] = pd.cut((wall_face_nyc['z_scaled']-9)/3.28084, \\\n",
    "                                      bins=range(0,40,3), \\\n",
    "                                      labels=range(3,40,3))\n",
    "\n",
    "for f in wall_face_nyc['flight_id'].unique():\n",
    "    flight_pts = wall_face_nyc[wall_face_nyc['flight_id']==f]\n",
    "    # Num of points\n",
    "    print(\"\\n\\nDensity for flight id {}:\".format(f),flight_pts.groupby('pts_bins')['X'].count()/(3*2.13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wall_face_nyc = wall_face_list[1]\n",
    "plt.plot(wall_face_list[0]['x_scaled'],wall_face_list[0]['z_scaled'],'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_flight_paths_laefer = []\n",
    "for flight in SampleFlightList:\n",
    "    try:\n",
    "        avg_flight_paths_laefer.append(len(flight.flight_list_laefer)-2)\n",
    "    except AttributeError:\n",
    "        avg_flight_paths_laefer.append(0)\n",
    "\n",
    "print(\"Avg number of flight paths per square: {:2.2f}\".format(np.mean(avg_flight_paths_laefer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cw = []\n",
    "for flight in SampleFlightList:\n",
    "    try:\n",
    "        cw.append(flight.error_decomp_laefer)\n",
    "    except AttributeError:\n",
    "        print(\"Missing\")\n",
    "#     cw_df = pd.DataFrame(cw,columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "    cw_df = pd.DataFrame(cw,columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "\n",
    "(cw_df/3.28084).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all heights by flight id\n",
    "from collections import defaultdict\n",
    "\n",
    "flight_id_dict = defaultdict(list)\n",
    "\n",
    "for sample_num in range(len(SampleFlightList)):\n",
    "    try:\n",
    "        dd = dict([(fp.flight_id,fp.h) for fp in SampleFlightList[sample_num].flight_list_laefer[2:]])\n",
    "        for key in dd.keys():\n",
    "            flight_id_dict[key].append(dd[key])\n",
    "    except AttributeError: \n",
    "        pass\n",
    "\n",
    "h_dist = []\n",
    "for key in flight_id_dict.keys():\n",
    "    mean_h = np.mean([abs(v) for v in flight_id_dict[key]])\n",
    "    h_dist.append(1000*mean_h)\n",
    "    print(\"{:2}: {:2.4f}\".format(key,mean_h))\n",
    "\n",
    "# Plot distribution of mean abs(heights)\n",
    "plt.hist(h_dist)\n",
    "plt.title(\"Dublin Horizontal Surfaces\",fontsize=12)\n",
    "plt.xlabel(\"Mean absolute height (mm)\",fontsize=12)\n",
    "plt.ylabel(\"Distribution of flight passes\",fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df2 = pd.read_pickle(\"../../accuracy_data/vertical_cw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cw_df2).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laefer\n",
    "sd_laefer_total = np.mean([ss.flight_list_laefer[0].sd_dist for ss in SampleFlightList])\n",
    "sd_laefer_sample = np.mean([ss.flight_list_laefer[1].sd_dist for ss in SampleFlightList])\n",
    "avg_flight_paths_laefer = np.mean([len(flight.flight_list_laefer) for flight in SampleFlightList])-2\n",
    "\n",
    "phis_laefer_total = [ss.phi_laefer_total for ss in SampleFlightList]\n",
    "phis_laefer_sample = [ss.phi_laefer_sample for ss in SampleFlightList]\n",
    "\n",
    "print(\"2019 scan (Vertical, {:d} samples)\\n\".format(len(pt_density_laefer_list))+\"*\"*30)\n",
    "print(\"Avg points per square: {:2.2f} points\".format((3.5*14)*np.mean(pt_density_laefer_list)))\n",
    "print(\"Avg density: {:2.4f} pts/sqft (SD: {:2.4f})\".format(np.mean(pt_density_laefer_list),np.std(pt_density_laefer_list)))\n",
    "print(\"Avg number of flight paths per square: {:2.2f}\".format(avg_flight_paths_laefer))\n",
    "\n",
    "print(\"\\nphi_total: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_laefer_total),np.std(phis_laefer_total)))\n",
    "print(\"phi_sample: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_laefer_sample),np.std(phis_laefer_total)))\n",
    "print(\"\\nTotal point dist from plane, SD: {:2.4f} feet\".format(sd_laefer_total))\n",
    "print(\"Avg flight point dist from plane, SD: {:2.4f} feet\".format(sd_laefer_total/np.mean(phis_laefer_total)))\n",
    "\n",
    "# phis_nyc_total = [ss.phi_nyc_total for ss in SampleFlightList]\n",
    "# phis_nyc_sample = [ss.phi_nyc_sample for ss in SampleFlightList]\n",
    "\n",
    "# sd_nyc_total = np.mean([ss.flight_list_nyc[0].sd_dist for ss in SampleFlightList])\n",
    "# sd_nyc_sample = np.mean([ss.flight_list_nyc[1].sd_dist for ss in SampleFlightList])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(SampleFlightList[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass_count = []\n",
    "# for flight in SampleFlightList:\n",
    "#     try:\n",
    "#         pass_count.append(len(flight.flight_list_nyc)-2)\n",
    "#     except AttributeError:\n",
    "#         pass_count.append(0)\n",
    "# print(\"NYC Mean Flight passes: {:2.4f}\".format(np.mean(pass_count)))\n",
    "# pass_arr = np.array(pass_count)\n",
    "# print(\"Mean Non-Zero Flight passes: {:2.4f}\".format(np.mean(pass_arr[pass_arr>0])))\n",
    "\n",
    "\n",
    "# pass_count = []\n",
    "# for flight in SampleFlightList:\n",
    "#     try:\n",
    "#         pass_count.append(len(flight.flight_list_usgs)-2)\n",
    "#     except AttributeError:\n",
    "#         pass_count.append(0)\n",
    "\n",
    "# print(\"USGS Mean Flight passes: {:2.4f}\".format(np.mean(pass_count)))\n",
    "# pass_arr = np.array(pass_count)\n",
    "# print(\"Mean Non-Zero Flight passes: {:2.4f}\".format(np.mean(pass_arr[pass_arr>0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing points by scan angle\n",
    "\n",
    "Count the missing scan points based on scan angle between consecutive points.  Goal is to 1) compare the % of missing points for horizontal vs vertical surfaces, and 2) compare the % of missing points at different wall heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_face_list[0].to_pickle(\"../../Data/parking_lot/wall_points_laefer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pull_first_scan_gap(wall_face_laefer):\n",
    "    # Separate return num, only keep the first returns, add scan_gap, sort\n",
    "    wall_face_laefer['num_returns'] = np.floor(wall_face_laefer['flag_byte']/16).astype(int)\n",
    "    wall_face_laefer['return_num'] = wall_face_laefer['flag_byte']%16\n",
    "    first_return_wall = wall_face_laefer[wall_face_laefer['return_num']==1]\n",
    "    first_return_wall.sort_values(by=['gps_time'],inplace=True)\n",
    "    first_return_wall.reset_index(inplace=True)\n",
    "    first_return_wall.loc[1:,'scan_gap'] = [first_return_wall.loc[i+1,'scan_angle'] - first_return_wall.loc[i,'scan_angle'] for i in range(first_return_wall.shape[0]-1)]\n",
    "    first_return_wall.loc[0,'scan_gap'] = 0\n",
    "    return first_return_wall\n",
    "\n",
    "# Wall\n",
    "wall_face_laefer = wall_face_list[0]\n",
    "first_return_wall = pull_first_scan_gap(wall_face_laefer)\n",
    "# Rectangle\n",
    "rectangle_face_laefer = pd.read_pickle(file_dir+\"rectangle_points_laefer.pkl\")\n",
    "first_return_rectangle = pull_first_scan_gap(rectangle_face_laefer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan gap of -4,-5,-6 is normal, -10,-11,-15 are a missed point\n",
    "w = pd.DataFrame(first_return_rectangle['scan_gap'].value_counts())\n",
    "w.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan gap of -4,-5,-6 is normal, -10,-11,-15 are a missed point\n",
    "w = pd.DataFrame(first_return_wall[first_return_wall['flight_id']=='180819']['scan_gap'].value_counts())\n",
    "w.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the wall height into bins, compare % missing points at different heights\n",
    "\n",
    "first_return_wall['pts_bins'] = pd.cut((first_return_wall['z_scaled']-9)/3.28084, \\\n",
    "                                       bins=range(0,40,3),labels=range(3,40,3))\n",
    "\n",
    "first_return_wall['missed_point'] = np.zeros(first_return_wall.shape[0])\n",
    "first_return_wall['good_point'] = np.zeros(first_return_wall.shape[0])\n",
    "for index, row in first_return_wall.iterrows():\n",
    "    if (row['scan_gap'] >-17) & (row['scan_gap']< -6):\n",
    "        first_return_wall.loc[index,'missed_point']=1\n",
    "    if (row['scan_gap'] <-1) & (row['scan_gap'] > -7):\n",
    "        first_return_wall.loc[index,'good_point']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_return_wall[first_return_wall['z_scaled']<18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = first_return_wall[first_return_wall['flight_id']=='181004'].groupby('pts_bins').mean()\n",
    "a = first_return_wall.groupby('pts_bins').mean()\n",
    "\n",
    "a['miss_pct'] = a['missed_point']/a['good_point']\n",
    "a['miss_pct'][:-2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['miss_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(list(a['miss_pct'][:-2]),list(a['miss_pct'][:-2].index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intensity up and down the wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wall_face_laefer = wall_face_list[0]\n",
    "flight_ids = ['181004','180819']\n",
    "wall_face_laefer['pts_bins'] = pd.cut((wall_face_laefer['z_scaled']-9)/3.28084,bins=range(0,40,3),labels=range(3,40,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_face_laefer['intensity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_pts = wall_face_laefer[wall_face_laefer['flight_id']==flight_ids[1]]\n",
    "print(\"shape\",flight_pts.shape)\n",
    "flight_pts.groupby('pts_bins')['intensity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intensity on the parking lot horizontal surface\n",
    "rectangle_points_laefer = pd.read_pickle(file_dir+\"rectangle_points_laefer.pkl\")\n",
    "rectangle_points_laefer[rectangle_points_laefer['flight_id']=='181004']['intensity'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density up and down the wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts.loc['wall_horiz'] = np.sqrt((pts['x_scaled']-bottom_left_pt[0])**2+(pts['y_scaled']-bottom_left_pt[1])**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# horizontal distance along wall face\n",
    "# wall_horiz = np.sqrt((pts['x_scaled']-bottom_left_pt[0])**2+(pts['y_scaled']-bottom_left_pt[1])**2)\n",
    "\n",
    "wall_face_laefer = wall_face_list[0]\n",
    "plt.figure(figsize=[20,22])\n",
    "for i,fid in enumerate(wall_face_laefer['flight_id'].unique()):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    pts = wall_face_laefer[wall_face_laefer['flight_id']==fid]\n",
    "    # Calculate horizontal wall location\n",
    "    pts['wall_horiz'] = np.sqrt((pts['x_scaled']-bottom_left_pt[0])**2+(pts['y_scaled']-bottom_left_pt[1])**2)\n",
    "    hist = pd.cut(wall_face_laefer[wall_face_laefer['flight_id']==fid]['z_scaled'],bins=range(0,120,5),labels=range(5,120,5))\n",
    "#     plt.hist(hist,orientation='horizontal')\n",
    "    plt.plot(pts['wall_horiz']/3.28084,pts['z_scaled']/3.28084,'x')\n",
    "    plt.yticks(np.arange(0,36,3))\n",
    "    plt.ylabel(\"Wall height (m)\")\n",
    "    plt.xlabel(\"Horizontal wall position (m)\")\n",
    "    plt.title(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_face_laefer[(wall_face_laefer['flight_id']=='200742')& \\\n",
    "                 (wall_face_laefer['x_scaled']<977216.622) &\\\n",
    "                 (wall_face_laefer['x_scaled']>977216.62)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_ids = ['181004','180819','164445','180632']\n",
    "pts_fid = wall_face_laefer[wall_face_laefer['flight_id']==flight_ids[1]]['z_scaled'].copy()\n",
    "pts_fid = pts_fid/3.28084\n",
    "pts_bins = pd.cut(pts_fid,bins=range(15,36,3),labels=range(18,36,3))\n",
    "pts_density = pts_bins.value_counts()/(3*(6.899845795386761/3.28084))\n",
    "pts_density.sort_index(inplace=True)\n",
    "plt.plot(pts_density,range(18,36,3),'-o')\n",
    "plt.xlabel(\"Vertical Density (pts/m^2)\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.ylabel(\"Height on wall (m)\",fontsize=15)\n",
    "plt.yticks(fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_fid = wall_face_laefer['z_scaled'].copy()\n",
    "pts_fid = pts_fid/3.28084\n",
    "pts_bins = pd.cut(pts_fid,bins=[0,16,32],labels=('low','high'))\n",
    "pts_density = pts_bins.value_counts()/(1*(6.899845795386761/3.28084))\n",
    "pts_density.sort_index(inplace=True)\n",
    "plt.bar(['low','high'],pts_density)\n",
    "plt.xlabel(\"Vertical Density (pts/m^2)\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.ylabel(\"Height on wall (m)\",fontsize=15)\n",
    "plt.yticks(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_fid = wall_face_laefer['z_scaled'].copy()\n",
    "pts_fid = pts_fid/3.28084\n",
    "pts_bins = pd.cut(pts_fid,bins=range(9,36,3),labels=range(12,36,3))\n",
    "pts_density = pts_bins.value_counts()/(2*(14.899845795386761/3.28084))\n",
    "pts_density.sort_index(inplace=True)\n",
    "plt.plot(pts_density,range(12,36,3),'-o')\n",
    "plt.xlabel(\"Vertical Density (pts/m^2)\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.ylabel(\"Height on wall (m)\",fontsize=15)\n",
    "plt.yticks(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy up the wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_fid = [sf.z for sf in SampleFlightList]\n",
    "pts_fid = [pt/3.28084 for pt in pts_fid]\n",
    "pts_bins = pd.cut(pts_fid,bins=range(8,36,2),labels=range(10,36,2))\n",
    "\n",
    "# Create acc_df Dataframe of accuracy and height bins for a specific flight id\n",
    "# acc_df = pd.DataFrame([ss.flight_list_laefer[0].sd_dist for ss in SampleFlightList],columns=['total_rmse'])\n",
    "acc_df = pd.DataFrame(pts_bins,columns=['bin'])\n",
    "\n",
    "acc_df['z'] = pts_fid\n",
    "# plt.plot(acc_df[acc_df['bin']==30]['z'])\n",
    "\n",
    "# Flight id specific accuracy\n",
    "fid = '181004' # Farther away \n",
    "# fid = '180819' # About 100m away\n",
    "acc_list = []\n",
    "for j in SampleFlightList:\n",
    "    dd = {j.flight_list_laefer[i].flight_id:i for i in range(len(j.flight_list_laefer))}\n",
    "    ix = dd[fid]\n",
    "    acc_list.append(j.flight_list_laefer[ix].sd_dist/3.28084)\n",
    "len(acc_list)\n",
    "\n",
    "acc_df['fid_rmse'] = acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(np.arange(12-3,33-3,2),acc_df.groupby('bin')['fid_rmse'].mean().iloc[1:-1])\n",
    "plt.ylabel(\"Wall Height (m)\")\n",
    "plt.xlabel(\"Single Flight RMSE (m)\")\n",
    "plt.title(\"Flight ID: \"+str(fid))\n",
    "print(acc_df['bin'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(np.arange(12-3,33-3,2),acc_df.groupby('bin')['fid_rmse'].mean().iloc[1:-1])\n",
    "plt.ylabel(\"Wall Height (m)\")\n",
    "plt.xlabel(\"Single Flight RMSE (m)\")\n",
    "plt.title(\"Flight ID: \"+str(fid))\n",
    "print(acc_df['bin'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What causes C and W?\n",
    "What's the distribution of h's that generate C for vertical surfaces?  Outlier, or consistent misalignment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = {\n",
    " '164239':'n-s  ',\n",
    " '164445':'n-s  ',\n",
    " '164640':'n-s  ',\n",
    " '172753':'e-w  ',\n",
    " '172928':'e-w  ',\n",
    " '173110':'e-w  ',\n",
    " '180632':'sw-ne',\n",
    " '180819':'sw-ne',\n",
    " '181004':'sw-ne',\n",
    " '200212':'se-nw',\n",
    " '200600':'se-nw',\n",
    " '200742':'se-nw',\n",
    " '200938':'se-nw' \n",
    "}\n",
    "dir_list = ['n-s  ','e-w  ','sw-ne','se-nw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square_points_list, SampleFlightList, wall_face_list, pt_density_list, sd_wall_list\n",
    "h_dict = {\n",
    " '164239':[],\n",
    " '164445':[],\n",
    " '164640':[],\n",
    " '172753':[],\n",
    " '172928':[],\n",
    " '173110':[],\n",
    " '180632':[],\n",
    " '180819':[],\n",
    " '181004':[],\n",
    " '200212':[],\n",
    " '200600':[],\n",
    " '200742':[],\n",
    " '200938':[] \n",
    "}\n",
    "# Collect h for each flight pass in each sample square\n",
    "for sample_num in range(2500):\n",
    "    h_list = [fp.h for fp in SampleFlightList[sample_num].flight_list_laefer[2:]]\n",
    "    num_pt_list = [fp.num_points for fp in SampleFlightList[sample_num].flight_list_laefer[2:]]\n",
    "    flight_ids = [fp.flight_id for fp in SampleFlightList[sample_num].flight_list_laefer[2:]]\n",
    "    total_pts = SampleFlightList[sample_num].flight_list_laefer[0].num_points\n",
    "    for a in h_dict.keys():\n",
    "        if a in flight_ids:\n",
    "            ix = flight_ids.index(a)\n",
    "            h_dict[a].append(h_list[ix])\n",
    "        else:\n",
    "            h_dict[a].append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean height for each flight pass\n",
    "print(\"F_Id\\t Mean abs height\\n\",\"*\"*23)\n",
    "[print(\"{}: {:6.3f}\".format(k,np.nanmean([abs(h) for h in h_dict[k]]))) for k in h_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(\"{}:\\t{:2.4f}\\t{:2} points\\t{:2.4f}\".format(flight_ids[i],h_list[i]**2*num_pt_list[i],num_pt_list[i],h_list[i])) for i in range(len(h_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "h_dir_dict = defaultdict(list)\n",
    "for ss in range(len(h_dict['164239'])):\n",
    "    for di in dir_list:\n",
    "        direction_h_sum = 0\n",
    "        direction_count = 0\n",
    "\n",
    "        for fp in h_dict.keys():\n",
    "            if direction[fp] == di:\n",
    "                direction_h_sum += h_dict[fp][ss]\n",
    "                direction_count +=1    \n",
    "        h_dir_dict[di].append(direction_h_sum/direction_count)\n",
    "dir_list = ['n-s  ','e-w  ','sw-ne','se-nw']\n",
    "# Mean height for each direction\n",
    "print(\"Direct\\tMean abs height\\n\",\"*\"*22)\n",
    "[print(\"{}: {:6.3f}\".format(k,np.nanmean([abs(h) for h in h_dir_dict[k]]))) for k in h_dir_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix of mean height differences across flight passes (would expect larger diffs for different directions)\n",
    "def create_h_matrix(h_dict):\n",
    "    h_matrix = np.zeros([len(h_dict),len(h_dict)])\n",
    "    for i,key1 in enumerate(h_dict.keys()):\n",
    "        for j,key2 in enumerate(h_dict.keys()):\n",
    "            h_matrix[i,j] = np.nanmean(abs(np.array(h_dict[key1]) - np.array(h_dict[key2])))\n",
    "    return h_matrix\n",
    "\n",
    "def h_heatmap(h_matrix,h_dict,fontsize=15,label='Flight ID'):\n",
    "    # Heatmap of the matrix\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.imshow(h_matrix, cmap='YlOrRd',vmin=0,vmax=0.6)\n",
    "    plt.xticks(np.arange(0,h_matrix.shape[0]),h_dict.keys(),rotation=90,fontsize=fontsize)\n",
    "    plt.yticks(np.arange(0,h_matrix.shape[0]),h_dict.keys(),fontsize=fontsize)\n",
    "    plt.ylabel(label,fontsize=fontsize)\n",
    "    plt.xlabel(label,fontsize=fontsize)\n",
    "    plt.ylim(h_matrix.shape[0]-0.5,-0.5)\n",
    "    plt.title(\"Mean Absolute h difference\",fontsize=fontsize)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "h_matrix = create_h_matrix(h_dict)\n",
    "h_heatmap(h_matrix,h_dict)  \n",
    "# h_matrix = create_h_matrix(h_dir_dict)\n",
    "# h_heatmap(h_matrix,h_dir_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "h_matrix = create_h_matrix(h_dir_dict)\n",
    "h_heatmap(h_matrix,h_dir_dict,label=\"Flight Direction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we remove the acute angle flight passes, what happens to C,W?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracted from SampleSquare class to remove specific flight passes\n",
    "def error_decomp_f(flight_list,skip_flight_pass_list=[]):\n",
    "    # Calculates the cross-pass, within-pass, and RMSE error for a particular SampleSquare and flight_list\n",
    "    C2,W2 = 0,0\n",
    "    \n",
    "    # num_points in skipped flight passes\n",
    "    num_pts_skip = 0\n",
    "    for flight in flight_list:\n",
    "        if flight.flight_id in skip_flight_pass_list:\n",
    "            num_pts_skip += flight.num_points\n",
    "    \n",
    "    for i,flight_i in enumerate(flight_list[2:]): # Skip total and sampled\n",
    "        if flight_i.flight_id not in skip_flight_pass_list:\n",
    "            C2 += flight_i.num_points*(flight_i.h**2) / (flight_list[0].num_points-num_pts_skip)\n",
    "            W2 += flight_i.num_points*(flight_i.sd_dist**2) / (flight_list[0].num_points - num_pts_skip)\n",
    "    rmse = np.sqrt(C2+W2)\n",
    "    C = np.sqrt(C2)\n",
    "    W = np.sqrt(W2)\n",
    "    return (C,W,rmse)\n",
    "\n",
    "# Worst 2 flight passes\n",
    "# skip_flight_pass_list = ['200600','200742']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "cw = []\n",
    "for flight in SampleFlightList:\n",
    "    try:\n",
    "        cw.append(flight.error_decomp_laefer)\n",
    "    except AttributeError:\n",
    "        print(\"Missing\")\n",
    "#     cw_df = pd.DataFrame(cw,columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "    cw_df = pd.DataFrame(cw,columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "\n",
    "(cw_df/3.28084).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only the sw-ne and se-nw flights\n",
    "skip_flight_pass_list = ['164239','164445','164640','172753','172928','173110']\n",
    "cw_aug = []\n",
    "for flight in SampleFlightList:\n",
    "    try:\n",
    "        cw_aug.append(error_decomp_f(flight.flight_list_laefer,skip_flight_pass_list))\n",
    "    except AttributeError:\n",
    "        print(\"Missing\")\n",
    "    cw_aug_df = pd.DataFrame(cw_aug,columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "\n",
    "(cw_aug_df/3.28084).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only the n-e and s-w flights\n",
    "skip_flight_pass_list = ['180632','180819','181004','200212','200600','200742','200938'] \n",
    "cw_aug = []\n",
    "for flight in SampleFlightList:\n",
    "    try:\n",
    "        cw_aug.append(error_decomp_f(flight.flight_list_laefer,skip_flight_pass_list))\n",
    "    except AttributeError:\n",
    "        print(\"Missing\")\n",
    "    cw_aug_df = pd.DataFrame(cw_aug,columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "\n",
    "(cw_aug_df/3.28084).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All except 2 worst flights\n",
    "skip_flight_pass_list =  ['200600','200742']\n",
    "cw_aug = []\n",
    "for flight in SampleFlightList:\n",
    "    try:\n",
    "        cw_aug.append(error_decomp_f(flight.flight_list_laefer,skip_flight_pass_list))\n",
    "    except AttributeError:\n",
    "        print(\"Missing\")\n",
    "    cw_aug_df = pd.DataFrame(cw_aug,columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "\n",
    "(cw_aug_df/3.28084).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract points within a square around the desired point\n",
    "\n",
    "# Parking Lot\n",
    "# pt_x = 977037.343\n",
    "# pt_y = 174586.034\n",
    "\n",
    "# Corner of building\n",
    "# pt_x_bldg = 977229.375\n",
    "# pt_y_bldg = 174579.42\n",
    "\n",
    "# Top of building\n",
    "# pt_x = 977229.375\n",
    "# pt_y = 174579.42\n",
    "\n",
    "# Projects in back parking lot\n",
    "# pt_x = 977458.238\n",
    "# pt_y = 173302.388\n",
    "\n",
    "# Solar panel\n",
    "# pt_x = 977682.975\n",
    "# pt_y = 174148.192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers and print the count: z < 0, z > 30\n",
    "def remove_vertical_outliers(rectangle_points,z_low,z_high):\n",
    "    outliers = rectangle_points[(rectangle_points['z_scaled']<z_low) | (rectangle_points['z_scaled']>z_high)].index\n",
    "    rectangle_points = rectangle_points.drop(outliers)\n",
    "    print(\"Number of outliers: {}\".format(len(outliers)))\n",
    "    return rectangle_points\n",
    "# rectangle_points_laefer = remove_vertical_outliers(rectangle_points_laefer,0,30)\n",
    "# rectangle_points_nyc = remove_vertical_outliers(rectangle_points_nyc,0,30)\n",
    "# rectangle_points_usgs = remove_vertical_outliers(rectangle_points_usgs,0,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(square_points_bldg, x='x_plot', y='y_plot', z='z_plot',\n",
    "              size='size_num',size_max = 12)\n",
    "\n",
    "fig.update_layout( \n",
    "    scene = dict(xaxis = dict(title=\"Easting (feet)\"),\n",
    "                 yaxis = dict(title=\"Northing (feet)\"),\n",
    "                 zaxis = dict(title=\"Vertical (feet)\"),\n",
    "                ),\n",
    "    width=900,\n",
    "    height=900,\n",
    "    margin=dict(r=20, l=10, b=10, t=10),\n",
    "    showlegend=False,\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(square_points_nyc, x='x_plot', y='y_plot', z='z_plot',\n",
    "              size='size_num',size_max = 12)\n",
    "\n",
    "fig.update_layout( \n",
    "    scene = dict(xaxis = dict(title=\"Easting (feet)\"),\n",
    "                 yaxis = dict(title=\"Northing (feet)\"),\n",
    "                 zaxis = dict(title=\"Vertical (feet)\"),\n",
    "                ),\n",
    "    width=900,\n",
    "    height=900,\n",
    "    margin=dict(r=20, l=10, b=10, t=10),\n",
    "    showlegend=False,\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the wall face, find normal vector, calculate vertical density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_1 = np.array([37.7,10.04])\n",
    "pt_2 = np.array([27.094,18.439])\n",
    "wall_pt = (31.77,14.90,43.00)\n",
    "\n",
    "# East? Facing Wall (farther from the little stump)\n",
    "# pt_1 = np.array([20.59,15.02])\n",
    "# pt_2 = np.array([10.34,2.93])\n",
    "# wall_pt = (19.414,12.379,73.863)\n",
    "\n",
    "wall_face = grab_wall_face(square_points_bldg,pt_1,pt_2,20,100,1e-2)\n",
    "wall_face_nyc = grab_wall_face(square_points_nyc,pt_1,pt_2,20,100,5e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wall_face.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_face_nyc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vector,points,wall_face,pts_on_plane = plane_fit(wall_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_vector)\n",
    "print(norm_vector_nyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vector_nyc,points,wall_face_nyc,pts_on_plane_nyc = plane_fit(wall_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(wall_face, x='x_plot', y='y_plot', z='z_plot',\n",
    "              color='flight_id',size='size_num',size_max = 12)\n",
    "\n",
    "fig.update_layout( \n",
    "    scene = dict(xaxis = dict(title=\"Easting (feet)\"),\n",
    "                 yaxis = dict(title=\"Northing (feet)\"),\n",
    "                 zaxis = dict(title=\"Vertical (feet)\"),\n",
    "                ),\n",
    "    width=900,\n",
    "    height=900,\n",
    "    margin=dict(r=20, l=10, b=10, t=10),\n",
    "    showlegend=False,\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point in middle of wall - in xyz_plot coordinates (less the min of each coordinate)\n",
    "# It's best to highlight a point in the plot above and use that.\n",
    "\n",
    "feet_from_pt = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate density for both datasets   \n",
    "vertical_point_density(square_points_nyc,norm_vector_nyc,wall_pt,feet_from_pt)\n",
    "vertical_point_density(square_points_bldg,norm_vector,wall_pt,feet_from_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(vertical_square, x='x_plot', y='y_plot', z='z_plot',\n",
    "              color='flight_id', size='size_num',size_max = 8)\n",
    "\n",
    "fig.update_layout( \n",
    "    scene = dict(xaxis = dict(title=\"Easting (feet)\"),\n",
    "                 yaxis = dict(title=\"Northing (feet)\"),\n",
    "                 zaxis = dict(title=\"Vertical (feet)\"),\n",
    "                ),\n",
    "    width=900,\n",
    "    height=900,\n",
    "    margin=dict(r=20, l=10, b=10, t=10),\n",
    "    showlegend=False,\n",
    "    xaxis = {\"title\":{\"text\":\"Cat\"}})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing LAS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write square_points_bldg to file\n",
    "inFile = File(file_dir+'10552_NYU_M2 - Scanner 1 - 190511_164039_1 - originalpoints.laz', mode='r')\n",
    "# Convert DF into tuples that laspy wants\n",
    "void = [(tuple(r[columns_point_cloud]),) for i,r in square_points_laefer.iterrows()]\n",
    "# Export\n",
    "outFile1 = File(\"../../Data/parking_lot/flat_parking_lot_laefer.las\", mode = \"w\",header = inFile.header)\n",
    "outFile1.points = void\n",
    "outFile1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYC data\n",
    "# Write square_points_bldg to file\n",
    "inFile_nyc = File(nyc_file_dir+'975172.las', mode='r')\n",
    "# Convert DF into tuples that laspy wants\n",
    "void = [(tuple(r[columns_point_cloud]),) for i,r in square_points_nyc.iterrows()]\n",
    "# Export\n",
    "outFile1 = File(\"../../Data/parking_lot/flat_parking_lot_nyc.las\", mode = \"w\",header = inFile.header)\n",
    "outFile1.points = void\n",
    "outFile1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting charts from previous updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vector,points,square_points,_ = plane_fit(square_points)\n",
    "\n",
    "# Add distance from flat plane with norm (x,y,z) = (0,0,1)\n",
    "square_points['dist_from_flat']=np.array([np.dot(point,np.array([0,0,1])) for point in points])\n",
    "\n",
    "# remove data points >5 feet below plane.\n",
    "outliers = square_points[square_points['dist_from_plane']<-5].index\n",
    "square_points = square_points.drop(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scan_angle_dist_from_plane(df,distance_metric):\n",
    "    x = abs(df['scan_angle'])*.006\n",
    "    y = df[distance_metric]\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.plot(x,y,'xb')\n",
    "    z = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(x,p(x),\"r--\")\n",
    "    plt.xlabel(\"Scan angle (degrees)\")\n",
    "    plt.ylabel(\"Point distance from plane\")\n",
    "    print(\"y={:2.8f}x+{:2.8f}\".format(z[0],z[1]))\n",
    "    plt.title(\"Scan Angle vs Distance to Fitted Plane\")\n",
    "plot_scan_angle_dist_from_plane(square_points,'dist_from_plane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(square_points)),square_points['scan_angle'],'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scan_angle_dist_from_plane(square_points,'dist_from_flat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart from slides showing points per run\n",
    "labels = [pt[0][11:-4] for pt in pts_from_scan]\n",
    "num_points = [pt[1]+.01 for pt in pts_from_scan]\n",
    "plt.figure(figsize=(25,20))\n",
    "plt.bar(labels,num_points,)\n",
    "plt.xticks(rotation=45,fontsize=20)\n",
    "plt.yticks(np.arange(0, max(num_points), step=(max(num_points)/10)),fontsize=20)\n",
    "plt.ylabel(\"Number of points from run\",fontsize=20)\n",
    "plt.xlabel(\"Run ID\",fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USGS: Converting Lat-Lon and adding flight id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting lat-lon to state plane\n",
    "from pyproj import Proj, transform\n",
    "y1 = np.array(usgs_square_points['x_scaled'])\n",
    "x1 = np.array(usgs_square_points['y_scaled'])\n",
    "inProj = Proj('epsg:4269')\n",
    "outProj = Proj('epsg:3628')\n",
    "x2,y2 = transform(inProj,outProj,x1,y1)\n",
    "usgs_square_points['latitude'] = usgs_square_points['y_scaled'].copy()\n",
    "usgs_square_points['longitude'] = usgs_square_points['x_scaled'].copy()\n",
    "usgs_square_points['x_scaled'] = x2\n",
    "usgs_square_points['y_scaled'] = y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_hdf(\"../../Data/parking_lot/las_points_180819.lz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['intensity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1:,'scan_gap'] = [df.loc[i+1,'scan_angle'] - df.loc[i,'scan_angle'] for i in range(df.shape[0]-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:1000000,'return_num'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df['num_returns'] = np.floor(df['flag_byte']/16).astype(int)\n",
    "df['return_num'] = df['flag_byte']%16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
