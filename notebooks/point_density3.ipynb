{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from laspy.file import File\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0,'..') # So we can import point_density_functions from parent directory\n",
    "from point_density_functions import *\n",
    "%load_ext autoreload\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laefer\n",
    "file_dir = '../../Data/parking_lot/'\n",
    "filenames =list(pd.read_csv(file_dir+\"filenames.txt\",header=None)[0])\n",
    "pt_files = list(pd.read_csv(file_dir+\"pt_files.txt\",header=None)[0])\n",
    "# NYC\n",
    "nyc_file_dir = '../../Data/NYC_topo/'\n",
    "nyc_pt_file = ['las_points_NYC_flightid_975172.lz']\n",
    "# USGS\n",
    "usgs_file_dir = '../../Data/USGS/'\n",
    "usgs_pt_files = ['las_points_flight_id_18TWK820985.lz']\n",
    "\n",
    "\n",
    "# Corresponds to LAS 1.2 Point Data Record Format 1\n",
    "columns_dublin_pt_cloud = [\n",
    "    'X',\n",
    "    'Y',\n",
    "    'Z',\n",
    "    'intensity',\n",
    "    'return_number_byte',\n",
    "    'classification_byte',\n",
    "    'scan_angle',\n",
    "    'user_data',\n",
    "    'pt_src_id',\n",
    "    'gps_time']\n",
    "\n",
    "columns_point_cloud = [\n",
    "    'X','Y','Z',\n",
    "    'intensity',\n",
    "    'flag_byte',\n",
    "    'classification_flags',\n",
    "    'classification_byte',\n",
    "    'user_data',\n",
    "    'scan_angle',\n",
    "    'pt_src_id',\n",
    "    'gps_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works\n",
    "# for filename in filenames:\n",
    "#     create_df_hd5(file_dir,filename,columns_point_cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supporting Functions for Horizontal Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Big parking lot rectangle\n",
    "def rectangle(pt1,pt2,y_length,x_length):\n",
    "    '''\n",
    "    Function returns uv_inv and w, for use in selecting points within the rectangle\n",
    "    Note: This function only works in 2D (horizontal plane)\n",
    "    Inputs:\n",
    "    pt1 - 2x1 numpy array with x and y coordinate for bottom point\n",
    "    pt2 - 2xy numpy array with x and y coordinate for top point\n",
    "    y_length - bottom-to-top length (positive is in direction of top from bottom point)\n",
    "    x_length - left-to-right length (positive means pts are on left border, negative means they're on right)\n",
    "    Outputs:\n",
    "    uv_inv: 2xy numpy array - u and v are the sides of the rectangle.  uv = [u v] is a matrix with u and v as columns.\n",
    "    w: 2x1 numpy array with (x,y) coordinates of reference (bottom) point.\n",
    "    \n",
    "    Reference: https://math.stackexchange.com/questions/190111/how-to-check-if-a-point-is-inside-a-rectangle\n",
    "    '''\n",
    "    unit_u = (pt2 - pt1)/np.linalg.norm(pt2-pt1)\n",
    "    unit_v = np.array([unit_u[1],-1*unit_u[0]])\n",
    "    u = unit_u*y_length\n",
    "    v = unit_v*x_length\n",
    "    uv = np.array([u,v]).T\n",
    "    uv_inv = np.linalg.inv(uv)\n",
    "    w = pt1\n",
    "    return uv_inv,w,unit_u,unit_v\n",
    "\n",
    "# rectangle_points_laefer = grab_points_big_rect(pt_files,file_dir,uv_inv,w)\n",
    "# rectangle_points_nyc = grab_points_big_rect(nyc_pt_file,nyc_file_dir,uv_inv,w)\n",
    "# rectangle_points_usgs = grab_points_big_rect(usgs_pt_files,usgs_file_dir,uv_inv,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(SampleFlightList,pt_density_laefer_list,pt_density_nyc_list,pt_density_usgs_list,feet_from_point):\n",
    "    # Laefer\n",
    "    sd_laefer_total = np.mean([ss.flight_list_laefer[0].sd_dist for ss in SampleFlightList])\n",
    "    sd_laefer_sample = np.mean([ss.flight_list_laefer[1].sd_dist for ss in SampleFlightList])\n",
    "    avg_flight_paths_laefer = np.mean([len(flight.flight_list_laefer) for flight in SampleFlightList])-2\n",
    "\n",
    "    phis_laefer_total = [ss.phi_laefer_total for ss in SampleFlightList]\n",
    "    phis_laefer_sample = [ss.phi_laefer_sample for ss in SampleFlightList]\n",
    "\n",
    "    print(\"2019 scan (Horizontal, {} samples): \\n\".format(len(SampleFlightList))+\"*\"*30)\n",
    "    print(\"Avg points per square: {:2.2f} points\".format((4 * feet_from_point**2)*np.mean(pt_density_laefer_list)))\n",
    "    print(\"Avg density: {:2.4f} pts/sqft (SD: {:2.4f})\".format(np.mean(pt_density_laefer_list),np.std(pt_density_laefer_list)))\n",
    "    print(\"Avg number of flight paths per square: {:2.2f}\".format(avg_flight_paths_laefer))\n",
    "    print(\"\\nphi_total: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_laefer_total),np.std(phis_laefer_total)))\n",
    "    print(\"phi_sample: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_laefer_sample),np.std(phis_laefer_sample)))\n",
    "    print(\"Total point dist from plane, SD: {:2.4f} feet\".format(sd_laefer_total))\n",
    "    print(\"Avg flight point dist from plane, SD: {:2.4f} feet\".format(sd_laefer_total/np.mean(phis_laefer_total)))\n",
    "\n",
    "    # NYC\n",
    "    phis_nyc_total = [ss.phi_nyc_total for ss in SampleFlightList]\n",
    "    phis_nyc_sample = [ss.phi_nyc_sample for ss in SampleFlightList]\n",
    "    avg_flight_paths_nyc = np.mean([len(flight.flight_list_nyc) for flight in SampleFlightList])-2\n",
    "\n",
    "    sd_nyc_total = np.mean([ss.flight_list_nyc[0].sd_dist for ss in SampleFlightList])\n",
    "    sd_nyc_sample = np.mean([ss.flight_list_nyc[1].sd_dist for ss in SampleFlightList])\n",
    "\n",
    "    print(\"\\n2017 scan (Horizontal, {} samples): \\n\".format(len(SampleFlightList))+\"*\"*30)\n",
    "    print(\"Avg points per square: {:2.2f} points\".format((4 * feet_from_point**2)*np.mean(pt_density_nyc_list)))\n",
    "    print(\"Avg density: {:2.4f} pts/sqft (SD: {:2.4f})\".format(np.mean(pt_density_nyc_list),np.std(pt_density_nyc_list)))\n",
    "    print(\"Avg number of flight paths per square: {:2.2f}\".format(avg_flight_paths_nyc))\n",
    "    print(\"\\nphi_total: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_nyc_total),np.std(phis_nyc_total)))\n",
    "    print(\"phi_sample: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_nyc_sample),np.std(phis_nyc_sample)))\n",
    "    print(\"Total point dist from plane, SD: {:2.4f} feet\".format(sd_nyc_total))\n",
    "    print(\"Avg flight point dist from plane, SD: {:2.4f} feet\".format(sd_nyc_total/np.mean(phis_nyc_total)))\n",
    "\n",
    "    # USGS\n",
    "    phis_usgs_total = [ss.phi_usgs_total for ss in SampleFlightList]\n",
    "    phis_usgs_sample = [ss.phi_usgs_sample for ss in SampleFlightList]\n",
    "    avg_flight_paths_usgs = np.mean([len(flight.flight_list_usgs) for flight in SampleFlightList])-2\n",
    "\n",
    "    sd_usgs_total = np.mean([ss.flight_list_usgs[0].sd_dist for ss in SampleFlightList])\n",
    "    sd_usgs_sample = np.mean([ss.flight_list_usgs[1].sd_dist for ss in SampleFlightList])\n",
    "\n",
    "    print(\"\\n2014 scan (Horizontal, {} samples): \\n\".format(len(SampleFlightList))+\"*\"*30)\n",
    "    print(\"Avg points per square: {:2.2f} points\".format((4 * feet_from_point**2)*np.mean(pt_density_usgs_list)))\n",
    "    print(\"Avg density: {:2.4f} pts/sqft (SD: {:2.4f})\".format(np.mean(pt_density_usgs_list),np.std(pt_density_usgs_list)))\n",
    "    print(\"Avg number of flight paths per square: {:2.2f}\".format(avg_flight_paths_usgs))\n",
    "    print(\"\\nphi_total: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_usgs_total),np.std(phis_usgs_total)))\n",
    "    print(\"phi_sample: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_usgs_sample),np.std(phis_usgs_sample)))\n",
    "    print(\"Total point dist from plane, SD: {:2.4f} feet\".format(sd_usgs_total))\n",
    "    print(\"Avg flight point dist from plane, SD: {:2.4f} feet\".format(sd_usgs_total/np.mean(phis_usgs_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling squares and Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregators\n",
    "pt_density_usgs_list, pt_density_nyc_list, pt_density_laefer_list = [],[],[]\n",
    "avg_height_diff = []\n",
    "sd_height_usgs, sd_height_nyc, sd_height_laefer = [],[],[]\n",
    "SampleFlightList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Water front parking lot\n",
    "pt1 = np.array([976534.92, 173979.05,0])\n",
    "pt2 = np.array([976863.17, 174360.18,0])\n",
    "u_length = np.linalg.norm(pt2-pt1)\n",
    "v_length = 80\n",
    "print(\"u_length: \",u_length)\n",
    "pt3 = np.array([976595.53720051, 173926.84315177,0]) # Backed into from previous 2D v calculation\n",
    "uv_inv,w,unit_u,unit_v = rectangle(pt1[:2],pt2[:2],500,80)\n",
    "\n",
    "rectangle_points_laefer = pd.read_pickle(file_dir+\"rectangle_points_laefer.pkl\")\n",
    "rectangle_points_nyc = pd.read_pickle(file_dir+\"rectangle_points_nyc.pkl\")\n",
    "rectangle_points_usgs = pd.read_pickle(usgs_file_dir+\"rectangle_points_usgs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create center_points\n",
    "feet_from_point = 3.281/np.sqrt(2)\n",
    "center_points = center_point_sample(5000,pt1,pt2,pt3,u_length=u_length,v_length=v_length,border=[0.05,0.05])\n",
    "mean_z = rectangle_points_laefer['z_scaled'].mean()\n",
    "pts_thrown_out = 0\n",
    "\n",
    "for center_point in center_points:\n",
    "    square_points_usgs = in_horizontal_square(rectangle_points_usgs,center_point[:2],feet_from_point)\n",
    "    square_points_nyc = in_horizontal_square(rectangle_points_nyc,center_point[:2],feet_from_point)\n",
    "    square_points_laefer = in_horizontal_square(rectangle_points_laefer,center_point[:2],feet_from_point)\n",
    "    \n",
    "    laefer_flight_count = len(square_points_laefer['flight_id'].unique())\n",
    "    nyc_flight_count = len(square_points_nyc['flight_id'].unique())\n",
    "    usgs_flight_count = len(square_points_usgs['flight_id'].unique())\n",
    "   \n",
    "    laefer_density = square_points_laefer.shape[0] / laefer_flight_count\n",
    "    try:\n",
    "        nyc_density = square_points_nyc.shape[0]/nyc_flight_count\n",
    "    except ZeroDivisionError:\n",
    "        nyc_density = 0\n",
    "        \n",
    "    try:\n",
    "        usgs_density = square_points_usgs.shape[0] / usgs_flight_count\n",
    "    except ZeroDivisionError:\n",
    "        usgs_density = 0\n",
    " \n",
    "    # If z_max > 10, <6 for any dataset, skip it\n",
    "    if (square_points_nyc['z_scaled'].max()<mean_z+3) & \\\n",
    "       (square_points_usgs['z_scaled'].max()<mean_z+3) & \\\n",
    "       (square_points_laefer['z_scaled'].max()<mean_z+3):\n",
    "        # Statistics!\n",
    "                \n",
    "        # Point density\n",
    "        num_points_nyc = square_points_nyc.shape[0]\n",
    "        pt_density_nyc_list.append(num_points_nyc / (4 * feet_from_point**2))        \n",
    "        num_points_usgs = square_points_usgs.shape[0]\n",
    "        pt_density_usgs_list.append(num_points_usgs / (4 * feet_from_point**2))        \n",
    "        num_points_laefer = square_points_laefer.shape[0]\n",
    "        pt_density_laefer_list.append(num_points_laefer / (4 * feet_from_point**2))        \n",
    "        \n",
    "        # Flight path specifics\n",
    "        laefer_flight_list = create_flight_list(square_points_laefer)\n",
    "        usgs_flight_list = create_flight_list(square_points_usgs)\n",
    "        nyc_flight_list = create_flight_list(square_points_nyc)\n",
    "        # Create SampleSquare from all flight passes\n",
    "        ss = SampleSquare(laefer_flight_list, nyc_flight_list,usgs_flight_list, x = center_point[0], \\\n",
    "                          y=center_point[1],feet_from_point=feet_from_point)\n",
    "        # Collect SampleSquares\n",
    "        SampleFlightList.append(ss)\n",
    "        \n",
    "    else:\n",
    "        pts_thrown_out +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_out(SampleFlightList,pt_density_laefer_list,pt_density_nyc_list,pt_density_usgs_list,feet_from_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back parking lot\n",
    "u_length = 200\n",
    "v_length = 40\n",
    "pt1 = np.array([977221.16,173403.09,0])\n",
    "pt2 = np.array([977345.97611538, 173559.36199794,0])\n",
    "uv_inv,w,unit_u,unit_v = rectangle(pt1[:2],pt2[:2],u_length,v_length)\n",
    "\n",
    "pt3 = np.concatenate((w + unit_v*v_length,np.zeros(1)))\n",
    "rectangle_points_laefer=pd.read_pickle(file_dir+\"rectangle_points_back_parking_laefer.pkl\")\n",
    "rectangle_points_nyc=pd.read_pickle(file_dir+\"rectangle_points_back_parking_nyc.pkl\")\n",
    "rectangle_points_usgs=pd.read_pickle(usgs_file_dir+\"rectangle_points_back_parking_usgs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create center_points\n",
    "feet_from_point = 3.281/np.sqrt(2)\n",
    "center_points = center_point_sample(5000,pt1,pt2,pt3,u_length=u_length,v_length=v_length,border=[0.05,0.05])\n",
    "mean_z = rectangle_points_laefer['z_scaled'].mean()\n",
    "pts_thrown_out = 0\n",
    "\n",
    "for center_point in center_points:\n",
    "    square_points_usgs = in_horizontal_square(rectangle_points_usgs,center_point[:2],feet_from_point)\n",
    "    square_points_nyc = in_horizontal_square(rectangle_points_nyc,center_point[:2],feet_from_point)\n",
    "    square_points_laefer = in_horizontal_square(rectangle_points_laefer,center_point[:2],feet_from_point)\n",
    "    \n",
    "    laefer_flight_count = len(square_points_laefer['flight_id'].unique())\n",
    "    nyc_flight_count = len(square_points_nyc['flight_id'].unique())\n",
    "    usgs_flight_count = len(square_points_usgs['flight_id'].unique())\n",
    "   \n",
    "    laefer_density = square_points_laefer.shape[0] / laefer_flight_count\n",
    "    try:\n",
    "        nyc_density = square_points_nyc.shape[0]/nyc_flight_count\n",
    "    except ZeroDivisionError:\n",
    "        nyc_density = 0\n",
    "    \n",
    "    try:\n",
    "        usgs_density = square_points_usgs.shape[0] / usgs_flight_count\n",
    "    except ZeroDivisionError:\n",
    "        usgs_density = 0\n",
    " \n",
    "    # If z_max > 10, <6 for any dataset, skip it\n",
    "    if (square_points_nyc['z_scaled'].max()<mean_z+3) & \\\n",
    "       (square_points_usgs['z_scaled'].max()<mean_z+3) & \\\n",
    "       (square_points_laefer['z_scaled'].max()<mean_z+3):\n",
    "        # Statistics!\n",
    "                \n",
    "        # Point density\n",
    "        num_points_nyc = square_points_nyc.shape[0]\n",
    "        pt_density_nyc_list.append(num_points_nyc / (4 * feet_from_point**2))        \n",
    "        num_points_usgs = square_points_usgs.shape[0]\n",
    "        pt_density_usgs_list.append(num_points_usgs / (4 * feet_from_point**2))        \n",
    "        num_points_laefer = square_points_laefer.shape[0]\n",
    "        pt_density_laefer_list.append(num_points_laefer / (4 * feet_from_point**2))        \n",
    "        \n",
    "        # Flight path specifics\n",
    "        laefer_flight_list = create_flight_list(square_points_laefer)\n",
    "        usgs_flight_list = create_flight_list(square_points_usgs)\n",
    "        nyc_flight_list = create_flight_list(square_points_nyc)\n",
    "        # Create SampleSquare from all flight passes\n",
    "        ss = SampleSquare(laefer_flight_list, nyc_flight_list,usgs_flight_list, x = center_point[0], \\\n",
    "                          y=center_point[1],feet_from_point=feet_from_point)\n",
    "        # Collect SampleSquares\n",
    "        SampleFlightList.append(ss)\n",
    "        \n",
    "    else:\n",
    "        pts_thrown_out +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_out(SampleFlightList,pt_density_laefer_list,pt_density_nyc_list,pt_density_usgs_list,feet_from_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df = pd.DataFrame([flight.error_decomp_laefer for flight in SampleFlightList],columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "cw_df['nyc_C'] = [flight.error_decomp_nyc[0] for flight in SampleFlightList]\n",
    "cw_df['nyc_W'] = [flight.error_decomp_nyc[1] for flight in SampleFlightList]\n",
    "cw_df['nyc_rmse'] = [flight.error_decomp_nyc[2] for flight in SampleFlightList]\n",
    "\n",
    "cw_df['usgs_C'] = [flight.error_decomp_usgs[0] for flight in SampleFlightList]\n",
    "cw_df['usgs_W'] = [flight.error_decomp_usgs[1] for flight in SampleFlightList]\n",
    "cw_df['usgs_rmse'] = [flight.error_decomp_usgs[2] for flight in SampleFlightList]\n",
    "\n",
    "(cw_df/3.28084).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rmse = [ss.flight_list_laefer[0].square_dist \\\n",
    "/ss.flight_list_laefer[0].num_points for ss in SampleFlightList]\n",
    "np.sqrt(l_rmse).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df['laefer_rmse'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df['nyc_rmse'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Distance from plane\\n\"+\"*\"*30)\n",
    "print(\"2019: {:2.4f} (SD: {:2.4f})\".format(np.mean([ss.delta_h_mean_laefer for ss in SampleFlightList]),np.mean([ss.delta_h_sd_laefer for ss in SampleFlightList])))\n",
    "print(\"2017: {:2.4f} (SD: {:2.4f})\".format(np.mean([ss.delta_h_mean_nyc for ss in SampleFlightList]),np.mean([ss.delta_h_sd_nyc for ss in SampleFlightList])))\n",
    "print(\"2014: {:2.4f} (SD: {:2.4f})\".format(np.mean([ss.delta_h_mean_usgs for ss in SampleFlightList]),np.mean([ss.delta_h_sd_usgs for ss in SampleFlightList])))\n",
    "\n",
    "print(\"\\nCosine Similarity\\n\"+\"*\"*30)\n",
    "print(\"{:2.4f}\".format(np.mean([np.mean(ss.cosine_sim_matrix_laefer) for ss in SampleFlightList])))\n",
    "print(\"{:2.4f}\".format(np.mean([np.mean(ss.cosine_sim_matrix_nyc) for ss in SampleFlightList])))\n",
    "print(\"{:2.4f}\".format(np.mean([np.mean(ss.cosine_sim_matrix_usgs) for ss in SampleFlightList])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Parking lot in between army terminal buildings\n",
    "# u_length = 200\n",
    "# v_length = 40\n",
    "# pt1 = np.array([976975.96, 173882.3,0])\n",
    "# pt2 = np.array([977107.27980512, 174033.14796579,0])\n",
    "# uv_inv,w,unit_u,unit_v = rectangle(pt1[:2],pt2[:2],u_length,v_length)\n",
    "\n",
    "# pt3 = np.concatenate((w + unit_v*v_length,np.zeros(1)))\n",
    "\n",
    "# rectangle_points_laefer = pd.read_pickle(file_dir+\"rectangle_points_middle_parking_laefer.pkl\")\n",
    "# rectangle_points_nyc = pd.read_pickle(file_dir+\"rectangle_points_middle_parking_nyc.pkl\")\n",
    "# rectangle_points_usgs = pd.read_pickle(usgs_file_dir+\"rectangle_points_middle_parking_usgs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical density\n",
    "Identifying point at corner of building to quantify the vertical point density.  \n",
    "Center point: \t40.645854, \t-74.025299  \n",
    "Easting - 977229.375  \n",
    "Northing - 174579.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Southern wall of Army Terminal Bldg\n",
    "# middle_pt = np.array([976617.27,173802.86,58])\n",
    "# Extract from all files, the points within feet_from_pt in the xy-plane of the middle wall point\n",
    "# square_points_vertical_laefer = grab_points(pt_files,file_dir,middle_pt[0],middle_pt[1],9)\n",
    "# square_points_vertical_nyc = grab_points(nyc_pt_file,nyc_file_dir,middle_pt[0],middle_pt[1],9)\n",
    "# square_points_vertical_usgs = grab_points(usgs_pt_files,usgs_file_dir,middle_pt[0],middle_pt[1],9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vert_density(square_points_list, \n",
    "                 middle_pt, \n",
    "                 right_pt, \n",
    "                 left_pt, \n",
    "                 bottom_left_pt, \n",
    "                 feet_from_pt,\n",
    "                 SampleFlightList=[],\n",
    "                 pt_density_list=[[],[],[]],\n",
    "                 sd_wall_list=[[],[],[]],\n",
    "                 wall_face_list=None\n",
    "                 ):\n",
    "    # Unzip the list\n",
    "    square_points_laefer,square_points_nyc,square_points_usgs = \\\n",
    "    square_points_list[0],square_points_list[1],square_points_list[2]\n",
    "    \n",
    "    pt_density_laefer_list,pt_density_nyc_list,pt_density_usgs_list = \\\n",
    "    pt_density_list[0],pt_density_list[1],pt_density_list[2]\n",
    "    \n",
    "    sd_wall_dist_laefer,sd_wall_dist_nyc,sd_wall_dist_usgs = \\\n",
    "    sd_wall_list[0],sd_wall_list[1],sd_wall_list[2] \n",
    "    # Create aggregators if not provided\n",
    "    \n",
    "    \n",
    "    # Calculate norm_vector from 3 points, to define plane and extract the wall face\n",
    "    norm = np.cross(middle_pt - right_pt,(left_pt-right_pt))\n",
    "    norm = norm / np.linalg.norm(norm)\n",
    "\n",
    "    # Extract the wall face, above 15ft and below 120ft to avoid roof and grouund points\n",
    "    wall_face_laefer = grab_wall_face(square_points_laefer,norm, middle_pt,15,110,5e-1)\n",
    "    wall_face_nyc = grab_wall_face(square_points_nyc,norm, middle_pt,15,110,5e-1)\n",
    "    wall_face_usgs = grab_wall_face(square_points_usgs,norm, middle_pt,15,110,5e-1)\n",
    "\n",
    "    # Fit a plane, create norm_vector, calculate dist_from_plane\n",
    "    norm_vector_laefer,_,wall_face_laefer,_ = plane_fit(wall_face_laefer) \n",
    "    norm_vector_nyc,_,wall_face_nyc,_ = plane_fit(wall_face_nyc) \n",
    "    norm_vector_usgs,_,wall_face_usgs,_ = plane_fit(wall_face_usgs) \n",
    "    \n",
    "    # Calculate the rectangle side length, based on points\n",
    "    u_length = np.linalg.norm(bottom_left_pt-top_left_pt)\n",
    "    v_length = np.linalg.norm(bottom_left_pt-bottom_right_pt)\n",
    "    print(\"u_length: {:2.2f}m\".format(u_length/3.28084))\n",
    "    print(\"v_length: {:2.2f}m\".format(v_length/3.28084))\n",
    "\n",
    "    # Sample points in wall\n",
    "    #Note 0.28 border_v comes from: (3.5/2) (half-meter feet_from_point) / v_length (with some buffer)\n",
    "    feet_from_pt_v = 3.5\n",
    "    feet_from_pt_u = 3.5\n",
    "    border = [0,0]\n",
    "    border[0] = 1.08*(feet_from_pt_u / u_length)\n",
    "    border[1] = 1.08*(feet_from_pt_v / v_length)\n",
    "    # For density up the wall below\n",
    "    try:\n",
    "        center_points_old = center_points\n",
    "    except:\n",
    "        pass\n",
    "    center_points = center_point_sample(2500,\n",
    "                        bottom_left_pt,top_left_pt,bottom_right_pt,\n",
    "                        u_length=u_length,v_length=v_length,border=border)\n",
    "    \n",
    "    # Main Loop through the sample points\n",
    "    pts_thrown_out = 0\n",
    "\n",
    "    for center_point in center_points:\n",
    "        square_points_usgs,pt_density_usgs = in_vertical_square(wall_face_usgs,\n",
    "                                                    norm_vector_usgs,\n",
    "                                                    center_point,\n",
    "                                                    feet_from_pt_v,\n",
    "                                                    feet_from_pt_u)\n",
    "        square_points_nyc,pt_density_nyc = in_vertical_square(wall_face_nyc,\n",
    "                                                    norm_vector_nyc,\n",
    "                                                    center_point,\n",
    "                                                    feet_from_pt_v,\n",
    "                                                    feet_from_pt_u)\n",
    "        square_points_laefer,pt_density_laefer = in_vertical_square(wall_face_laefer,\n",
    "                                                    norm_vector_laefer,\n",
    "                                                    center_point,\n",
    "                                                    feet_from_pt_v,\n",
    "                                                    feet_from_pt_u)\n",
    "        laefer_flight_count = len(square_points_laefer['flight_id'].unique())\n",
    "        nyc_flight_count = len(square_points_nyc['flight_id'].unique())\n",
    "        usgs_flight_count = len(square_points_usgs['flight_id'].unique())\n",
    "\n",
    "        # Statistics!\n",
    "\n",
    "        # Point density\n",
    "        num_points_laefer = square_points_laefer.shape[0]\n",
    "        pt_density_laefer_list.append(pt_density_laefer)        \n",
    "        num_points_usgs = square_points_usgs.shape[0]\n",
    "        pt_density_usgs_list.append(pt_density_usgs)        \n",
    "        num_points_nyc = square_points_nyc.shape[0]\n",
    "        pt_density_nyc_list.append(pt_density_nyc)        \n",
    "        \n",
    "\n",
    "        # Fit a plane\n",
    "        if square_points_laefer.shape[0] > 0:\n",
    "            norm_vector_laefer,_,square_points_laefer,_ = plane_fit(square_points_laefer)\n",
    "            laefer_flight_list = create_flight_list(square_points_laefer)\n",
    "        else:\n",
    "            laefer_flight_list=None\n",
    "\n",
    "        if square_points_nyc.shape[0] > 0:\n",
    "            norm_vector_nyc,_,square_points_nyc,_ = plane_fit(square_points_nyc)\n",
    "            nyc_flight_list = create_flight_list(square_points_nyc)\n",
    "        else:\n",
    "            nyc_flight_list=None\n",
    "\n",
    "        if square_points_usgs.shape[0] > 0:\n",
    "            norm_vector_usgs,_,square_points_usgs,_ = plane_fit(square_points_usgs)\n",
    "            usgs_flight_list = create_flight_list(square_points_usgs)\n",
    "        else:\n",
    "            usgs_flight_list=None\n",
    "        # Flight path specifics\n",
    "        ss = SampleSquare(laefer_flight_list, nyc_flight_list,usgs_flight_list, x = center_point[0], \\\n",
    "                          y=center_point[1],z=center_point[2],feet_from_point=[feet_from_pt_v,feet_from_pt_u])\n",
    "        SampleFlightList.append(ss)    \n",
    "    \n",
    "    # Print outs\n",
    "    print(\"Pts in Laefer: {}\".format(wall_face_laefer.shape[0]))\n",
    "    print(\"Pts in NYC: {}\".format(wall_face_nyc.shape[0]))\n",
    "    print(\"Pts in USGS: {}\".format(wall_face_usgs.shape[0]))\n",
    "\n",
    "    print(\"Vertical face point density over {:d} samples\".format(len(pt_density_laefer_list)))\n",
    "    print(\"*\"*30)\n",
    "    print(\"USGS avg density: {:2.4f} (SD: {:2.4f})\".format(np.mean(pt_density_usgs_list),np.std(pt_density_usgs_list)))\n",
    "    print(\"NYC avg density: {:2.4f} (SD: {:2.4f})\".format(np.mean(pt_density_nyc_list),np.std(pt_density_nyc_list)))\n",
    "    print(\"Laefer avg density: {:2.4f} (SD: {:2.4f})\".format(np.mean(pt_density_laefer_list),np.std(pt_density_laefer_list)))\n",
    "    \n",
    "    # Output\n",
    "    wall_face_list = [wall_face_laefer,wall_face_nyc,wall_face_usgs]\n",
    "    pt_density_list = [pt_density_laefer_list,pt_density_nyc_list,pt_density_usgs_list]\n",
    "    sd_wall_list = [sd_wall_dist_laefer,sd_wall_dist_nyc,sd_wall_dist_usgs]\n",
    "    \n",
    "    return SampleFlightList, wall_face_list, pt_density_list, sd_wall_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregators\n",
    "pt_density_list= [[],[],[]]\n",
    "sd_wall_list=[[],[],[]]\n",
    "SampleFlightList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other side of the windows\n",
    "middle_pt = np.array([977214.86,174562.64,58.762])\n",
    "right_pt = np.array([977213.577,174561.01,111.614])\n",
    "left_pt = np.array([977217.294, 174565.64, 33.483])\n",
    "bottom_left_pt= np.array([977217.09,174565.64,25.809])\n",
    "top_left_pt = np.array([977217.09,174565.64,115.80])\n",
    "bottom_right_pt = np.array([977213.026,174560.064,25.809])\n",
    "feet_from_pt = 3.5\n",
    "\n",
    "# Right vertical wall\n",
    "square_points_vertical_laefer = pd.read_pickle(\"../../Data/parking_lot/right_wall_vertical_laefer.pkl\")\n",
    "square_points_vertical_nyc = pd.read_pickle(\"../../Data/parking_lot/right_wall_vertical_nyc.pkl\")\n",
    "square_points_vertical_usgs = pd.read_pickle(\"../../Data/parking_lot/right_wall_vertical_usgs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/python-virtual-environments/data/lib/python3.6/site-packages/pandas/core/indexing.py:376: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/home/michael/python-virtual-environments/data/lib/python3.6/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "../point_density_functions.py:446: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "../point_density_functions.py:444: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "../point_density_functions.py:243: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_length: 27.43m\n",
      "v_length: 2.10m\n",
      "Pts in Laefer: 4467\n",
      "Pts in NYC: 52\n",
      "Pts in USGS: 9\n",
      "Vertical face point density over 2500 samples\n",
      "******************************\n",
      "USGS avg density: 0.0120 (SD: 0.0106)\n",
      "NYC avg density: 0.0494 (SD: 0.1484)\n",
      "Laefer avg density: 5.4957 (SD: 0.7609)\n"
     ]
    }
   ],
   "source": [
    "square_points_list = [square_points_vertical_laefer,square_points_vertical_nyc,square_points_vertical_usgs]\n",
    "SampleFlightList, wall_face_list, pt_density_list, sd_wall_list = \\\n",
    "vert_density(square_points_list, \n",
    "                 middle_pt, \n",
    "                 right_pt, \n",
    "                 left_pt, \n",
    "                 bottom_left_pt, \n",
    "                 feet_from_pt,\n",
    "                 SampleFlightList,    \n",
    "                 pt_density_list,\n",
    "                 sd_wall_list\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wall_face_nyc = wall_face_list[2]\n",
    "flight_ids = wall_face_nyc['flight_id'].unique()\n",
    "wall_face_nyc['pts_bins'] = pd.cut((wall_face_nyc['z_scaled']-9)/3.28084, \\\n",
    "                                      bins=range(0,40,3), \\\n",
    "                                      labels=range(3,40,3))\n",
    "\n",
    "for f in flight_ids:\n",
    "    flight_pts = wall_face_nyc[wall_face_nyc['flight_id']==f]\n",
    "    # Num of points\n",
    "    print(\"\\n\\nDensity for flight id {}:\".format(f),flight_pts.groupby('pts_bins')['X'].count()/(3*2.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all wall_face_laefers\n",
    "wall_face_laefer_total = wall_face_list[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer wall (B)\n",
    "middle_pt = np.array([977223.71,174573.7,75.141])\n",
    "right_pt = np.array([977221.44, 174571.037, 68.44])\n",
    "left_pt = np.array([977226.47, 174577.23, 36.958])\n",
    "bottom_left_pt = np.array([977225.752, 174576.37, 25.393])\n",
    "top_left_pt = np.array([977225.752, 174576.37, 117.937])\n",
    "bottom_right_pt = np.array([977221.605,174571.074,25.393])\n",
    "feet_from_pt = 3.5\n",
    "\n",
    "# Left vertical wall\n",
    "square_points_vertical_laefer = pd.read_pickle(\"../../Data/parking_lot/left_wall_vertical_laefer.pkl\")\n",
    "square_points_vertical_nyc = pd.read_pickle(\"../../Data/parking_lot/left_wall_vertical_nyc.pkl\")\n",
    "square_points_vertical_usgs = pd.read_pickle(\"../../Data/parking_lot/left_wall_vertical_usgs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "square_points_list = [square_points_vertical_laefer,square_points_vertical_nyc,square_points_vertical_usgs]\n",
    "SampleFlightList, wall_face_list, pt_density_list, sd_wall_list = \\\n",
    "vert_density(square_points_list, \n",
    "                 middle_pt, \n",
    "                 right_pt, \n",
    "                 left_pt, \n",
    "                 bottom_left_pt, \n",
    "                 feet_from_pt,\n",
    "                 SampleFlightList,  \n",
    "                 pt_density_list,\n",
    "                 sd_wall_list\n",
    "                 )\n",
    "\n",
    "# Append wall_face to wall_face_laefer_total\n",
    "wall_face_laefer_total = wall_face_laefer_total.append(wall_face_list[0])\n",
    "wall_face_laefer_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_face_nyc = wall_face_list[2]\n",
    "flight_ids = wall_face_nyc['flight_id'].unique()\n",
    "wall_face_nyc['pts_bins'] = pd.cut((wall_face_nyc['z_scaled']-9)/3.28084, \\\n",
    "                                      bins=range(0,40,3), \\\n",
    "                                      labels=range(3,40,3))\n",
    "\n",
    "for f in flight_ids:\n",
    "    flight_pts = wall_face_nyc[wall_face_nyc['flight_id']==f]\n",
    "    # Num of points\n",
    "    print(\"\\n\\nDensity for flight id {}:\".format(f),flight_pts.groupby('pts_bins')['X'].count()/(3*2.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wall at other end of Army Terminal Bldg (C)\n",
    "middle_pt = np.array([976665.066,173867.613,75.54])\n",
    "right_pt = np.array([976663.22,173865.13,28.945])\n",
    "left_pt = np.array([976666.636,173869.511,54.121])\n",
    "bottom_left_pt= np.array([976665.002991,173867.726,13.903])\n",
    "top_left_pt = np.array([976665.002991,173867.726,110.903])\n",
    "bottom_right_pt = np.array([976662.514,173864.906,15.875])\n",
    "\n",
    "feet_from_pt = 3.5\n",
    "\n",
    "square_points_vertical_laefer = pd.read_pickle(\"../../Data/parking_lot/wall_c_laefer.pkl\")\n",
    "square_points_vertical_nyc = pd.read_pickle(\"../../Data/parking_lot/wall_c_nyc.pkl\")\n",
    "square_points_vertical_usgs = pd.read_pickle(\"../../Data/parking_lot/wall_c_usgs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_points_list = [square_points_vertical_laefer,square_points_vertical_nyc,square_points_vertical_usgs]\n",
    "SampleFlightList, wall_face_list, pt_density_list, sd_wall_list = \\\n",
    "vert_density(square_points_list, \n",
    "                 middle_pt, \n",
    "                 right_pt, \n",
    "                 left_pt, \n",
    "                 bottom_left_pt, \n",
    "                 feet_from_pt,\n",
    "                 SampleFlightList,      \n",
    "                 pt_density_list,\n",
    "                 sd_wall_list\n",
    "                 )\n",
    "# Append wall_face to wall_face_laefer_total\n",
    "wall_face_laefer_total = wall_face_laefer_total.append(wall_face_list[0])\n",
    "wall_face_laefer_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_face_nyc = wall_face_list[2]\n",
    "flight_ids = wall_face_nyc['flight_id'].unique()\n",
    "wall_face_nyc['pts_bins'] = pd.cut((wall_face_nyc['z_scaled']-9)/3.28084, \\\n",
    "                                      bins=range(0,40,3), \\\n",
    "                                      labels=range(3,40,3))\n",
    "\n",
    "for f in flight_ids:\n",
    "    flight_pts = wall_face_nyc[wall_face_nyc['flight_id']==f]\n",
    "    # Num of points\n",
    "    print(\"\\n\\nDensity for flight id {}:\".format(f),flight_pts.groupby('pts_bins')['X'].count()/(3*1.29))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wall in middle of Army Terminal Bldg (D)\n",
    "middle_pt = np.array([976763.544,173992.004,23.858])\n",
    "right_pt = np.array([976762.356,173990.422,101.224])\n",
    "left_pt = np.array([976765.87,173994.878,87.094])\n",
    "bottom_left_pt= np.array([976765.87,173994.878,13.9])\n",
    "top_left_pt = np.array([976765.87,173994.878,110.9])\n",
    "bottom_right_pt = np.array([976762.356,173990.422,13.9])\n",
    "\n",
    "feet_from_pt = 3.5/2\n",
    "\n",
    "square_points_vertical_laefer = pd.read_pickle(\"../../Data/parking_lot/wall_d_laefer.pkl\")\n",
    "square_points_vertical_nyc = pd.read_pickle(\"../../Data/parking_lot/wall_d_nyc.pkl\")\n",
    "square_points_vertical_usgs = pd.read_pickle(\"../../Data/parking_lot/wall_d_usgs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_points_list = [square_points_vertical_laefer,square_points_vertical_nyc,square_points_vertical_usgs]\n",
    "SampleFlightList, wall_face_list, pt_density_list, sd_wall_list = \\\n",
    "vert_density(square_points_list, \n",
    "                 middle_pt, \n",
    "                 right_pt, \n",
    "                 left_pt, \n",
    "                 bottom_left_pt, \n",
    "                 feet_from_pt,\n",
    "                 SampleFlightList,  \n",
    "                 pt_density_list,\n",
    "                 sd_wall_list\n",
    "                 )\n",
    "# Append wall_face to wall_face_laefer_total\n",
    "wall_face_laefer_total = wall_face_laefer_total.append(wall_face_list[0])\n",
    "wall_face_laefer_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_face_nyc = wall_face_list[2]\n",
    "flight_ids = wall_face_nyc['flight_id'].unique()\n",
    "wall_face_nyc['pts_bins'] = pd.cut((wall_face_nyc['z_scaled']-9)/3.28084, \\\n",
    "                                      bins=range(0,40,3), \\\n",
    "                                      labels=range(3,40,3))\n",
    "\n",
    "for f in flight_ids:\n",
    "    flight_pts = wall_face_nyc[wall_face_nyc['flight_id']==f]\n",
    "    # Num of points\n",
    "    print(\"\\n\\nDensity for flight id {}:\".format(f),flight_pts.groupby('pts_bins')['X'].count()/(3*1.73))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# South wall!  For vertical density of NYC\n",
    "middle_pt = np.array([976617.27,173802.86,58])\n",
    "right_pt = np.array([976620.67,173800.14,50])\n",
    "left_pt = np.array([976615.24,173804.53,62])\n",
    "bottom_left_pt = np.array([976615.24,173804.53,21.98])\n",
    "top_left_pt = np.array([976615.24,173804.53,115])\n",
    "bottom_right_pt = np.array([976620.67,173800.14,21.98])\n",
    "feet_from_pt = 3.5/2\n",
    "\n",
    "square_points_vertical_laefer = pd.read_pickle(\"../../Data/parking_lot/south_outer_wall_vertical_laefer.pkl\")\n",
    "square_points_vertical_nyc = pd.read_pickle(\"../../Data/parking_lot/south_outer_wall_vertical_nyc.pkl\")\n",
    "square_points_vertical_usgs = pd.read_pickle(\"../../Data/parking_lot/south_outer_wall_vertical_usgs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_points_list = [square_points_vertical_laefer,square_points_vertical_nyc,square_points_vertical_usgs]\n",
    "SampleFlightList, wall_face_list, pt_density_list, sd_wall_list = \\\n",
    "vert_density(square_points_list, \n",
    "                 middle_pt, \n",
    "                 right_pt, \n",
    "                 left_pt, \n",
    "                 bottom_left_pt, \n",
    "                 feet_from_pt,\n",
    "                 SampleFlightList,  \n",
    "                 pt_density_list,\n",
    "                 sd_wall_list\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wall density for NYC flight pass\n",
    "wall_face_nyc = wall_face_list[1]\n",
    "flight_ids = ['181004','180819']\n",
    "wall_face_nyc['pts_bins'] = pd.cut((wall_face_nyc['z_scaled']-9)/3.28084, \\\n",
    "                                      bins=range(0,40,3), \\\n",
    "                                      labels=range(3,40,3))\n",
    "\n",
    "for f in wall_face_nyc['flight_id'].unique():\n",
    "    flight_pts = wall_face_nyc[wall_face_nyc['flight_id']==f]\n",
    "    # Num of points\n",
    "    print(\"\\n\\nDensity for flight id {}:\".format(f),flight_pts.groupby('pts_bins')['X'].count()/(3*2.13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wall_face_nyc = wall_face_list[1]\n",
    "plt.plot(wall_face_list[0]['x_scaled'],wall_face_list[0]['z_scaled'],'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_flight_paths_laefer = []\n",
    "for flight in SampleFlightList:\n",
    "    try:\n",
    "        avg_flight_paths_laefer.append(len(flight.flight_list_laefer)-2)\n",
    "    except AttributeError:\n",
    "        avg_flight_paths_laefer.append(0)\n",
    "\n",
    "print(\"Avg number of flight paths per square: {:2.2f}\".format(np.mean(avg_flight_paths_laefer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cw = []\n",
    "for flight in SampleFlightList:\n",
    "    try:\n",
    "        cw.append(flight.error_decomp_laefer)\n",
    "    except AttributeError:\n",
    "        print(\"Missing\")\n",
    "#     cw_df = pd.DataFrame(cw,columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "    cw_df = pd.DataFrame(cw,columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "\n",
    "(cw_df/3.28084).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Distance from plane\\n\"+\"*\"*30)\n",
    "print(\"2019: {:2.4f} (SD: {:2.4f})\".format(np.mean([ss.delta_h_mean_laefer for ss in SampleFlightList]),np.mean([ss.delta_h_sd_laefer for ss in SampleFlightList])))\n",
    "# print(\"2017: {:2.4f} (SD: {:2.4f})\".format(np.mean([ss.delta_h_mean_nyc for ss in SampleFlightList]),np.mean([ss.delta_h_sd_nyc for ss in SampleFlightList])))\n",
    "# print(\"2014: {:2.4f} (SD: {:2.4f})\".format(np.mean([ss.delta_h_mean_usgs for ss in SampleFlightList]),np.mean([ss.delta_h_sd_usgs for ss in SampleFlightList])))\n",
    "\n",
    "print(\"\\nCosine Similarity\\n\"+\"*\"*30)\n",
    "print(\"{:2.4f}\".format(np.mean([np.mean(ss.cosine_sim_matrix_laefer) for ss in SampleFlightList])))\n",
    "# print(\"{:2.4f}\".format(np.mean([np.mean(ss.cosine_sim_matrix_nyc) for ss in SampleFlightList])))\n",
    "# print(\"{:2.4f}\".format(np.mean([np.mean(ss.cosine_sim_matrix_usgs) for ss in SampleFlightList])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df2 = pd.read_pickle(\"../../accuracy_data/vertical_cw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cw_df2).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laefer\n",
    "sd_laefer_total = np.mean([ss.flight_list_laefer[0].sd_dist for ss in SampleFlightList])\n",
    "sd_laefer_sample = np.mean([ss.flight_list_laefer[1].sd_dist for ss in SampleFlightList])\n",
    "avg_flight_paths_laefer = np.mean([len(flight.flight_list_laefer) for flight in SampleFlightList])-2\n",
    "\n",
    "phis_laefer_total = [ss.phi_laefer_total for ss in SampleFlightList]\n",
    "phis_laefer_sample = [ss.phi_laefer_sample for ss in SampleFlightList]\n",
    "\n",
    "print(\"2019 scan (Vertical, {:d} samples)\\n\".format(len(pt_density_laefer_list))+\"*\"*30)\n",
    "print(\"Avg points per square: {:2.2f} points\".format((3.5*14)*np.mean(pt_density_laefer_list)))\n",
    "print(\"Avg density: {:2.4f} pts/sqft (SD: {:2.4f})\".format(np.mean(pt_density_laefer_list),np.std(pt_density_laefer_list)))\n",
    "print(\"Avg number of flight paths per square: {:2.2f}\".format(avg_flight_paths_laefer))\n",
    "\n",
    "print(\"\\nphi_total: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_laefer_total),np.std(phis_laefer_total)))\n",
    "print(\"phi_sample: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_laefer_sample),np.std(phis_laefer_total)))\n",
    "print(\"\\nTotal point dist from plane, SD: {:2.4f} feet\".format(sd_laefer_total))\n",
    "print(\"Avg flight point dist from plane, SD: {:2.4f} feet\".format(sd_laefer_total/np.mean(phis_laefer_total)))\n",
    "\n",
    "# phis_nyc_total = [ss.phi_nyc_total for ss in SampleFlightList]\n",
    "# phis_nyc_sample = [ss.phi_nyc_sample for ss in SampleFlightList]\n",
    "\n",
    "# sd_nyc_total = np.mean([ss.flight_list_nyc[0].sd_dist for ss in SampleFlightList])\n",
    "# sd_nyc_sample = np.mean([ss.flight_list_nyc[1].sd_dist for ss in SampleFlightList])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(SampleFlightList[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass_count = []\n",
    "# for flight in SampleFlightList:\n",
    "#     try:\n",
    "#         pass_count.append(len(flight.flight_list_nyc)-2)\n",
    "#     except AttributeError:\n",
    "#         pass_count.append(0)\n",
    "# print(\"NYC Mean Flight passes: {:2.4f}\".format(np.mean(pass_count)))\n",
    "# pass_arr = np.array(pass_count)\n",
    "# print(\"Mean Non-Zero Flight passes: {:2.4f}\".format(np.mean(pass_arr[pass_arr>0])))\n",
    "\n",
    "\n",
    "# pass_count = []\n",
    "# for flight in SampleFlightList:\n",
    "#     try:\n",
    "#         pass_count.append(len(flight.flight_list_usgs)-2)\n",
    "#     except AttributeError:\n",
    "#         pass_count.append(0)\n",
    "\n",
    "# print(\"USGS Mean Flight passes: {:2.4f}\".format(np.mean(pass_count)))\n",
    "# pass_arr = np.array(pass_count)\n",
    "# print(\"Mean Non-Zero Flight passes: {:2.4f}\".format(np.mean(pass_arr[pass_arr>0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing points by scan angle\n",
    "\n",
    "Count the missing scan points based on scan angle between consecutive points.  Goal is to 1) compare the % of missing points for horizontal vs vertical surfaces, and 2) compare the % of missing points at different wall heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_face_list[0].to_pickle(\"../../Data/parking_lot/wall_points_laefer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pull_first_scan_gap(wall_face_laefer):\n",
    "    # Separate return num, only keep the first returns, add scan_gap, sort\n",
    "    wall_face_laefer['num_returns'] = np.floor(wall_face_laefer['flag_byte']/16).astype(int)\n",
    "    wall_face_laefer['return_num'] = wall_face_laefer['flag_byte']%16\n",
    "    first_return_wall = wall_face_laefer[wall_face_laefer['return_num']==1]\n",
    "    first_return_wall.sort_values(by=['gps_time'],inplace=True)\n",
    "    first_return_wall.reset_index(inplace=True)\n",
    "    first_return_wall.loc[1:,'scan_gap'] = [first_return_wall.loc[i+1,'scan_angle'] - first_return_wall.loc[i,'scan_angle'] for i in range(first_return_wall.shape[0]-1)]\n",
    "    first_return_wall.loc[0,'scan_gap'] = 0\n",
    "    return first_return_wall\n",
    "\n",
    "# Wall\n",
    "wall_face_laefer = wall_face_list[0]\n",
    "first_return_wall = pull_first_scan_gap(wall_face_laefer)\n",
    "# Rectangle\n",
    "rectangle_face_laefer = pd.read_pickle(file_dir+\"rectangle_points_laefer.pkl\")\n",
    "first_return_rectangle = pull_first_scan_gap(rectangle_face_laefer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan gap of -4,-5,-6 is normal, -10,-11,-15 are a missed point\n",
    "w = pd.DataFrame(first_return_rectangle['scan_gap'].value_counts())\n",
    "w.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan gap of -4,-5,-6 is normal, -10,-11,-15 are a missed point\n",
    "w = pd.DataFrame(first_return_wall[first_return_wall['flight_id']=='180819']['scan_gap'].value_counts())\n",
    "w.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the wall height into bins, compare % missing points at different heights\n",
    "\n",
    "first_return_wall['pts_bins'] = pd.cut((first_return_wall['z_scaled']-9)/3.28084, \\\n",
    "                                       bins=range(0,40,3),labels=range(3,40,3))\n",
    "\n",
    "first_return_wall['missed_point'] = np.zeros(first_return_wall.shape[0])\n",
    "first_return_wall['good_point'] = np.zeros(first_return_wall.shape[0])\n",
    "for index, row in first_return_wall.iterrows():\n",
    "    if (row['scan_gap'] >-17) & (row['scan_gap']< -6):\n",
    "        first_return_wall.loc[index,'missed_point']=1\n",
    "    if (row['scan_gap'] <-1) & (row['scan_gap'] > -7):\n",
    "        first_return_wall.loc[index,'good_point']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_return_wall[first_return_wall['z_scaled']<18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = first_return_wall[first_return_wall['flight_id']=='181004'].groupby('pts_bins').mean()\n",
    "a = first_return_wall.groupby('pts_bins').mean()\n",
    "\n",
    "a['miss_pct'] = a['missed_point']/a['good_point']\n",
    "a['miss_pct'][:-2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['miss_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(list(a['miss_pct'][:-2]),list(a['miss_pct'][:-2].index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intensity up and down the wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/python-virtual-environments/data/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wall_face_laefer = wall_face_list[0]\n",
    "flight_ids = ['181004','180819']\n",
    "wall_face_laefer['pts_bins'] = pd.cut((wall_face_laefer['z_scaled']-9)/3.28084,bins=range(0,40,3),labels=range(3,40,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1814.2668457577793"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wall_face_laefer['intensity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (979, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pts_bins\n",
       "3     1793.416667\n",
       "6     1886.800000\n",
       "9     1839.164948\n",
       "12    1830.783505\n",
       "15    1858.752475\n",
       "18    1927.020000\n",
       "21    1941.323810\n",
       "24    1965.550459\n",
       "27    1972.009615\n",
       "30    1869.527778\n",
       "33    1851.037037\n",
       "36            NaN\n",
       "39            NaN\n",
       "Name: intensity, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_pts = wall_face_laefer[wall_face_laefer['flight_id']==flight_ids[1]]\n",
    "print(\"shape\",flight_pts.shape)\n",
    "flight_pts.groupby('pts_bins')['intensity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intensity on the parking lot horizontal surface\n",
    "rectangle_points_laefer = pd.read_pickle(file_dir+\"rectangle_points_laefer.pkl\")\n",
    "rectangle_points_laefer[rectangle_points_laefer['flight_id']=='181004']['intensity'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density up and down the wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wall_face_laefer = wall_face_list[0]\n",
    "plt.figure(figsize=[20,22])\n",
    "for i,fid in enumerate(wall_face_laefer['flight_id'].unique()):\n",
    "    plt.subplot(4,3,i+1)\n",
    "    pts = wall_face_laefer[wall_face_laefer['flight_id']==fid]\n",
    "    hist = pd.cut(wall_face_laefer[wall_face_laefer['flight_id']==fid]['z_scaled'],bins=range(0,120,5),labels=range(5,120,5))\n",
    "#     plt.hist(hist,orientation='horizontal')\n",
    "    plt.plot(range(pts.shape[0]),pts['z_scaled']/3.28084,'x')\n",
    "    plt.yticks(np.arange(0,36,3))\n",
    "    plt.ylabel(\"Wall height (m)\")\n",
    "    plt.xlabel(\"Point number (not spatial)\")\n",
    "    plt.title(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_ids = ['181004','180819','164445','180632']\n",
    "pts_fid = wall_face_laefer[wall_face_laefer['flight_id']==flight_ids[1]]['z_scaled'].copy()\n",
    "pts_fid = pts_fid/3.28084\n",
    "pts_bins = pd.cut(pts_fid,bins=range(15,36,3),labels=range(18,36,3))\n",
    "pts_density = pts_bins.value_counts()/(3*(6.899845795386761/3.28084))\n",
    "pts_density.sort_index(inplace=True)\n",
    "plt.plot(pts_density,range(18,36,3),'-o')\n",
    "plt.xlabel(\"Vertical Density (pts/m^2)\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.ylabel(\"Height on wall (m)\",fontsize=15)\n",
    "plt.yticks(fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_fid = wall_face_laefer['z_scaled'].copy()\n",
    "pts_fid = pts_fid/3.28084\n",
    "pts_bins = pd.cut(pts_fid,bins=[0,16,32],labels=('low','high'))\n",
    "pts_density = pts_bins.value_counts()/(1*(6.899845795386761/3.28084))\n",
    "pts_density.sort_index(inplace=True)\n",
    "plt.bar(['low','high'],pts_density)\n",
    "plt.xlabel(\"Vertical Density (pts/m^2)\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.ylabel(\"Height on wall (m)\",fontsize=15)\n",
    "plt.yticks(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_fid = wall_face_laefer['z_scaled'].copy()\n",
    "pts_fid = pts_fid/3.28084\n",
    "pts_bins = pd.cut(pts_fid,bins=range(9,36,3),labels=range(12,36,3))\n",
    "pts_density = pts_bins.value_counts()/(2*(14.899845795386761/3.28084))\n",
    "pts_density.sort_index(inplace=True)\n",
    "plt.plot(pts_density,range(12,36,3),'-o')\n",
    "plt.xlabel(\"Vertical Density (pts/m^2)\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.ylabel(\"Height on wall (m)\",fontsize=15)\n",
    "plt.yticks(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy up the wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_fid = [sf.z for sf in SampleFlightList]\n",
    "pts_fid = [pt/3.28084 for pt in pts_fid]\n",
    "pts_bins = pd.cut(pts_fid,bins=range(8,36,2),labels=range(10,36,2))\n",
    "\n",
    "# Create acc_df Dataframe of accuracy and height bins for a specific flight id\n",
    "# acc_df = pd.DataFrame([ss.flight_list_laefer[0].sd_dist for ss in SampleFlightList],columns=['total_rmse'])\n",
    "acc_df = pd.DataFrame(pts_bins,columns=['bin'])\n",
    "\n",
    "acc_df['z'] = pts_fid\n",
    "# plt.plot(acc_df[acc_df['bin']==30]['z'])\n",
    "\n",
    "# Flight id specific accuracy\n",
    "fid = '181004' # Farther away \n",
    "# fid = '180819' # About 100m away\n",
    "acc_list = []\n",
    "for j in SampleFlightList:\n",
    "    dd = {j.flight_list_laefer[i].flight_id:i for i in range(len(j.flight_list_laefer))}\n",
    "    ix = dd[fid]\n",
    "    acc_list.append(j.flight_list_laefer[ix].sd_dist/3.28084)\n",
    "len(acc_list)\n",
    "\n",
    "acc_df['fid_rmse'] = acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(np.arange(12-3,33-3,2),acc_df.groupby('bin')['fid_rmse'].mean().iloc[1:-1])\n",
    "plt.ylabel(\"Wall Height (m)\")\n",
    "plt.xlabel(\"Single Flight RMSE (m)\")\n",
    "plt.title(\"Flight ID: \"+str(fid))\n",
    "print(acc_df['bin'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(np.arange(12-3,33-3,2),acc_df.groupby('bin')['fid_rmse'].mean().iloc[1:-1])\n",
    "plt.ylabel(\"Wall Height (m)\")\n",
    "plt.xlabel(\"Single Flight RMSE (m)\")\n",
    "plt.title(\"Flight ID: \"+str(fid))\n",
    "print(acc_df['bin'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract points within a square around the desired point\n",
    "\n",
    "# Parking Lot\n",
    "# pt_x = 977037.343\n",
    "# pt_y = 174586.034\n",
    "\n",
    "# Corner of building\n",
    "# pt_x_bldg = 977229.375\n",
    "# pt_y_bldg = 174579.42\n",
    "\n",
    "# Top of building\n",
    "# pt_x = 977229.375\n",
    "# pt_y = 174579.42\n",
    "\n",
    "# Projects in back parking lot\n",
    "# pt_x = 977458.238\n",
    "# pt_y = 173302.388\n",
    "\n",
    "# Solar panel\n",
    "# pt_x = 977682.975\n",
    "# pt_y = 174148.192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers and print the count: z < 0, z > 30\n",
    "def remove_vertical_outliers(rectangle_points,z_low,z_high):\n",
    "    outliers = rectangle_points[(rectangle_points['z_scaled']<z_low) | (rectangle_points['z_scaled']>z_high)].index\n",
    "    rectangle_points = rectangle_points.drop(outliers)\n",
    "    print(\"Number of outliers: {}\".format(len(outliers)))\n",
    "    return rectangle_points\n",
    "# rectangle_points_laefer = remove_vertical_outliers(rectangle_points_laefer,0,30)\n",
    "# rectangle_points_nyc = remove_vertical_outliers(rectangle_points_nyc,0,30)\n",
    "# rectangle_points_usgs = remove_vertical_outliers(rectangle_points_usgs,0,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(square_points_bldg, x='x_plot', y='y_plot', z='z_plot',\n",
    "              size='size_num',size_max = 12)\n",
    "\n",
    "fig.update_layout( \n",
    "    scene = dict(xaxis = dict(title=\"Easting (feet)\"),\n",
    "                 yaxis = dict(title=\"Northing (feet)\"),\n",
    "                 zaxis = dict(title=\"Vertical (feet)\"),\n",
    "                ),\n",
    "    width=900,\n",
    "    height=900,\n",
    "    margin=dict(r=20, l=10, b=10, t=10),\n",
    "    showlegend=False,\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(square_points_nyc, x='x_plot', y='y_plot', z='z_plot',\n",
    "              size='size_num',size_max = 12)\n",
    "\n",
    "fig.update_layout( \n",
    "    scene = dict(xaxis = dict(title=\"Easting (feet)\"),\n",
    "                 yaxis = dict(title=\"Northing (feet)\"),\n",
    "                 zaxis = dict(title=\"Vertical (feet)\"),\n",
    "                ),\n",
    "    width=900,\n",
    "    height=900,\n",
    "    margin=dict(r=20, l=10, b=10, t=10),\n",
    "    showlegend=False,\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the wall face, find normal vector, calculate vertical density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_1 = np.array([37.7,10.04])\n",
    "pt_2 = np.array([27.094,18.439])\n",
    "wall_pt = (31.77,14.90,43.00)\n",
    "\n",
    "# East? Facing Wall (farther from the little stump)\n",
    "# pt_1 = np.array([20.59,15.02])\n",
    "# pt_2 = np.array([10.34,2.93])\n",
    "# wall_pt = (19.414,12.379,73.863)\n",
    "\n",
    "wall_face = grab_wall_face(square_points_bldg,pt_1,pt_2,20,100,1e-2)\n",
    "wall_face_nyc = grab_wall_face(square_points_nyc,pt_1,pt_2,20,100,5e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wall_face.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_face_nyc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vector,points,wall_face,pts_on_plane = plane_fit(wall_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_vector)\n",
    "print(norm_vector_nyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vector_nyc,points,wall_face_nyc,pts_on_plane_nyc = plane_fit(wall_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(wall_face, x='x_plot', y='y_plot', z='z_plot',\n",
    "              color='flight_id',size='size_num',size_max = 12)\n",
    "\n",
    "fig.update_layout( \n",
    "    scene = dict(xaxis = dict(title=\"Easting (feet)\"),\n",
    "                 yaxis = dict(title=\"Northing (feet)\"),\n",
    "                 zaxis = dict(title=\"Vertical (feet)\"),\n",
    "                ),\n",
    "    width=900,\n",
    "    height=900,\n",
    "    margin=dict(r=20, l=10, b=10, t=10),\n",
    "    showlegend=False,\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point in middle of wall - in xyz_plot coordinates (less the min of each coordinate)\n",
    "# It's best to highlight a point in the plot above and use that.\n",
    "\n",
    "feet_from_pt = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate density for both datasets   \n",
    "vertical_point_density(square_points_nyc,norm_vector_nyc,wall_pt,feet_from_pt)\n",
    "vertical_point_density(square_points_bldg,norm_vector,wall_pt,feet_from_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(vertical_square, x='x_plot', y='y_plot', z='z_plot',\n",
    "              color='flight_id', size='size_num',size_max = 8)\n",
    "\n",
    "fig.update_layout( \n",
    "    scene = dict(xaxis = dict(title=\"Easting (feet)\"),\n",
    "                 yaxis = dict(title=\"Northing (feet)\"),\n",
    "                 zaxis = dict(title=\"Vertical (feet)\"),\n",
    "                ),\n",
    "    width=900,\n",
    "    height=900,\n",
    "    margin=dict(r=20, l=10, b=10, t=10),\n",
    "    showlegend=False,\n",
    "    xaxis = {\"title\":{\"text\":\"Cat\"}})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing LAS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write square_points_bldg to file\n",
    "inFile = File(file_dir+'10552_NYU_M2 - Scanner 1 - 190511_164039_1 - originalpoints.laz', mode='r')\n",
    "# Convert DF into tuples that laspy wants\n",
    "void = [(tuple(r[columns_point_cloud]),) for i,r in square_points_laefer.iterrows()]\n",
    "# Export\n",
    "outFile1 = File(\"../../Data/parking_lot/flat_parking_lot_laefer.las\", mode = \"w\",header = inFile.header)\n",
    "outFile1.points = void\n",
    "outFile1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYC data\n",
    "# Write square_points_bldg to file\n",
    "inFile_nyc = File(nyc_file_dir+'975172.las', mode='r')\n",
    "# Convert DF into tuples that laspy wants\n",
    "void = [(tuple(r[columns_point_cloud]),) for i,r in square_points_nyc.iterrows()]\n",
    "# Export\n",
    "outFile1 = File(\"../../Data/parking_lot/flat_parking_lot_nyc.las\", mode = \"w\",header = inFile.header)\n",
    "outFile1.points = void\n",
    "outFile1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting charts from previous updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vector,points,square_points,_ = plane_fit(square_points)\n",
    "\n",
    "# Add distance from flat plane with norm (x,y,z) = (0,0,1)\n",
    "square_points['dist_from_flat']=np.array([np.dot(point,np.array([0,0,1])) for point in points])\n",
    "\n",
    "# remove data points >5 feet below plane.\n",
    "outliers = square_points[square_points['dist_from_plane']<-5].index\n",
    "square_points = square_points.drop(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scan_angle_dist_from_plane(df,distance_metric):\n",
    "    x = abs(df['scan_angle'])*.006\n",
    "    y = df[distance_metric]\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.plot(x,y,'xb')\n",
    "    z = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(x,p(x),\"r--\")\n",
    "    plt.xlabel(\"Scan angle (degrees)\")\n",
    "    plt.ylabel(\"Point distance from plane\")\n",
    "    print(\"y={:2.8f}x+{:2.8f}\".format(z[0],z[1]))\n",
    "    plt.title(\"Scan Angle vs Distance to Fitted Plane\")\n",
    "plot_scan_angle_dist_from_plane(square_points,'dist_from_plane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(square_points)),square_points['scan_angle'],'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scan_angle_dist_from_plane(square_points,'dist_from_flat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart from slides showing points per run\n",
    "labels = [pt[0][11:-4] for pt in pts_from_scan]\n",
    "num_points = [pt[1]+.01 for pt in pts_from_scan]\n",
    "plt.figure(figsize=(25,20))\n",
    "plt.bar(labels,num_points,)\n",
    "plt.xticks(rotation=45,fontsize=20)\n",
    "plt.yticks(np.arange(0, max(num_points), step=(max(num_points)/10)),fontsize=20)\n",
    "plt.ylabel(\"Number of points from run\",fontsize=20)\n",
    "plt.xlabel(\"Run ID\",fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USGS: Converting Lat-Lon and adding flight id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting lat-lon to state plane\n",
    "from pyproj import Proj, transform\n",
    "y1 = np.array(usgs_square_points['x_scaled'])\n",
    "x1 = np.array(usgs_square_points['y_scaled'])\n",
    "inProj = Proj('epsg:4269')\n",
    "outProj = Proj('epsg:3628')\n",
    "x2,y2 = transform(inProj,outProj,x1,y1)\n",
    "usgs_square_points['latitude'] = usgs_square_points['y_scaled'].copy()\n",
    "usgs_square_points['longitude'] = usgs_square_points['x_scaled'].copy()\n",
    "usgs_square_points['x_scaled'] = x2\n",
    "usgs_square_points['y_scaled'] = y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_hdf(\"../../Data/parking_lot/las_points_180819.lz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['intensity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1:,'scan_gap'] = [df.loc[i+1,'scan_angle'] - df.loc[i,'scan_angle'] for i in range(df.shape[0]-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:1000000,'return_num'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df['num_returns'] = np.floor(df['flag_byte']/16).astype(int)\n",
    "df['return_num'] = df['flag_byte']%16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
