{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling and Analysis - Dublin\n",
    "This file is a replica of point_density, but considers sample surfaces in the Dublin dataset.  \n",
    "\n",
    "This notebook performs the central sampling and analysis of the paper. For each sample surface (defined by a set of xyz coordinates on the plane), the notebook generates the desired number of sample squares, collects the points in that square, generates the desired statistics, and aggregates over all the sample surfaces.  Most of the functions utilized are from the point_density_functions.py file.  \n",
    "\n",
    "Additional analyses:\n",
    "* Density at different wall heights\n",
    "* Missing points by scan angle, missing points on vertical vs. horizontal surfaces\n",
    "* Figure 12 analysis - mean orthogonal offset by flight pass, which generates the cross-pass error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from laspy.file import File\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0,'..') # So we can import point_density_functions from parent directory\n",
    "from point_density_functions import *\n",
    "%load_ext autoreload\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dublin tile\n",
    "file_dir = '../../Data/dublin_sample/'\n",
    "# filename = 'bank_of_ireland.las'\n",
    "filename = 'dublin_horizontal.las'\n",
    "pt_files_vertical = ['las_points_bank_of_ireland.lz']\n",
    "                    \n",
    "\n",
    "\n",
    "# Corresponds to LAS 1.2 Point Data Record Format 1\n",
    "columns_dublin_pt_cloud = [\n",
    "    'X',\n",
    "    'Y',\n",
    "    'Z',\n",
    "    'intensity',\n",
    "    'return_number_byte',\n",
    "    'classification_byte',\n",
    "    'scan_angle',\n",
    "    'user_data',\n",
    "    'pt_src_id',\n",
    "    'gps_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works\n",
    "# for file in filenames:\n",
    "#     create_df_hd5(file_dir,file,columns_dublin_pt_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the lz file\n",
    "# bank_df = pd.read_hdf(file_dir+'las_points_bank_of_ireland.lz')\n",
    "# horiz_df = pd.read_hdf(file_dir+'las_points_dublin_horizontal.lz')\n",
    "# horiz_df = pd.read_hdf(file_dir+'las_points_dublin_horizontal.lz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(SampleFlightList,pt_density_laefer_list,feet_from_point):\n",
    "    # Laefer\n",
    "    sd_laefer_total = np.mean([ss.flight_list_laefer[0].sd_dist for ss in SampleFlightList])\n",
    "    sd_laefer_sample = np.mean([ss.flight_list_laefer[1].sd_dist for ss in SampleFlightList])\n",
    "    avg_flight_paths_laefer = np.mean([len(flight.flight_list_laefer) for flight in SampleFlightList])-2\n",
    "    sd_flight_paths_laefer = np.std([len(flight.flight_list_laefer) for flight in SampleFlightList])\n",
    "    phis_laefer_total = [ss.phi_laefer_total for ss in SampleFlightList]\n",
    "    phis_laefer_sample = [ss.phi_laefer_sample for ss in SampleFlightList]\n",
    "\n",
    "    print(\"2019 scan (Horizontal, {} samples): \\n\".format(len(SampleFlightList))+\"*\"*30)\n",
    "    print(\"Avg points per square: {:2.2f} points\".format((4 * feet_from_point**2)*np.mean(pt_density_laefer_list)))\n",
    "    print(\"Avg density: {:2.4f} pts/m^2 (SD: {:2.4f})\".format(np.mean(pt_density_laefer_list),np.std(pt_density_laefer_list)))\n",
    "    print(\"Avg number of flight paths per square: {:2.4f} (SD: {:2.4f})\".format(avg_flight_paths_laefer,sd_flight_paths_laefer))\n",
    "    print(\"\\nphi_total: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_laefer_total),np.std(phis_laefer_total)))\n",
    "    print(\"phi_sample: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_laefer_sample),np.std(phis_laefer_sample)))\n",
    "    print(\"Total point dist from plane, SD: {:2.4f} m\".format(sd_laefer_total))\n",
    "    print(\"Avg flight point dist from plane, SD: {:2.4f} m\".format(sd_laefer_total/np.mean(phis_laefer_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling squares and Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal Density\n",
    "The section below iterates through the sample surfaces, generating sample squares, generating density/accuracy statistics for each, and gathering the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregators - collect sample squares across multiple sample areas\n",
    "pt_density_list = []\n",
    "avg_height_diff = []\n",
    "sd_height = []\n",
    "SampleFlightList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_files_horizontal = ['las_points_leinster_house_lot_1.lz', \\\n",
    "                       'las_points_leinster_house_lot_2.lz', \\\n",
    "                       'las_points_stephensgreen_walking.lz', \\\n",
    "                       'las_points_city_hall_square.lz'\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Horizontal - City Hall Square\n",
    "pt1 = np.array([315483.8333,234007.297119,6.139])\n",
    "pt2 = np.array([315481.253052,234021.491943,6.034])\n",
    "u_length = np.linalg.norm(pt2-pt1) # ~14.1m\n",
    "v_length = 14\n",
    "pt3 = np.array([3.15497605e+05, 2.34009799e+05, 5.87147628e+00]) # Backed into from previous 2D v calculation\n",
    "uv_inv,w,unit_u,unit_v = rectangle(pt1[:2],pt2[:2],u_length,v_length)\n",
    "\n",
    "rectangle_points = pd.read_hdf(file_dir+pt_files_horizontal[3])\n",
    "rectangle_points = rectangle_points[(rectangle_points['z_scaled']<6.2)& \\\n",
    "                                                  (rectangle_points['z_scaled']>5.7)]\n",
    "\n",
    "rectangle_points['flight_id'] = rectangle_points['pt_src_id']\n",
    "# Norm from any 3 points on plane\n",
    "# a = np.array([315485.316040,234016.809082,6.011])\n",
    "# b = np.array([315483.8333,234007.297119,6.139])\n",
    "# c = np.array([315493.062,234019.477051,5.84700])\n",
    "# norm = np.cross(c - b,(a-b))\n",
    "\n",
    "# bottom_vec = (np.cross(norm,(pt2 - pt1)))/np.linalg.norm(np.cross(norm,(pt2 - pt1)))\n",
    "# bottom_right_pt = pt1 - bottom_vec*v_length\n",
    "# bottom_right_pt\n",
    "print(u_length*v_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create center_points\n",
    "feet_from_point = 0.5\n",
    "border = []\n",
    "border.append(1.05*feet_from_point/u_length)\n",
    "border.append(1.05*feet_from_point/v_length)\n",
    "center_points = center_point_sample(2800,pt1,pt2,pt3,u_length=u_length,v_length=v_length,border=border)\n",
    "mean_z = rectangle_points['z_scaled'].mean()\n",
    "pts_thrown_out = 0\n",
    "\n",
    "for center_point in center_points:\n",
    "    square_points = in_horizontal_square(rectangle_points,center_point[:2],feet_from_point)\n",
    "    \n",
    "    flight_count = len(square_points['flight_id'].unique())\n",
    "   \n",
    "    # If z_max > 6.2, for any point in square skip it\n",
    "    if square_points['z_scaled'].max()<6.2:\n",
    "        # Statistics!\n",
    "                \n",
    "        # Point density\n",
    "        num_points = square_points.shape[0]\n",
    "        pt_density_list.append(num_points / (4 * feet_from_point**2))        \n",
    "        \n",
    "        # Flight path specifics\n",
    "        flight_list = create_flight_list(square_points)\n",
    "        # Create SampleSquare from all flight passes\n",
    "        ss = SampleSquare(flight_list, x = center_point[0], \\\n",
    "                          y=center_point[1],feet_from_point=feet_from_point)\n",
    "        # Collect SampleSquares\n",
    "        SampleFlightList.append(ss)\n",
    "        \n",
    "    else:\n",
    "        pts_thrown_out +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_out(SampleFlightList,pt_density_list,feet_from_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df = pd.DataFrame([flight.error_decomp_laefer for flight in SampleFlightList],columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "\n",
    "cw_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Horizontal - stephensgreen walking\n",
    "pt1 = np.array([315925.706055,233508.467041,11.846])\n",
    "pt2 = np.array([315920.5,233521.358887,11.669])\n",
    "u_length = np.linalg.norm(pt2-pt1) # ~14m\n",
    "v_length = 5\n",
    "pt3 = np.array([3.15930342e+05, 2.33510339e+05, 1.18615851e+01]) # Backed into from previous 2D v calculation\n",
    "uv_inv,w,unit_u,unit_v = rectangle(pt1[:2],pt2[:2],u_length,v_length)\n",
    "\n",
    "rectangle_points = pd.read_hdf(file_dir+pt_files_horizontal[2])\n",
    "\n",
    "rectangle_points['flight_id'] = rectangle_points['pt_src_id']\n",
    "# Norm from any 3 points on plane\n",
    "# a = pt1\n",
    "# b = np.array([315929.901978,233511.337891,11.855])\n",
    "# c = np.array([315924.854004,233518.982910,11.796])\n",
    "# norm = np.cross(c - b,(a-b))\n",
    "\n",
    "# bottom_vec = (np.cross(norm,(pt2 - pt1)))/np.linalg.norm(np.cross(norm,(pt2 - pt1)))\n",
    "# bottom_right_pt = pt1 - bottom_vec*v_length\n",
    "# bottom_right_pt\n",
    "print(u_length*v_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create center_points\n",
    "feet_from_point = 0.5\n",
    "border = []\n",
    "border.append(1.05*feet_from_point/u_length)\n",
    "border.append(1.05*feet_from_point/v_length)\n",
    "center_points = center_point_sample(2500,pt1,pt2,pt3,u_length=u_length,v_length=v_length,border=border)\n",
    "mean_z = rectangle_points['z_scaled'].mean()\n",
    "pts_thrown_out = 0\n",
    "\n",
    "for center_point in center_points:\n",
    "    square_points = in_horizontal_square(rectangle_points,center_point[:2],feet_from_point)\n",
    "    \n",
    "    flight_count = len(square_points['flight_id'].unique())\n",
    "   \n",
    "    # If z_max > 10, <6 for any dataset, skip it\n",
    "    if square_points['z_scaled'].max()<mean_z+1:\n",
    "        # Statistics!\n",
    "                \n",
    "        # Point density\n",
    "        num_points = square_points.shape[0]\n",
    "        pt_density_list.append(num_points / (4 * feet_from_point**2))        \n",
    "        \n",
    "        # Flight path specifics\n",
    "        flight_list = create_flight_list(square_points)\n",
    "        # Create SampleSquare from all flight passes\n",
    "        ss = SampleSquare(flight_list, x = center_point[0], \\\n",
    "                          y=center_point[1],feet_from_point=feet_from_point)\n",
    "        # Collect SampleSquares\n",
    "        SampleFlightList.append(ss)\n",
    "        \n",
    "    else:\n",
    "        pts_thrown_out +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_out(SampleFlightList,pt_density_list,feet_from_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df = pd.DataFrame([flight.error_decomp_laefer for flight in SampleFlightList],columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "\n",
    "cw_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Horizontal - leinster house lot 1\n",
    "pt1 = np.array([316315.836914,233643.625977,10.56])\n",
    "pt2 = np.array([316286.843994,233655.563965,10.523])\n",
    "u_length = np.linalg.norm(pt2-pt1) # ~31m\n",
    "v_length = 4.9\n",
    "pt3 = np.array([3.16317702e+05, 2.33648155e+05, 1.07051393e+01]) # Backed into from previous 2D v calculation\n",
    "uv_inv,w,unit_u,unit_v = rectangle(pt1[:2],pt2[:2],u_length,v_length)\n",
    "\n",
    "rectangle_points = pd.read_hdf(file_dir+pt_files_horizontal[0])\n",
    "# rectangle_points = rectangle_points[(rectangle_points['z_scaled']<6.2)& \\\n",
    "#                                                   (rectangle_points['z_scaled']>5.7)]\n",
    "\n",
    "rectangle_points['flight_id'] = rectangle_points['pt_src_id']\n",
    "# # # Norm from any 3 points on plane\n",
    "# a = pt1\n",
    "# b = np.array([316290.827881,233658.487061,10.519])\n",
    "# c = np.array([316312.126953,233650.197998,10.664])\n",
    "# norm = np.cross(c - b,(a-b))\n",
    "\n",
    "# bottom_vec = (np.cross(norm,(pt2 - pt1)))/np.linalg.norm(np.cross(norm,(pt2 - pt1)))\n",
    "# bottom_right_pt = pt1 + bottom_vec*v_length\n",
    "# print(bottom_right_pt)\n",
    "print(u_length*v_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create center_points\n",
    "feet_from_point = 0.5\n",
    "border = []\n",
    "border.append(1.05*feet_from_point/u_length)\n",
    "border.append(1.05*feet_from_point/v_length)\n",
    "center_points = center_point_sample(2500,pt1,pt2,pt3,u_length=u_length,v_length=v_length,border=border)\n",
    "mean_z = rectangle_points['z_scaled'].mean()\n",
    "pts_thrown_out = 0\n",
    "\n",
    "for center_point in center_points:\n",
    "    square_points = in_horizontal_square(rectangle_points,center_point[:2],feet_from_point)\n",
    "    \n",
    "    flight_count = len(square_points['flight_id'].unique())\n",
    "   \n",
    "    # If z_max > 10, <6 for any dataset, skip it\n",
    "    if square_points['z_scaled'].max()<mean_z+1:\n",
    "        # Statistics!\n",
    "                \n",
    "        # Point density\n",
    "        num_points = square_points.shape[0]\n",
    "        pt_density_list.append(num_points / (4 * feet_from_point**2))        \n",
    "        \n",
    "        # Flight path specifics\n",
    "        flight_list = create_flight_list(square_points)\n",
    "        # Create SampleSquare from all flight passes\n",
    "        ss = SampleSquare(flight_list, x = center_point[0], \\\n",
    "                          y=center_point[1],feet_from_point=feet_from_point)\n",
    "        # Collect SampleSquares\n",
    "        SampleFlightList.append(ss)\n",
    "        \n",
    "    else:\n",
    "        pts_thrown_out +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_out(SampleFlightList,pt_density_list,feet_from_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df = pd.DataFrame([flight.error_decomp_laefer for flight in SampleFlightList],columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "\n",
    "cw_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Horizontal - leinster house lot 2\n",
    "pt1 = np.array([316307.085938,233679.488037,10.607])\n",
    "pt2 = np.array([316293.058105,233682.521973,10.478])\n",
    "u_length = np.linalg.norm(pt2-pt1) # ~14m\n",
    "v_length = 4.5\n",
    "pt3 = np.array([3.16307932e+05, 2.33683397e+05, 1.05349566e+01]) # Backed into from previous 2D v calculation\n",
    "uv_inv,w,unit_u,unit_v = rectangle(pt1[:2],pt2[:2],u_length,v_length)\n",
    "\n",
    "rectangle_points = pd.read_hdf(file_dir+pt_files_horizontal[1])\n",
    "rectangle_points = rectangle_points[(rectangle_points['z_scaled']<10.7)& \\\n",
    "                                                  (rectangle_points['z_scaled']>10.4)]\n",
    "\n",
    "rectangle_points['flight_id'] = rectangle_points['pt_src_id']\n",
    "# # Norm from any 3 points on plane\n",
    "# a = pt1\n",
    "# b = np.array([316294.368896,233686.305908,10.505])\n",
    "# c = np.array([316307.704102,233681.699951,10.566])\n",
    "# norm = np.cross(c - b,(a-b))\n",
    "\n",
    "# bottom_vec = (np.cross(norm,(pt2 - pt1)))/np.linalg.norm(np.cross(norm,(pt2 - pt1)))\n",
    "# bottom_right_pt = pt1 + bottom_vec*v_length\n",
    "# print(bottom_right_pt)\n",
    "print(u_length*v_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create center_points\n",
    "feet_from_point = 0.5\n",
    "border = []\n",
    "border.append(1.05*feet_from_point/u_length)\n",
    "border.append(1.05*feet_from_point/v_length)\n",
    "center_points = center_point_sample(2500,pt1,pt2,pt3,u_length=u_length,v_length=v_length,border=border)\n",
    "mean_z = rectangle_points['z_scaled'].mean()\n",
    "pts_thrown_out = 0\n",
    "\n",
    "for center_point in center_points:\n",
    "    square_points = in_horizontal_square(rectangle_points,center_point[:2],feet_from_point)\n",
    "    \n",
    "    flight_count = len(square_points['flight_id'].unique())\n",
    "   \n",
    "    # If z_max > 10, <6 for any dataset, skip it\n",
    "    if square_points['z_scaled'].max()<mean_z+1:\n",
    "        # Statistics!\n",
    "                \n",
    "        # Point density\n",
    "        num_points = square_points.shape[0]\n",
    "        pt_density_list.append(num_points / (4 * feet_from_point**2))        \n",
    "        \n",
    "        # Flight path specifics\n",
    "        flight_list = create_flight_list(square_points)\n",
    "        # Create SampleSquare from all flight passes\n",
    "        ss = SampleSquare(flight_list, x = center_point[0], \\\n",
    "                          y=center_point[1],feet_from_point=feet_from_point)\n",
    "        # Collect SampleSquares\n",
    "        SampleFlightList.append(ss)\n",
    "        \n",
    "    else:\n",
    "        pts_thrown_out +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_out(SampleFlightList,pt_density_list,feet_from_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df = pd.DataFrame([flight.error_decomp_laefer for flight in SampleFlightList],columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "\n",
    "cw_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flight pass height distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all heights by flight id\n",
    "from collections import defaultdict\n",
    "\n",
    "flight_id_dict = defaultdict(list)\n",
    "\n",
    "for sample_num in range(len(SampleFlightList)):\n",
    "\n",
    "    dd = dict([(fp.flight_id,fp.h) for fp in SampleFlightList[sample_num].flight_list_laefer[2:]])\n",
    "    for key in dd.keys():\n",
    "        flight_id_dict[key].append(dd[key])\n",
    "\n",
    "h_dist = []\n",
    "for key in flight_id_dict.keys():\n",
    "    mean_h = np.mean([abs(v) for v in flight_id_dict[key]])\n",
    "    h_dist.append(1000*mean_h)\n",
    "    print(\"{:2}: {:2.4f}\".format(key,mean_h))\n",
    "\n",
    "# Plot distribution of mean abs(heights)\n",
    "plt.hist(h_dist,density=True)\n",
    "plt.title(\"Dublin Horizontal Surfaces\",fontsize=12)\n",
    "plt.xlabel(\"Mean absolute height (mm)\",fontsize=12)\n",
    "plt.ylabel(\"Distribution of flight passes\",fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical density\n",
    "The section below iterates through the sample surfaces, generating sample squares, generating density/accuracy statistics for each, and gathering the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''flight_id_mapping = {\n",
    "\t\"F_150326_122941\":7,\n",
    "\t\"F_150326_123430\":8,\n",
    "\t\"F_150326_123922\": 9,\n",
    "\t\"F_150326_124415\":10,\n",
    "\t\"F_150326_154909\":32,\n",
    "\t\"F_150326_155238\":33,\n",
    "\t\"F_ 150326_155529\":34,\n",
    "\t\"F_150326_155833\":35\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the bottom right point\n",
    "# a = (np.cross(norm,(top_left_pt - bottom_left_pt)))/np.linalg.norm(np.cross(norm,(top_left_pt - bottom_left_pt)))\n",
    "# bottom_right_pt = bottom_left_pt + a*v_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vert_density(square_points, \n",
    "                 middle_pt, \n",
    "                 right_pt, \n",
    "                 left_pt, \n",
    "                 bottom_left_pt,\n",
    "                 u_length,\n",
    "                 v_length,\n",
    "                 feet_from_pt,\n",
    "                 SampleFlightList=[],\n",
    "                 pt_density_list=[],\n",
    "                 sd_wall=[],\n",
    "                 wall_face=None\n",
    "                 ): \n",
    "    \n",
    "    # Calculate norm_vector from 3 points, to define plane and extract the wall face\n",
    "    norm = np.cross(middle_pt - right_pt,(left_pt-right_pt))\n",
    "    norm = norm / np.linalg.norm(norm)\n",
    "\n",
    "    # Extract the wall face, above 6.5m and below 34m to avoid roof and ground points\n",
    "    wall_face = grab_wall_face(square_points,norm, middle_pt,6.5,34,5e-1)\n",
    "\n",
    "    # Fit a plane, create norm_vector, calculate dist_from_plane\n",
    "    norm_vector,_,wall_face,_ = plane_fit(wall_face) \n",
    "    \n",
    "    # Sample points in wall\n",
    "    #Note 0.28 border_v comes from: (3.5/2) (half-meter feet_from_point) / v_length (with some buffer)\n",
    "    feet_from_pt_v = 1\n",
    "    feet_from_pt_u = 1\n",
    "    border = [0,0]\n",
    "    border[0] = 1.05*(feet_from_pt_u / u_length)\n",
    "    border[1] = 1.05*(feet_from_pt_v / v_length)\n",
    "\n",
    "    center_points = center_point_sample(5000,\n",
    "                        bottom_left_pt,top_left_pt,bottom_right_pt,\n",
    "                        u_length=u_length,v_length=v_length,border=border)\n",
    "    \n",
    "    # Main Loop through the sample points\n",
    "    pts_thrown_out = 0\n",
    "\n",
    "    for center_point in center_points:\n",
    "        square_points,pt_density = in_vertical_square(wall_face,\n",
    "                                                    norm_vector,\n",
    "                                                    center_point,\n",
    "                                                    feet_from_pt_v,\n",
    "                                                    feet_from_pt_u)\n",
    "        flight_count = len(square_points['flight_id'].unique())\n",
    "        \n",
    "        # Statistics!\n",
    "\n",
    "        # Point density\n",
    "        num_points = square_points.shape[0]\n",
    "        pt_density_list.append(pt_density)        \n",
    "        \n",
    "\n",
    "        # Fit a plane\n",
    "        if square_points.shape[0] > 0:\n",
    "            norm_vector,_,square_points,_ = plane_fit(square_points)\n",
    "            flight_list = create_flight_list(square_points)\n",
    "        else:\n",
    "            flight_list=None\n",
    "\n",
    "        # Flight path specifics\n",
    "        ss = SampleSquare(flight_list, x = center_point[0], \\\n",
    "                          y=center_point[1],z=center_point[2],feet_from_point=[feet_from_pt_v,feet_from_pt_u])\n",
    "        SampleFlightList.append(ss)    \n",
    "    \n",
    "    # Print outs\n",
    "    print(\"Pts in dataset: {}\".format(wall_face.shape[0]))\n",
    "    \n",
    "    print(\"Vertical face point density over {:d} samples\".format(len(pt_density_list)))\n",
    "    print(\"*\"*30)\n",
    "    print(\"Avg density: {:2.4f} (SD: {:2.4f})\".format(np.mean(pt_density_list),np.std(pt_density_list)))\n",
    "    \n",
    "    return SampleFlightList, wall_face, pt_density_list, sd_wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregators\n",
    "pt_density_list= []\n",
    "sd_wall=[]\n",
    "SampleFlightList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Main wall on Bank of Ireland\n",
    "middle_pt = np.array([316566.945068,234635.687012,17.288])\n",
    "\n",
    "# Extract from all files, the points within feet_from_pt in the xy-plane of the middle wall point\n",
    "square_points_vertical = grab_points(pt_files_vertical,file_dir,middle_pt[0],middle_pt[1],4.15)\n",
    "square_points_vertical['flight_id'] = square_points_vertical['pt_src_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the norm\n",
    "middle_pt = np.array([316566.945068,234635.687012,17.288])\n",
    "right_pt = np.array([316572.521973,234635.230957,29.448999])\n",
    "left_pt = np.array([316563.1521, 234635.970215, 22.895])\n",
    "bottom_left_pt= np.array([316563.1521, 234635.970215, 8.895])\n",
    "top_left_pt = np.array([316563.1521, 234635.970215, 33.895])\n",
    "bottom_right_pt = np.array([316571.4272615415,234635.3285753328,8.895])\n",
    "feet_from_pt = 4.15\n",
    "u_length = 25\n",
    "v_length = 8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSEV: \",(.0166/.0291)-1)\n",
    "print(\"C: \",.0072/.025-1)\n",
    "print(\"W: \",.01457/.0149-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SampleFlightList, wall_face, pt_density_list, sd_wall = \\\n",
    "vert_density(square_points_vertical, \n",
    "                 middle_pt, \n",
    "                 right_pt, \n",
    "                 left_pt, \n",
    "                 bottom_left_pt, \n",
    "                 u_length,\n",
    "                 v_length,\n",
    "                 feet_from_pt,\n",
    "                 SampleFlightList,    \n",
    "                 pt_density_list,\n",
    "                 sd_wall\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "flight_ids = wall_face['pt_src_id'].unique()\n",
    "wall_face['pts_bins'] = pd.cut((wall_face['z_scaled']-3.5), \\\n",
    "                                      bins=range(0,36,3), \\\n",
    "                                      labels=range(3,36,3))\n",
    "\n",
    "for f in flight_ids:\n",
    "    flight_pts = wall_face[wall_face['pt_src_id']==f]\n",
    "    # Num of points\n",
    "    print(\"\\n\\nDensity for flight id {}:\".format(f),flight_pts.groupby('pts_bins')['X'].count()/(3*v_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main wall on Bank of Ireland\n",
    "middle_pt = np.array([316543.00,234675.172852,18.693])\n",
    "\n",
    "# Extract from all files, the points within feet_from_pt in the xy-plane of the middle wall point\n",
    "square_points_vertical = grab_points(pt_files_vertical,file_dir,middle_pt[0],middle_pt[1],3)\n",
    "square_points_vertical['flight_id'] = square_points_vertical['pt_src_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the norm\n",
    "middle_pt = np.array([316543.00,234675.172852,18.693]) ##\n",
    "right_pt = np.array([316542.769043,234672.121094,19.367]) ##\n",
    "left_pt = np.array([316543.187988,234677.369141,26.181]) ##\n",
    "bottom_left_pt= np.array([316543.198975,234677.737793,6]) ##\n",
    "top_left_pt = np.array([316543.198975,234677.737793,28.5]) ##\n",
    "bottom_right_pt = np.array([3.16542722e+05, 2.34671757e+05, 6.00000000e+00])\n",
    "feet_from_pt = 3 ##\n",
    "u_length = 25\n",
    "v_length = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vector,_,_,_ = plane_fit(square_points_vertical)\n",
    "wall_face = grab_wall_face(square_points_vertical,norm_vector, middle_pt,6.5,34,5e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleFlightList, wall_face, pt_density_list, sd_wall = \\\n",
    "vert_density(square_points_vertical, \n",
    "                 middle_pt, \n",
    "                 right_pt, \n",
    "                 left_pt, \n",
    "                 bottom_left_pt, \n",
    "                 u_length,\n",
    "                 v_length,\n",
    "                 feet_from_pt,\n",
    "                 SampleFlightList,    \n",
    "                 pt_density_list,\n",
    "                 sd_wall\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_ids = wall_face['pt_src_id'].unique()\n",
    "wall_face['pts_bins'] = pd.cut((wall_face['z_scaled']-3.5), \\\n",
    "                                      bins=range(0,36,3), \\\n",
    "                                      labels=range(3,36,3))\n",
    "\n",
    "for f in flight_ids:\n",
    "    flight_pts = wall_face[wall_face['pt_src_id']==f]\n",
    "    # Num of points\n",
    "    print(\"\\n\\nDensity for flight id {}:\".format(f),flight_pts.groupby('pts_bins')['X'].count()/(3*(8.3+6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_points_vertical['pt_src_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_flight_paths_laefer = []\n",
    "for flight in SampleFlightList:\n",
    "    try:\n",
    "        avg_flight_paths_laefer.append(len(flight.flight_list_laefer)-2)\n",
    "    except AttributeError:\n",
    "        avg_flight_paths_laefer.append(0)\n",
    "\n",
    "print(\"Avg number of flight paths per square: {:2.2f}\".format(np.mean(avg_flight_paths_laefer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cw = []\n",
    "for flight in SampleFlightList:\n",
    "    try:\n",
    "        cw.append(flight.error_decomp_laefer)\n",
    "    except AttributeError:\n",
    "        print(\"Missing\")\n",
    "#     cw_df = pd.DataFrame(cw,columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "    cw_df = pd.DataFrame(cw,columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "\n",
    "(cw_df).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flight pass height distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all heights by flight id\n",
    "from collections import defaultdict\n",
    "\n",
    "flight_id_dict = defaultdict(list)\n",
    "\n",
    "for sample_num in range(len(SampleFlightList)):\n",
    "\n",
    "    dd = dict([(fp.flight_id,fp.h) for fp in SampleFlightList[sample_num].flight_list_laefer[2:]])\n",
    "    for key in dd.keys():\n",
    "        flight_id_dict[key].append(dd[key])\n",
    "\n",
    "h_dist = []\n",
    "for key in flight_id_dict.keys():\n",
    "    mean_h = np.mean([abs(v) for v in flight_id_dict[key]])\n",
    "    h_dist.append(1000*mean_h)\n",
    "    print(\"{:2}: {:2.4f}\".format(key,mean_h))\n",
    "\n",
    "# Plot distribution of mean abs(heights)\n",
    "plt.hist(h_dist)\n",
    "plt.title(\"Dublin Horizontal Surfaces\",fontsize=12)\n",
    "plt.xlabel(\"Mean absolute height (mm)\",fontsize=12)\n",
    "plt.ylabel(\"Distribution of flight passes\",fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_id_dict[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where on the  wall are the points from each flight pass? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,22])\n",
    "for i,fid in enumerate(wall_face['flight_id'].unique()):\n",
    "    plt.subplot(4,3,i+1)\n",
    "    pts = wall_face[wall_face['flight_id']==fid]\n",
    "    hist = pd.cut(wall_face[wall_face['flight_id']==fid]['z_scaled'],bins=range(0,120,5),labels=range(5,120,5))\n",
    "#     plt.hist(hist,orientation='horizontal')\n",
    "    plt.plot(pts['x_scaled'],pts['z_scaled'],'x')\n",
    "    plt.yticks(np.arange(0,36,3))\n",
    "    plt.ylabel(\"Wall height (m)\")\n",
    "#     plt.xlabel(\"Point number (not spatial)\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.title(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_face['flight_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap by flight pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square_points_list, SampleFlightList, wall_face_list, pt_density_list, sd_wall_list\n",
    "h_dict = {\n",
    " 7:[],\n",
    " 8:[],\n",
    " 9:[],\n",
    " 32:[],\n",
    " 33:[],\n",
    " 34:[],\n",
    "}\n",
    "# Collect h for each flight pass in each sample square\n",
    "for sample_num in range(10000):\n",
    "    h_list = [fp.h for fp in SampleFlightList[sample_num].flight_list_laefer[2:]]\n",
    "    num_pt_list = [fp.num_points for fp in SampleFlightList[sample_num].flight_list_laefer[2:]]\n",
    "    flight_ids = [fp.flight_id for fp in SampleFlightList[sample_num].flight_list_laefer[2:]]\n",
    "    total_pts = SampleFlightList[sample_num].flight_list_laefer[0].num_points\n",
    "    for a in h_dict.keys():\n",
    "        if a in flight_ids:\n",
    "            ix = flight_ids.index(a)\n",
    "            h_dict[a].append(h_list[ix])\n",
    "        else:\n",
    "            h_dict[a].append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean height for each flight pass\n",
    "print(\"F_Id\\t Mean abs height\\n\",\"*\"*23)\n",
    "[print(\"{}: {:6.3f}\".format(k,np.nanmean([abs(h) for h in h_dict[k]]))) for k in h_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix of mean height differences across flight passes (would expect larger diffs for different directions)\n",
    "def create_h_matrix(h_dict):\n",
    "    h_matrix = np.zeros([len(h_dict),len(h_dict)])\n",
    "    for i,key1 in enumerate(h_dict.keys()):\n",
    "        for j,key2 in enumerate(h_dict.keys()):\n",
    "            h_matrix[i,j] = np.nanmean(abs(np.array(h_dict[key1]) - np.array(h_dict[key2])))\n",
    "    return h_matrix\n",
    "\n",
    "def h_heatmap(h_matrix,h_dict,fontsize=15,label='Flight ID'):\n",
    "    # Heatmap of the matrix\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.imshow(h_matrix, cmap='YlOrRd',vmin=0,vmax=0.6)\n",
    "    plt.xticks(np.arange(0,h_matrix.shape[0]),h_dict.keys(),fontsize=fontsize)\n",
    "    plt.yticks(np.arange(0,h_matrix.shape[0]),h_dict.keys(),fontsize=fontsize)\n",
    "    plt.ylabel(label,fontsize=fontsize)\n",
    "    plt.xlabel(label,fontsize=fontsize)\n",
    "    plt.ylim(h_matrix.shape[0]-0.5,-0.5)\n",
    "    plt.title(\"Mean Absolute h difference\",fontsize=fontsize)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "h_matrix = create_h_matrix(h_dict)\n",
    "h_heatmap(h_matrix,h_dict)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing points by scan angle\n",
    "\n",
    "Count the missing scan points based on scan angle between consecutive points.  Goal is to 1) compare the % of missing points for horizontal vs vertical surfaces, and 2) compare the % of missing points at different wall heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_face_list[0].to_pickle(\"../../Data/parking_lot/wall_points_laefer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pull_first_scan_gap(wall_face_laefer):\n",
    "    # Separate return num, only keep the first returns, add scan_gap, sort\n",
    "    wall_face_laefer['num_returns'] = np.floor(wall_face_laefer['flag_byte']/16).astype(int)\n",
    "    wall_face_laefer['return_num'] = wall_face_laefer['flag_byte']%16\n",
    "    first_return_wall = wall_face_laefer[wall_face_laefer['return_num']==1]\n",
    "    first_return_wall.sort_values(by=['gps_time'],inplace=True)\n",
    "    first_return_wall.reset_index(inplace=True)\n",
    "    first_return_wall.loc[1:,'scan_gap'] = [first_return_wall.loc[i+1,'scan_angle'] - first_return_wall.loc[i,'scan_angle'] for i in range(first_return_wall.shape[0]-1)]\n",
    "    first_return_wall.loc[0,'scan_gap'] = 0\n",
    "    return first_return_wall\n",
    "\n",
    "# Wall\n",
    "wall_face_laefer = wall_face_list[0]\n",
    "first_return_wall = pull_first_scan_gap(wall_face_laefer)\n",
    "# Rectangle\n",
    "rectangle_face_laefer = pd.read_pickle(file_dir+\"rectangle_points_laefer.pkl\")\n",
    "first_return_rectangle = pull_first_scan_gap(rectangle_face_laefer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan gap of -4,-5,-6 is normal, -10,-11,-15 are a missed point\n",
    "w = pd.DataFrame(first_return_rectangle['scan_gap'].value_counts())\n",
    "w.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan gap of -4,-5,-6 is normal, -10,-11,-15 are a missed point\n",
    "w = pd.DataFrame(first_return_wall[first_return_wall['flight_id']=='180819']['scan_gap'].value_counts())\n",
    "w.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the wall height into bins, compare % missing points at different heights\n",
    "\n",
    "first_return_wall['pts_bins'] = pd.cut((first_return_wall['z_scaled']-9)/3.28084, \\\n",
    "                                       bins=range(0,40,3),labels=range(3,40,3))\n",
    "\n",
    "first_return_wall['missed_point'] = np.zeros(first_return_wall.shape[0])\n",
    "first_return_wall['good_point'] = np.zeros(first_return_wall.shape[0])\n",
    "for index, row in first_return_wall.iterrows():\n",
    "    if (row['scan_gap'] >-17) & (row['scan_gap']< -6):\n",
    "        first_return_wall.loc[index,'missed_point']=1\n",
    "    if (row['scan_gap'] <-1) & (row['scan_gap'] > -7):\n",
    "        first_return_wall.loc[index,'good_point']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_return_wall[first_return_wall['z_scaled']<18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = first_return_wall[first_return_wall['flight_id']=='181004'].groupby('pts_bins').mean()\n",
    "a = first_return_wall.groupby('pts_bins').mean()\n",
    "\n",
    "a['miss_pct'] = a['missed_point']/a['good_point']\n",
    "a['miss_pct'][:-2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['miss_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(list(a['miss_pct'][:-2]),list(a['miss_pct'][:-2].index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intensity up and down the wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wall_face_laefer = wall_face_list[0]\n",
    "flight_ids = ['181004','180819']\n",
    "wall_face_laefer['pts_bins'] = pd.cut((wall_face_laefer['z_scaled']-9)/3.28084,bins=range(0,40,3),labels=range(3,40,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_face_laefer['intensity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_pts = wall_face_laefer[wall_face_laefer['flight_id']==flight_ids[1]]\n",
    "print(\"shape\",flight_pts.shape)\n",
    "flight_pts.groupby('pts_bins')['intensity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intensity on the parking lot horizontal surface\n",
    "rectangle_points_laefer = pd.read_pickle(file_dir+\"rectangle_points_laefer.pkl\")\n",
    "rectangle_points_laefer[rectangle_points_laefer['flight_id']=='181004']['intensity'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density up and down the wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wall_face_laefer = wall_face_list[0]\n",
    "plt.figure(figsize=[20,22])\n",
    "for i,fid in enumerate(wall_face_laefer['flight_id'].unique()):\n",
    "    plt.subplot(4,3,i+1)\n",
    "    pts = wall_face_laefer[wall_face_laefer['flight_id']==fid]\n",
    "    hist = pd.cut(wall_face_laefer[wall_face_laefer['flight_id']==fid]['z_scaled'],bins=range(0,120,5),labels=range(5,120,5))\n",
    "#     plt.hist(hist,orientation='horizontal')\n",
    "    plt.plot(range(pts.shape[0]),pts['z_scaled']/3.28084,'x')\n",
    "    plt.yticks(np.arange(0,36,3))\n",
    "    plt.ylabel(\"Wall height (m)\")\n",
    "    plt.xlabel(\"Point number (not spatial)\")\n",
    "    plt.title(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_ids = ['181004','180819','164445','180632']\n",
    "pts_fid = wall_face_laefer[wall_face_laefer['flight_id']==flight_ids[1]]['z_scaled'].copy()\n",
    "pts_fid = pts_fid/3.28084\n",
    "pts_bins = pd.cut(pts_fid,bins=range(15,36,3),labels=range(18,36,3))\n",
    "pts_density = pts_bins.value_counts()/(3*(6.899845795386761/3.28084))\n",
    "pts_density.sort_index(inplace=True)\n",
    "plt.plot(pts_density,range(18,36,3),'-o')\n",
    "plt.xlabel(\"Vertical Density (pts/m^2)\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.ylabel(\"Height on wall (m)\",fontsize=15)\n",
    "plt.yticks(fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_fid = wall_face_laefer['z_scaled'].copy()\n",
    "pts_fid = pts_fid/3.28084\n",
    "pts_bins = pd.cut(pts_fid,bins=[0,16,32],labels=('low','high'))\n",
    "pts_density = pts_bins.value_counts()/(1*(6.899845795386761/3.28084))\n",
    "pts_density.sort_index(inplace=True)\n",
    "plt.bar(['low','high'],pts_density)\n",
    "plt.xlabel(\"Vertical Density (pts/m^2)\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.ylabel(\"Height on wall (m)\",fontsize=15)\n",
    "plt.yticks(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_fid = wall_face_laefer['z_scaled'].copy()\n",
    "pts_fid = pts_fid/3.28084\n",
    "pts_bins = pd.cut(pts_fid,bins=range(9,36,3),labels=range(12,36,3))\n",
    "pts_density = pts_bins.value_counts()/(2*(14.899845795386761/3.28084))\n",
    "pts_density.sort_index(inplace=True)\n",
    "plt.plot(pts_density,range(12,36,3),'-o')\n",
    "plt.xlabel(\"Vertical Density (pts/m^2)\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.ylabel(\"Height on wall (m)\",fontsize=15)\n",
    "plt.yticks(fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy up the wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_fid = [sf.z for sf in SampleFlightList]\n",
    "pts_fid = [pt/3.28084 for pt in pts_fid]\n",
    "pts_bins = pd.cut(pts_fid,bins=range(8,36,2),labels=range(10,36,2))\n",
    "\n",
    "# Create acc_df Dataframe of accuracy and height bins for a specific flight id\n",
    "# acc_df = pd.DataFrame([ss.flight_list_laefer[0].sd_dist for ss in SampleFlightList],columns=['total_rmse'])\n",
    "acc_df = pd.DataFrame(pts_bins,columns=['bin'])\n",
    "\n",
    "acc_df['z'] = pts_fid\n",
    "# plt.plot(acc_df[acc_df['bin']==30]['z'])\n",
    "\n",
    "# Flight id specific accuracy\n",
    "fid = '181004' # Farther away \n",
    "# fid = '180819' # About 100m away\n",
    "acc_list = []\n",
    "for j in SampleFlightList:\n",
    "    dd = {j.flight_list_laefer[i].flight_id:i for i in range(len(j.flight_list_laefer))}\n",
    "    ix = dd[fid]\n",
    "    acc_list.append(j.flight_list_laefer[ix].sd_dist/3.28084)\n",
    "len(acc_list)\n",
    "\n",
    "acc_df['fid_rmse'] = acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(np.arange(12-3,33-3,2),acc_df.groupby('bin')['fid_rmse'].mean().iloc[1:-1])\n",
    "plt.ylabel(\"Wall Height (m)\")\n",
    "plt.xlabel(\"Single Flight RMSE (m)\")\n",
    "plt.title(\"Flight ID: \"+str(fid))\n",
    "print(acc_df['bin'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(np.arange(12-3,33-3,2),acc_df.groupby('bin')['fid_rmse'].mean().iloc[1:-1])\n",
    "plt.ylabel(\"Wall Height (m)\")\n",
    "plt.xlabel(\"Single Flight RMSE (m)\")\n",
    "plt.title(\"Flight ID: \"+str(fid))\n",
    "print(acc_df['bin'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What causes C and W?\n",
    "What's the distribution of h's that generate C for vertical surfaces?  Outlier, or consistent misalignment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(\"{}:\\t{:2.4f}\\t{:2} points\\t{:2.4f}\".format(flight_ids[i],h_list[i]**2*num_pt_list[i],num_pt_list[i],h_list[i])) for i in range(len(h_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = {\n",
    " '164239':'n-s  ',\n",
    " '164445':'n-s  ',\n",
    " '164640':'n-s  ',\n",
    " '172753':'e-w  ',\n",
    " '172928':'e-w  ',\n",
    " '173110':'e-w  ',\n",
    " '180632':'sw-ne',\n",
    " '180819':'sw-ne',\n",
    " '181004':'sw-ne',\n",
    " '200212':'se-nw',\n",
    " '200600':'se-nw',\n",
    " '200742':'se-nw',\n",
    " '200938':'se-nw' \n",
    "}\n",
    "dir_list = ['n-s  ','e-w  ','sw-ne','se-nw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square_points_list, SampleFlightList, wall_face_list, pt_density_list, sd_wall_list\n",
    "h_dict = {\n",
    " '164239':[],\n",
    " '164445':[],\n",
    " '164640':[],\n",
    " '172753':[],\n",
    " '172928':[],\n",
    " '173110':[],\n",
    " '180632':[],\n",
    " '180819':[],\n",
    " '181004':[],\n",
    " '200212':[],\n",
    " '200600':[],\n",
    " '200742':[],\n",
    " '200938':[] \n",
    "}\n",
    "# Collect h for each flight pass in each sample square\n",
    "for sample_num in range(2500):\n",
    "    h_list = [fp.h for fp in SampleFlightList[sample_num].flight_list_laefer[2:]]\n",
    "#     num_pt_list = [fp.num_points for fp in SampleFlightList[sample_num].flight_list_laefer[2:]]\n",
    "    flight_ids = [fp.flight_id for fp in SampleFlightList[sample_num].flight_list_laefer[2:]]\n",
    "#     total_pts = SampleFlightList[sample_num].flight_list_laefer[0].num_points\n",
    "    for a in h_dict.keys():\n",
    "        if a in flight_ids:\n",
    "            ix = flight_ids.index(a)\n",
    "            h_dict[a].append(h_list[ix])\n",
    "        else:\n",
    "            h_dict[a].append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean height for each flight pass\n",
    "print(\"F_Id\\t Mean abs height\\n\",\"*\"*23)\n",
    "[print(\"{}: {:6.3f}\".format(k,np.nanmean([abs(h) for h in h_dict[k]]))) for k in h_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "h_dir_dict = defaultdict(list)\n",
    "for ss in range(len(h_dict['164239'])):\n",
    "    for di in dir_list:\n",
    "        direction_h_sum = 0\n",
    "        direction_count = 0\n",
    "\n",
    "        for fp in h_dict.keys():\n",
    "            if direction[fp] == di:\n",
    "                direction_h_sum += h_dict[fp][ss]\n",
    "                direction_count +=1    \n",
    "        h_dir_dict[di].append(direction_h_sum/direction_count)\n",
    "dir_list = ['n-s  ','e-w  ','sw-ne','se-nw']\n",
    "# Mean height for each direction\n",
    "print(\"Direct\\tMean abs height\\n\",\"*\"*22)\n",
    "[print(\"{}: {:6.3f}\".format(k,np.nanmean([abs(h) for h in h_dir_dict[k]]))) for k in h_dir_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix of mean height differences across flight passes (would expect larger diffs for different directions)\n",
    "def create_h_matrix(h_dict):\n",
    "    h_matrix = np.zeros([len(h_dict),len(h_dict)])\n",
    "    for i,key1 in enumerate(h_dict.keys()):\n",
    "        for j,key2 in enumerate(h_dict.keys()):\n",
    "            h_matrix[i,j] = np.nanmean(abs(np.array(h_dict[key1]) - np.array(h_dict[key2])))\n",
    "    return h_matrix\n",
    "\n",
    "def h_heatmap(h_matrix,h_dict,fontsize=15,label='Flight ID'):\n",
    "    # Heatmap of the matrix\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.imshow(h_matrix, cmap='YlOrRd')\n",
    "    plt.xticks(np.arange(0,h_matrix.shape[0]),h_dict.keys(),rotation=90,fontsize=fontsize)\n",
    "    plt.yticks(np.arange(0,h_matrix.shape[0]),h_dict.keys(),fontsize=fontsize)\n",
    "    plt.ylabel(label,fontsize=fontsize)\n",
    "    plt.xlabel(label,fontsize=fontsize)\n",
    "    plt.ylim(h_matrix.shape[0]-0.5,-0.5)\n",
    "    plt.title(\"Mean Absolute h difference\",fontsize=fontsize)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "h_matrix = create_h_matrix(h_dict)\n",
    "h_heatmap(h_matrix,h_dict)  \n",
    "# h_matrix = create_h_matrix(h_dir_dict)\n",
    "# h_heatmap(h_matrix,h_dir_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_matrix = create_h_matrix(h_dir_dict)\n",
    "h_heatmap(h_matrix,h_dir_dict,label=\"Flight Direction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
