{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from laspy.file import File\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = '../../Data/parking_lot/'\n",
    "filenames =[\n",
    "            '10552_NYU_M2 - Scanner 1 - 190511_164039_1 - originalpoints.laz',\n",
    "            '10552_NYU_M2 - Scanner 1 - 190511_164239_1 - originalpoints.laz',\n",
    "            '10552_NYU_M2 - Scanner 1 - 190511_164445_1 - originalpoints.laz',\n",
    "            '10552_NYU_M2 - Scanner 1 - 190511_172558_1 - originalpoints.laz',\n",
    "            '10552_NYU_M2 - Scanner 1 - 190511_172753_1 - originalpoints.laz',    \n",
    "            '10552_NYU_M2 - Scanner 1 - 190511_172928_1 - originalpoints.laz',\n",
    "            '10552_NYU_M2 - Scanner 1 - 190511_180428_1 - originalpoints.laz',\n",
    "            '10552_NYU_M2 - Scanner 1 - 190511_180632_1 - originalpoints.laz',\n",
    "            '10552_NYU_M2 - Scanner 1 - 190511_180819_1 - originalpoints.laz',\n",
    "            '10552_NYU_M3 - Scanner 1 - 190511_200348_1 - originalpoints.laz',\n",
    "            '10552_NYU_M3 - Scanner 1 - 190511_200600_1 - originalpoints.laz',\n",
    "            '10552_NYU_M3 - Scanner 1 - 190511_200742_1 - originalpoints.laz',\n",
    "            '10552_NYU_M2 - Scanner 1 - 190511_163824_1 - originalpoints.laz',\n",
    "            '10552_NYU_M2 - Scanner 1 - 190511_164640_1 - originalpoints.laz',\n",
    "            '10552_NYU_M2 - Scanner 1 - 190511_172416_1 - originalpoints.laz',\n",
    "            '10552_NYU_M2 - Scanner 1 - 190511_173110_1 - originalpoints.laz',\n",
    "            '10552_NYU_M2 - Scanner 1 - 190511_164845_1 - originalpoints.laz',\n",
    "           '10552_NYU_M2 - Scanner 1 - 190511_172201_1 - originalpoints.laz',\n",
    "           '10552_NYU_M2 - Scanner 1 - 190511_173238_1 - originalpoints.laz',\n",
    "           '10552_NYU_M3 - Scanner 1 - 190511_200938_1 - originalpoints.laz',\n",
    "           '10552_NYU_M3 - Scanner 1 - 190511_200212_1 - originalpoints.laz',\n",
    "           '10552_NYU_M2 - Scanner 1 - 190511_181004_1 - originalpoints.laz',\n",
    "           '10552_NYU_M2 - Scanner 1 - 190511_180231_1 - originalpoints.laz'\n",
    " ]\n",
    "\n",
    "\n",
    "pt_files = [   'las_points_163824.lz',\n",
    "                'las_points_164039.lz',\n",
    "                'las_points_164239.lz',\n",
    "                'las_points_164445.lz',\n",
    "                'las_points_164640.lz',\n",
    "                'las_points_164845.lz',\n",
    "                'las_points_172201.lz',\n",
    "                'las_points_172416.lz',\n",
    "                'las_points_172558.lz',\n",
    "                'las_points_172753.lz',\n",
    "                'las_points_172928.lz',\n",
    "                'las_points_173110.lz',\n",
    "                'las_points_173238.lz',\n",
    "                'las_points_180231.lz',\n",
    "                'las_points_180428.lz',\n",
    "                'las_points_180632.lz',\n",
    "                'las_points_180819.lz',\n",
    "                'las_points_181004.lz',\n",
    "                'las_points_200212.lz',\n",
    "                'las_points_200348.lz',\n",
    "                'las_points_200600.lz',\n",
    "                'las_points_200742.lz',\n",
    "                'las_points_200938.lz',]\n",
    "\n",
    "# Corresponds to LAS 1.2 Point Data Record Format 1\n",
    "columns_dublin_pt_cloud = [\n",
    "    'X',\n",
    "    'Y',\n",
    "    'Z',\n",
    "    'intensity',\n",
    "    'return_number_byte',\n",
    "    'classification_byte',\n",
    "    'scan_angle',\n",
    "    'user_data',\n",
    "    'pt_src_id',\n",
    "    'gps_time']\n",
    "\n",
    "columns_point_cloud = [\n",
    "    'X','Y','Z',\n",
    "    'intensity',\n",
    "    'flag_byte',\n",
    "    'classification_flags',\n",
    "    'classification_byte',\n",
    "    'user_data',\n",
    "    'scan_angle',\n",
    "    'pt_src_id',\n",
    "    'gps_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_to_df(raw,column_names):\n",
    "    '''function takes raw output of laspy.File.get_points() and column names, and returns a pandas Dataframe'''\n",
    "    raw_list = [a[0].tolist() for a in raw]\n",
    "    df = pd.DataFrame(raw_list,columns = column_names)\n",
    "    return df\n",
    "\n",
    "def scale_and_offset(df,header,append_to_df=False):\n",
    "    '''Function takes as input the dataframe output of raw_to_df and the laspy header file.\n",
    "       Output is a nx3 dataframe with adjusted X,Y, and Z coordinates, from the formula: \n",
    "       X_adj = X*X_scale + X_offset.\n",
    "       Brooklyn LiDAR readings appear to be in feet, and use NAVD 88 in the vertical and \n",
    "       New York Long Island State Plane Coordinate System NAD 33 in the horizontal.'''\n",
    "    offset = header.offset\n",
    "    scale = header.scale\n",
    "    scaled_xyz = df[['X','Y','Z']]*scale + offset\n",
    "    if append_to_df:\n",
    "        df['x_scaled'] = scaled_xyz['X']\n",
    "        df['y_scaled'] = scaled_xyz['Y']\n",
    "        df['z_scaled'] = scaled_xyz['Z'] \n",
    "        return df\n",
    "    else:\n",
    "        return scaled_xyz\n",
    "\n",
    "def create_df_pickle(file_dir,filename,column_names):\n",
    "    inFile = File(file_dir+filename, mode='r')\n",
    "    raw = inFile.get_points()\n",
    "    df = raw_to_df(raw,column_names)\n",
    "    df = scale_and_offset(df,inFile.header,append_to_df=True)\n",
    "    pickle_name = 'las_points_'+filename[34:40]+'.pkl'\n",
    "    df.to_pickle(file_dir + pickle_name)\n",
    "\n",
    "def create_df_hd5(file_dir,filename,column_names):\n",
    "    inFile = File(file_dir+filename, mode='r')\n",
    "    raw = inFile.get_points()\n",
    "    df = raw_to_df(raw,column_names)\n",
    "    df = scale_and_offset(df,inFile.header,append_to_df=True)\n",
    "    hdf_name = 'las_points_'+filename[34:40]+'.lz'\n",
    "#     df.to_hdf(file_dir + hdf_name,key='df',complevel=1,complib='lzo')\n",
    "    return df\n",
    "\n",
    "# Load pickle, extract points around square, iterate\n",
    "def grab_points(pt_files,file_dir,pt_x,pt_y,feet_from_point):\n",
    "    size_of_square = (2*feet_from_point)**2\n",
    "    square_points = pd.DataFrame()\n",
    "    for pick in pt_files:\n",
    "        las_points = pd.read_hdf(file_dir+pick)\n",
    "        las_points['flight_id'] = pick[11:-3]\n",
    "        new_square_points = las_points[ (las_points['x_scaled'] < pt_x + feet_from_point)\n",
    "                &(las_points['x_scaled'] > pt_x - feet_from_point) \n",
    "                &(las_points['y_scaled'] < pt_y + feet_from_point)\n",
    "                &(las_points['y_scaled'] > pt_y - feet_from_point)\n",
    "              ]\n",
    "        print(\"Point count in new square from {:s}: {:d}\".format(pick,new_square_points.shape[0]))\n",
    "        #pts_from_scan.append((pick,new_square_points.shape[0]))\n",
    "        square_points = square_points.append(new_square_points,sort=True)\n",
    "\n",
    "    print(\"Total point count in square: {:d}\".format(square_points.shape[0]))\n",
    "    print(\"Size of square: {:2.2f} sq ft\".format(size_of_square))\n",
    "    print(\"Point density: {:2.2f} points / sq ft\".format(square_points.shape[0]/size_of_square))\n",
    "    return square_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flat surface\n",
    "Identifying points in a parking lot to assess how consistently flat they are.  \n",
    "Center point: 40.645789, -74.025951  \n",
    "Easting - 977048.434  \n",
    "Northing - 174555.792"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =create_df_hd5('../../Data/','T_315500_234000.laz',columns_dublin_pt_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82302919, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>intensity</th>\n",
       "      <th>return_number_byte</th>\n",
       "      <th>classification_byte</th>\n",
       "      <th>scan_angle</th>\n",
       "      <th>user_data</th>\n",
       "      <th>pt_src_id</th>\n",
       "      <th>gps_time</th>\n",
       "      <th>x_scaled</th>\n",
       "      <th>y_scaled</th>\n",
       "      <th>z_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.230292e+07</td>\n",
       "      <td>8.230292e+07</td>\n",
       "      <td>8.230292e+07</td>\n",
       "      <td>8.230292e+07</td>\n",
       "      <td>8.230292e+07</td>\n",
       "      <td>8.230292e+07</td>\n",
       "      <td>8.230292e+07</td>\n",
       "      <td>82302919.0</td>\n",
       "      <td>8.230292e+07</td>\n",
       "      <td>8.230292e+07</td>\n",
       "      <td>8.230292e+07</td>\n",
       "      <td>8.230292e+07</td>\n",
       "      <td>8.230292e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.756931e+06</td>\n",
       "      <td>4.234703e+06</td>\n",
       "      <td>1.287429e+04</td>\n",
       "      <td>2.258420e+02</td>\n",
       "      <td>7.510773e+01</td>\n",
       "      <td>2.456181e+00</td>\n",
       "      <td>8.736389e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.239856e+01</td>\n",
       "      <td>3.967786e+05</td>\n",
       "      <td>3.157569e+05</td>\n",
       "      <td>2.342347e+05</td>\n",
       "      <td>1.287429e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.450786e+05</td>\n",
       "      <td>1.471303e+05</td>\n",
       "      <td>8.549734e+03</td>\n",
       "      <td>3.320399e+02</td>\n",
       "      <td>6.466772e+00</td>\n",
       "      <td>8.392025e-01</td>\n",
       "      <td>1.779510e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.949736e+00</td>\n",
       "      <td>3.830248e+03</td>\n",
       "      <td>1.450786e+02</td>\n",
       "      <td>1.471303e+02</td>\n",
       "      <td>8.549734e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>4.000000e+06</td>\n",
       "      <td>-9.959400e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.300000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>-4.200000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>3.896547e+05</td>\n",
       "      <td>3.155000e+05</td>\n",
       "      <td>2.340000e+05</td>\n",
       "      <td>-9.959400e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.632096e+06</td>\n",
       "      <td>4.104507e+06</td>\n",
       "      <td>4.629000e+03</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>7.300000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>-1.400000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>3.933806e+05</td>\n",
       "      <td>3.156321e+05</td>\n",
       "      <td>2.341045e+05</td>\n",
       "      <td>4.629000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.761575e+06</td>\n",
       "      <td>4.218552e+06</td>\n",
       "      <td>1.232400e+04</td>\n",
       "      <td>1.740000e+02</td>\n",
       "      <td>7.300000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>3.942447e+05</td>\n",
       "      <td>3.157616e+05</td>\n",
       "      <td>2.342186e+05</td>\n",
       "      <td>1.232400e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.884316e+06</td>\n",
       "      <td>4.366342e+06</td>\n",
       "      <td>1.894700e+04</td>\n",
       "      <td>2.950000e+02</td>\n",
       "      <td>7.300000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>3.999988e+05</td>\n",
       "      <td>3.158843e+05</td>\n",
       "      <td>2.343663e+05</td>\n",
       "      <td>1.894700e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.999999e+06</td>\n",
       "      <td>4.499999e+06</td>\n",
       "      <td>3.433290e+05</td>\n",
       "      <td>6.553400e+04</td>\n",
       "      <td>2.490000e+02</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>3.900000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.500000e+01</td>\n",
       "      <td>4.031852e+05</td>\n",
       "      <td>3.160000e+05</td>\n",
       "      <td>2.345000e+05</td>\n",
       "      <td>3.433290e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  X             Y             Z     intensity  \\\n",
       "count  8.230292e+07  8.230292e+07  8.230292e+07  8.230292e+07   \n",
       "mean   1.756931e+06  4.234703e+06  1.287429e+04  2.258420e+02   \n",
       "std    1.450786e+05  1.471303e+05  8.549734e+03  3.320399e+02   \n",
       "min    1.500000e+06  4.000000e+06 -9.959400e+04  0.000000e+00   \n",
       "25%    1.632096e+06  4.104507e+06  4.629000e+03  1.000000e+02   \n",
       "50%    1.761575e+06  4.218552e+06  1.232400e+04  1.740000e+02   \n",
       "75%    1.884316e+06  4.366342e+06  1.894700e+04  2.950000e+02   \n",
       "max    1.999999e+06  4.499999e+06  3.433290e+05  6.553400e+04   \n",
       "\n",
       "       return_number_byte  classification_byte    scan_angle   user_data  \\\n",
       "count        8.230292e+07         8.230292e+07  8.230292e+07  82302919.0   \n",
       "mean         7.510773e+01         2.456181e+00  8.736389e-01         0.0   \n",
       "std          6.466772e+00         8.392025e-01  1.779510e+01         0.0   \n",
       "min          7.300000e+01         2.000000e+00 -4.200000e+01         0.0   \n",
       "25%          7.300000e+01         2.000000e+00 -1.400000e+01         0.0   \n",
       "50%          7.300000e+01         2.000000e+00  1.000000e+00         0.0   \n",
       "75%          7.300000e+01         2.000000e+00  1.600000e+01         0.0   \n",
       "max          2.490000e+02         4.000000e+00  3.900000e+01         0.0   \n",
       "\n",
       "          pt_src_id      gps_time      x_scaled      y_scaled      z_scaled  \n",
       "count  8.230292e+07  8.230292e+07  8.230292e+07  8.230292e+07  8.230292e+07  \n",
       "mean   2.239856e+01  3.967786e+05  3.157569e+05  2.342347e+05  1.287429e+01  \n",
       "std    6.949736e+00  3.830248e+03  1.450786e+02  1.471303e+02  8.549734e+00  \n",
       "min    4.000000e+00  3.896547e+05  3.155000e+05  2.340000e+05 -9.959400e+01  \n",
       "25%    1.700000e+01  3.933806e+05  3.156321e+05  2.341045e+05  4.629000e+00  \n",
       "50%    2.000000e+01  3.942447e+05  3.157616e+05  2.342186e+05  1.232400e+01  \n",
       "75%    2.800000e+01  3.999988e+05  3.158843e+05  2.343663e+05  1.894700e+01  \n",
       "max    3.500000e+01  4.031852e+05  3.160000e+05  2.345000e+05  3.433290e+02  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"T_315500_234000.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works\n",
    "for filename in filenames:\n",
    "    create_df_hd5(file_dir,filename,columns_point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract points within a square around the desired point\n",
    "\n",
    "# Parking Lot\n",
    "pt_x = 977037.343\n",
    "pt_y = 174586.034\n",
    "\n",
    "# Top of building\n",
    "# pt_x = 977229.375\n",
    "# pt_y = 174579.42\n",
    "\n",
    "# Projects in back parking lot\n",
    "# pt_x = 977458.238\n",
    "# pt_y = 173302.388\n",
    "\n",
    "# Solar panel\n",
    "# pt_x = 977682.975\n",
    "# pt_y = 174148.192\n",
    "\n",
    "# Run this\n",
    "feet_from_point = 2\n",
    "square_points = grab_points(pt_files,file_dir,pt_x,pt_y,feet_from_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a plane to square_points via SVD\n",
    "def plane_fit(square_points):\n",
    "    '''\n",
    "    Fits a plane via SVD to the provided points.\n",
    "    Input: \n",
    "        (n x 3+) dataframe with fields x_scaled, y_scaled, and z_scaled\n",
    "    Output: \n",
    "        normal vector - normal vector to plane fitted via MLS (3x1 numpy array)\n",
    "        points - provided x,y,z points with zero mean (n x 3 numpy array)\n",
    "        square_points - returns the dataframe with 'dist_from_plane' appended (n x 4+ dataframe)\n",
    "        pts_on_plane - projection of x,y,z points onto the fitted plane (n x 3 numpy array)\n",
    "    '''\n",
    "    \n",
    "    raw_points = np.array(square_points[['x_scaled','y_scaled','z_scaled']]).T\n",
    "    points = raw_points.T - raw_points.mean(axis=1)\n",
    "    svd = np.linalg.svd(points.T)\n",
    "    norm_vector = np.transpose(svd[0])[2]    \n",
    "    # Calculate each point's distance from the plane\n",
    "    dist_from_plane = [np.dot(point,norm_vector) for point in points]\n",
    "\n",
    "    # Project each point onto the plane\n",
    "    proj_on_norm = dist_from_plane*np.array([norm_vector]).T\n",
    "    pts_on_plane = points - proj_on_norm.T\n",
    "    \n",
    "    square_points['dist_from_plane'] = dist_from_plane\n",
    "    \n",
    "    return norm_vector,points,square_points,pts_on_plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_square_for_plotting(square_points):\n",
    "    square_points['size_num'] = 1\n",
    "    square_points['x_plot'] = square_points['x_scaled'] - square_points['x_scaled'].min()\n",
    "    square_points['y_plot'] = square_points['y_scaled'] - square_points['y_scaled'].min()\n",
    "    square_points['z_plot'] = square_points['z_scaled'] - square_points['z_scaled'].min()\n",
    "    return square_points\n",
    "\n",
    "square_points = prep_square_for_plotting(square_points)\n",
    "fig = px.scatter_3d(square_points_1, x='x_plot', y='y_plot', z='z_plot',\n",
    "              color='flight_id',size='size_num',size_max = 12)\n",
    "\n",
    "fig.update_layout( \n",
    "    scene = dict(xaxis = dict(title=\"Easting (feet)\"),\n",
    "                 yaxis = dict(title=\"Northing (feet)\"),\n",
    "                 zaxis = dict(title=\"Vertical (feet)\",range=[0,2]),\n",
    "                ),\n",
    "    width=900,\n",
    "    height=900,\n",
    "    margin=dict(r=20, l=10, b=10, t=10),\n",
    "    showlegend=False,\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical density\n",
    "Identifying point at corner of building to quantify the vertical point density.  \n",
    "Center point: \t40.645854, \t-74.025299  \n",
    "Easting - 977229.375  \n",
    "Northing - 174579.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top of building\n",
    "pt_x_bldg = 977229.375\n",
    "pt_y_bldg = 174579.42\n",
    "\n",
    "square_points_bldg = grab_points(pt_files,file_dir,pt_x_bldg,pt_y_bldg)\n",
    "\n",
    "wall_face = square_points_bldg[(square_points_bldg['x_plot']<5) & \n",
    "                          (square_points_bldg['y_plot']<5) & \n",
    "                          (square_points_bldg['z_plot']<100) &\n",
    "                          (square_points_bldg['z_plot']>10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vector,points,wall_face,pts_on_plane = plane_fit(wall_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_on_plane_df = pd.DataFrame(pts_on_plane,columns=['x_plot','y_plot','z_plot'])\n",
    "pts_on_plane_df['size_num'] = 1\n",
    "\n",
    "fig = px.scatter_3d(pts_on_plane_df, x='x_plot', y='y_plot', z='z_plot',\n",
    "              size='size_num',size_max = 8)\n",
    "\n",
    "fig.update_layout( \n",
    "    scene = dict(xaxis = dict(title=\"Easting (feet)\"),\n",
    "                 yaxis = dict(title=\"Northing (feet)\"),\n",
    "                 #zaxis = dict(title=\"Vertical (feet)\",range=[0,10]),\n",
    "                ),\n",
    "    width=900,\n",
    "    height=900,\n",
    "    margin=dict(r=20, l=10, b=10, t=10),\n",
    "    showlegend=False,\n",
    "    xaxis = {\"title\":{\"text\":\"Cat\"}})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data using laspy\n",
    "file_dir = '../../Data/NYC_topo/'\n",
    "filename = '975172.las'\n",
    "\n",
    "create_df_hd5(file_dir,filename,columns_point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract points within a square around the desired point\n",
    "pt_x = 977037.343\n",
    "pt_y = 174586.034\n",
    "feet_from_point = 2\n",
    "nyc_file_dir = '../../Data/NYC_topo/'\n",
    "nyc_pt_file = ['las_points_NYC_975172.lz']\n",
    "square_points_1 = grab_points(nyc_pt_file,nyc_file_dir,pt_x,pt_y,feet_from_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the .lz file\n",
    "nyc = pd.read_hdf(nyc_file_dir+nyc_pt_file[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time spread for nyc flight\n",
    "(nyc['gps_time'].max() - nyc['gps_time'].min())/(60*60*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_returns(las_df):\n",
    "    '''\n",
    "    Parses the flag_byte into number of returns and return number, adds these fields to las_df.\n",
    "    Input - las_df - dataframe from .laz or .lz file\n",
    "    Output - first_return_df - only the first return points from las_df.\n",
    "           - las_df - input dataframe with num_returns and return_num fields added \n",
    "    '''\n",
    "    \n",
    "    las_df['num_returns'] = np.floor(las_df['flag_byte']/16).astype(int)\n",
    "    las_df['return_num'] = las_df['flag_byte']%16\n",
    "    first_return_df = las_df[las_df['return_num']==1]\n",
    "    first_return_df = first_return_df.reset_index(drop=True)\n",
    "    return first_return_df, las_df\n",
    "_,nyc = label_returns(nyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portion of points that are first returns\n",
    "sum(nyc['return_num']==1)/nyc.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the NYC header file\n",
    "inFile = File(nyc_file_dir+'975172.las', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First bit of Global Encoding indicates the gps time model: 0 for GPS Week Time, \n",
    "# 1 for GPS Adj Standard Time (Standard Time - 1e9)\n",
    "# The origin of standard GPS Time is defined as midnight of the morning of January 6, 1980.\n",
    "print(inFile.header.global_encoding%2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting charts from previous updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vector,points,square_points,_ = plane_fit(square_points)\n",
    "\n",
    "# Add distance from flat plane with norm (x,y,z) = (0,0,1)\n",
    "square_points['dist_from_flat']=np.array([np.dot(point,np.array([0,0,1])) for point in points])\n",
    "\n",
    "# remove data points >5 feet below plane.\n",
    "outliers = square_points[square_points['dist_from_plane']<-5].index\n",
    "square_points = square_points.drop(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scan_angle_dist_from_plane(df,distance_metric):\n",
    "    x = abs(df['scan_angle'])*.006\n",
    "    y = df[distance_metric]\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.plot(x,y,'xb')\n",
    "    z = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(x,p(x),\"r--\")\n",
    "    plt.xlabel(\"Scan angle (degrees)\")\n",
    "    plt.ylabel(\"Point distance from plane\")\n",
    "    print(\"y={:2.8f}x+{:2.8f}\".format(z[0],z[1]))\n",
    "    plt.title(\"Scan Angle vs Distance to Fitted Plane\")\n",
    "plot_scan_angle_dist_from_plane(square_points,'dist_from_plane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(square_points)),square_points['scan_angle'],'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scan_angle_dist_from_plane(square_points,'dist_from_flat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart from slides showing points per run\n",
    "labels = [pt[0][11:-4] for pt in pts_from_scan]\n",
    "num_points = [pt[1]+.01 for pt in pts_from_scan]\n",
    "plt.figure(figsize=(25,20))\n",
    "plt.bar(labels,num_points,)\n",
    "plt.xticks(rotation=45,fontsize=20)\n",
    "plt.yticks(np.arange(0, max(num_points), step=(max(num_points)/10)),fontsize=20)\n",
    "plt.ylabel(\"Number of points from run\",fontsize=20)\n",
    "plt.xlabel(\"Run ID\",fontsize=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
