{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from laspy.file import File\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0,'..') # So we can import point_density_functions from parent directory\n",
    "from point_density_functions import *\n",
    "%load_ext autoreload\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dublin tile\n",
    "file_dir = '../../Data/dublin_sample/'\n",
    "# filename = 'bank_of_ireland.las'\n",
    "filename = 'dublin_horizontal.las'\n",
    "pt_files_vertical = ['las_points_bank_of_ireland.lz']\n",
    "                    \n",
    "\n",
    "\n",
    "# Corresponds to LAS 1.2 Point Data Record Format 1\n",
    "columns_dublin_pt_cloud = [\n",
    "    'X',\n",
    "    'Y',\n",
    "    'Z',\n",
    "    'intensity',\n",
    "    'return_number_byte',\n",
    "    'classification_byte',\n",
    "    'scan_angle',\n",
    "    'user_data',\n",
    "    'pt_src_id',\n",
    "    'gps_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works\n",
    "# for file in filenames:\n",
    "#     create_df_hd5(file_dir,file,columns_dublin_pt_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the lz file\n",
    "# bank_df = pd.read_hdf(file_dir+'las_points_bank_of_ireland.lz')\n",
    "# horiz_df = pd.read_hdf(file_dir+'las_points_dublin_horizontal.lz')\n",
    "# horiz_df = pd.read_hdf(file_dir+'las_points_dublin_horizontal.lz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supporting Functions for Horizontal Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Big parking lot rectangle\n",
    "def rectangle(pt1,pt2,y_length,x_length):\n",
    "    '''\n",
    "    Function returns uv_inv and w, for use in selecting points within the rectangle\n",
    "    Note: This function only works in 2D (horizontal plane)\n",
    "    Inputs:\n",
    "    pt1 - 2x1 numpy array with x and y coordinate for bottom point\n",
    "    pt2 - 2xy numpy array with x and y coordinate for top point\n",
    "    y_length - bottom-to-top length (positive is in direction of top from bottom point)\n",
    "    x_length - left-to-right length (positive means pts are on left border, negative means they're on right)\n",
    "    Outputs:\n",
    "    uv_inv: 2xy numpy array - u and v are the sides of the rectangle.  uv = [u v] is a matrix with u and v as columns.\n",
    "    w: 2x1 numpy array with (x,y) coordinates of reference (bottom) point.\n",
    "    \n",
    "    Reference: https://math.stackexchange.com/questions/190111/how-to-check-if-a-point-is-inside-a-rectangle\n",
    "    '''\n",
    "    unit_u = (pt2 - pt1)/np.linalg.norm(pt2-pt1)\n",
    "    unit_v = np.array([unit_u[1],-1*unit_u[0]])\n",
    "    u = unit_u*y_length\n",
    "    v = unit_v*x_length\n",
    "    uv = np.array([u,v]).T\n",
    "    uv_inv = np.linalg.inv(uv)\n",
    "    w = pt1\n",
    "    return uv_inv,w,unit_u,unit_v\n",
    "\n",
    "# rectangle_points_laefer = grab_points_big_rect(pt_files,file_dir,uv_inv,w)\n",
    "# rectangle_points_nyc = grab_points_big_rect(nyc_pt_file,nyc_file_dir,uv_inv,w)\n",
    "# rectangle_points_usgs = grab_points_big_rect(usgs_pt_files,usgs_file_dir,uv_inv,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(SampleFlightList,pt_density_laefer_list,feet_from_point):\n",
    "    # Laefer\n",
    "    sd_laefer_total = np.mean([ss.flight_list_laefer[0].sd_dist for ss in SampleFlightList])\n",
    "    sd_laefer_sample = np.mean([ss.flight_list_laefer[1].sd_dist for ss in SampleFlightList])\n",
    "    avg_flight_paths_laefer = np.mean([len(flight.flight_list_laefer) for flight in SampleFlightList])-2\n",
    "    sd_flight_paths_laefer = np.std([len(flight.flight_list_laefer) for flight in SampleFlightList])\n",
    "    phis_laefer_total = [ss.phi_laefer_total for ss in SampleFlightList]\n",
    "    phis_laefer_sample = [ss.phi_laefer_sample for ss in SampleFlightList]\n",
    "\n",
    "    print(\"2019 scan (Horizontal, {} samples): \\n\".format(len(SampleFlightList))+\"*\"*30)\n",
    "    print(\"Avg points per square: {:2.2f} points\".format((4 * feet_from_point**2)*np.mean(pt_density_laefer_list)))\n",
    "    print(\"Avg density: {:2.4f} pts/m^2 (SD: {:2.4f})\".format(np.mean(pt_density_laefer_list),np.std(pt_density_laefer_list)))\n",
    "    print(\"Avg number of flight paths per square: {:2.4f} (SD: {:2.4f})\".format(avg_flight_paths_laefer,sd_flight_paths_laefer))\n",
    "    print(\"\\nphi_total: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_laefer_total),np.std(phis_laefer_total)))\n",
    "    print(\"phi_sample: {:2.4f} (SD: {:2.4f})\".format(np.mean(phis_laefer_sample),np.std(phis_laefer_sample)))\n",
    "    print(\"Total point dist from plane, SD: {:2.4f} m\".format(sd_laefer_total))\n",
    "    print(\"Avg flight point dist from plane, SD: {:2.4f} m\".format(sd_laefer_total/np.mean(phis_laefer_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling squares and Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregators\n",
    "pt_density_list = []\n",
    "avg_height_diff = []\n",
    "sd_height = []\n",
    "SampleFlightList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_files_horizontal = ['las_points_leinster_house_lot_1.lz', \\\n",
    "                       'las_points_leinster_house_lot_2.lz', \\\n",
    "                       'las_points_stephensgreen_walking.lz', \\\n",
    "                       'las_points_city_hall_square.lz'\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Horizontal - City Hall Square\n",
    "pt1 = np.array([315483.8333,234007.297119,6.139])\n",
    "pt2 = np.array([315481.253052,234021.491943,6.034])\n",
    "u_length = np.linalg.norm(pt2-pt1) # ~14.1m\n",
    "v_length = 14\n",
    "pt3 = np.array([3.15497605e+05, 2.34009799e+05, 5.87147628e+00]) # Backed into from previous 2D v calculation\n",
    "uv_inv,w,unit_u,unit_v = rectangle(pt1[:2],pt2[:2],u_length,v_length)\n",
    "\n",
    "rectangle_points = pd.read_hdf(file_dir+pt_files_horizontal[3])\n",
    "rectangle_points = rectangle_points[(rectangle_points['z_scaled']<6.2)& \\\n",
    "                                                  (rectangle_points['z_scaled']>5.7)]\n",
    "\n",
    "rectangle_points['flight_id'] = rectangle_points['pt_src_id']\n",
    "# Norm from any 3 points on plane\n",
    "# a = np.array([315485.316040,234016.809082,6.011])\n",
    "# b = np.array([315483.8333,234007.297119,6.139])\n",
    "# c = np.array([315493.062,234019.477051,5.84700])\n",
    "# norm = np.cross(c - b,(a-b))\n",
    "\n",
    "# bottom_vec = (np.cross(norm,(pt2 - pt1)))/np.linalg.norm(np.cross(norm,(pt2 - pt1)))\n",
    "# bottom_right_pt = pt1 - bottom_vec*v_length\n",
    "# bottom_right_pt\n",
    "print(u_length*v_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create center_points\n",
    "feet_from_point = 0.5\n",
    "border = []\n",
    "border.append(1.05*feet_from_point/u_length)\n",
    "border.append(1.05*feet_from_point/v_length)\n",
    "center_points = center_point_sample(2800,pt1,pt2,pt3,u_length=u_length,v_length=v_length,border=border)\n",
    "mean_z = rectangle_points['z_scaled'].mean()\n",
    "pts_thrown_out = 0\n",
    "\n",
    "for center_point in center_points:\n",
    "    square_points = in_horizontal_square(rectangle_points,center_point[:2],feet_from_point)\n",
    "    \n",
    "    flight_count = len(square_points['flight_id'].unique())\n",
    "   \n",
    "    # If z_max > 6.2, for any point in square skip it\n",
    "    if square_points['z_scaled'].max()<6.2:\n",
    "        # Statistics!\n",
    "                \n",
    "        # Point density\n",
    "        num_points = square_points.shape[0]\n",
    "        pt_density_list.append(num_points / (4 * feet_from_point**2))        \n",
    "        \n",
    "        # Flight path specifics\n",
    "        flight_list = create_flight_list(square_points)\n",
    "        # Create SampleSquare from all flight passes\n",
    "        ss = SampleSquare(flight_list, x = center_point[0], \\\n",
    "                          y=center_point[1],feet_from_point=feet_from_point)\n",
    "        # Collect SampleSquares\n",
    "        SampleFlightList.append(ss)\n",
    "        \n",
    "    else:\n",
    "        pts_thrown_out +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_out(SampleFlightList,pt_density_list,feet_from_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df = pd.DataFrame([flight.error_decomp_laefer for flight in SampleFlightList],columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "\n",
    "cw_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Horizontal - stephensgreen walking\n",
    "pt1 = np.array([315925.706055,233508.467041,11.846])\n",
    "pt2 = np.array([315920.5,233521.358887,11.669])\n",
    "u_length = np.linalg.norm(pt2-pt1) # ~14m\n",
    "v_length = 5\n",
    "pt3 = np.array([3.15930342e+05, 2.33510339e+05, 1.18615851e+01]) # Backed into from previous 2D v calculation\n",
    "uv_inv,w,unit_u,unit_v = rectangle(pt1[:2],pt2[:2],u_length,v_length)\n",
    "\n",
    "rectangle_points = pd.read_hdf(file_dir+pt_files_horizontal[2])\n",
    "\n",
    "rectangle_points['flight_id'] = rectangle_points['pt_src_id']\n",
    "# Norm from any 3 points on plane\n",
    "# a = pt1\n",
    "# b = np.array([315929.901978,233511.337891,11.855])\n",
    "# c = np.array([315924.854004,233518.982910,11.796])\n",
    "# norm = np.cross(c - b,(a-b))\n",
    "\n",
    "# bottom_vec = (np.cross(norm,(pt2 - pt1)))/np.linalg.norm(np.cross(norm,(pt2 - pt1)))\n",
    "# bottom_right_pt = pt1 - bottom_vec*v_length\n",
    "# bottom_right_pt\n",
    "print(u_length*v_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create center_points\n",
    "feet_from_point = 0.5\n",
    "border = []\n",
    "border.append(1.05*feet_from_point/u_length)\n",
    "border.append(1.05*feet_from_point/v_length)\n",
    "center_points = center_point_sample(2500,pt1,pt2,pt3,u_length=u_length,v_length=v_length,border=border)\n",
    "mean_z = rectangle_points['z_scaled'].mean()\n",
    "pts_thrown_out = 0\n",
    "\n",
    "for center_point in center_points:\n",
    "    square_points = in_horizontal_square(rectangle_points,center_point[:2],feet_from_point)\n",
    "    \n",
    "    flight_count = len(square_points['flight_id'].unique())\n",
    "   \n",
    "    # If z_max > 10, <6 for any dataset, skip it\n",
    "    if square_points['z_scaled'].max()<mean_z+1:\n",
    "        # Statistics!\n",
    "                \n",
    "        # Point density\n",
    "        num_points = square_points.shape[0]\n",
    "        pt_density_list.append(num_points / (4 * feet_from_point**2))        \n",
    "        \n",
    "        # Flight path specifics\n",
    "        flight_list = create_flight_list(square_points)\n",
    "        # Create SampleSquare from all flight passes\n",
    "        ss = SampleSquare(flight_list, x = center_point[0], \\\n",
    "                          y=center_point[1],feet_from_point=feet_from_point)\n",
    "        # Collect SampleSquares\n",
    "        SampleFlightList.append(ss)\n",
    "        \n",
    "    else:\n",
    "        pts_thrown_out +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_out(SampleFlightList,pt_density_list,feet_from_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df = pd.DataFrame([flight.error_decomp_laefer for flight in SampleFlightList],columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "\n",
    "cw_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Horizontal - leinster house lot 1\n",
    "pt1 = np.array([316315.836914,233643.625977,10.56])\n",
    "pt2 = np.array([316286.843994,233655.563965,10.523])\n",
    "u_length = np.linalg.norm(pt2-pt1) # ~31m\n",
    "v_length = 4.9\n",
    "pt3 = np.array([3.16317702e+05, 2.33648155e+05, 1.07051393e+01]) # Backed into from previous 2D v calculation\n",
    "uv_inv,w,unit_u,unit_v = rectangle(pt1[:2],pt2[:2],u_length,v_length)\n",
    "\n",
    "rectangle_points = pd.read_hdf(file_dir+pt_files_horizontal[0])\n",
    "# rectangle_points = rectangle_points[(rectangle_points['z_scaled']<6.2)& \\\n",
    "#                                                   (rectangle_points['z_scaled']>5.7)]\n",
    "\n",
    "rectangle_points['flight_id'] = rectangle_points['pt_src_id']\n",
    "# # # Norm from any 3 points on plane\n",
    "# a = pt1\n",
    "# b = np.array([316290.827881,233658.487061,10.519])\n",
    "# c = np.array([316312.126953,233650.197998,10.664])\n",
    "# norm = np.cross(c - b,(a-b))\n",
    "\n",
    "# bottom_vec = (np.cross(norm,(pt2 - pt1)))/np.linalg.norm(np.cross(norm,(pt2 - pt1)))\n",
    "# bottom_right_pt = pt1 + bottom_vec*v_length\n",
    "# print(bottom_right_pt)\n",
    "print(u_length*v_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create center_points\n",
    "feet_from_point = 0.5\n",
    "border = []\n",
    "border.append(1.05*feet_from_point/u_length)\n",
    "border.append(1.05*feet_from_point/v_length)\n",
    "center_points = center_point_sample(2500,pt1,pt2,pt3,u_length=u_length,v_length=v_length,border=border)\n",
    "mean_z = rectangle_points['z_scaled'].mean()\n",
    "pts_thrown_out = 0\n",
    "\n",
    "for center_point in center_points:\n",
    "    square_points = in_horizontal_square(rectangle_points,center_point[:2],feet_from_point)\n",
    "    \n",
    "    flight_count = len(square_points['flight_id'].unique())\n",
    "   \n",
    "    # If z_max > 10, <6 for any dataset, skip it\n",
    "    if square_points['z_scaled'].max()<mean_z+1:\n",
    "        # Statistics!\n",
    "                \n",
    "        # Point density\n",
    "        num_points = square_points.shape[0]\n",
    "        pt_density_list.append(num_points / (4 * feet_from_point**2))        \n",
    "        \n",
    "        # Flight path specifics\n",
    "        flight_list = create_flight_list(square_points)\n",
    "        # Create SampleSquare from all flight passes\n",
    "        ss = SampleSquare(flight_list, x = center_point[0], \\\n",
    "                          y=center_point[1],feet_from_point=feet_from_point)\n",
    "        # Collect SampleSquares\n",
    "        SampleFlightList.append(ss)\n",
    "        \n",
    "    else:\n",
    "        pts_thrown_out +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_out(SampleFlightList,pt_density_list,feet_from_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df = pd.DataFrame([flight.error_decomp_laefer for flight in SampleFlightList],columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "\n",
    "cw_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Horizontal - leinster house lot 2\n",
    "pt1 = np.array([316307.085938,233679.488037,10.607])\n",
    "pt2 = np.array([316293.058105,233682.521973,10.478])\n",
    "u_length = np.linalg.norm(pt2-pt1) # ~14m\n",
    "v_length = 4.5\n",
    "pt3 = np.array([3.16307932e+05, 2.33683397e+05, 1.05349566e+01]) # Backed into from previous 2D v calculation\n",
    "uv_inv,w,unit_u,unit_v = rectangle(pt1[:2],pt2[:2],u_length,v_length)\n",
    "\n",
    "rectangle_points = pd.read_hdf(file_dir+pt_files_horizontal[1])\n",
    "rectangle_points = rectangle_points[(rectangle_points['z_scaled']<10.7)& \\\n",
    "                                                  (rectangle_points['z_scaled']>10.4)]\n",
    "\n",
    "rectangle_points['flight_id'] = rectangle_points['pt_src_id']\n",
    "# # Norm from any 3 points on plane\n",
    "# a = pt1\n",
    "# b = np.array([316294.368896,233686.305908,10.505])\n",
    "# c = np.array([316307.704102,233681.699951,10.566])\n",
    "# norm = np.cross(c - b,(a-b))\n",
    "\n",
    "# bottom_vec = (np.cross(norm,(pt2 - pt1)))/np.linalg.norm(np.cross(norm,(pt2 - pt1)))\n",
    "# bottom_right_pt = pt1 + bottom_vec*v_length\n",
    "# print(bottom_right_pt)\n",
    "print(u_length*v_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create center_points\n",
    "feet_from_point = 0.5\n",
    "border = []\n",
    "border.append(1.05*feet_from_point/u_length)\n",
    "border.append(1.05*feet_from_point/v_length)\n",
    "center_points = center_point_sample(2500,pt1,pt2,pt3,u_length=u_length,v_length=v_length,border=border)\n",
    "mean_z = rectangle_points['z_scaled'].mean()\n",
    "pts_thrown_out = 0\n",
    "\n",
    "for center_point in center_points:\n",
    "    square_points = in_horizontal_square(rectangle_points,center_point[:2],feet_from_point)\n",
    "    \n",
    "    flight_count = len(square_points['flight_id'].unique())\n",
    "   \n",
    "    # If z_max > 10, <6 for any dataset, skip it\n",
    "    if square_points['z_scaled'].max()<mean_z+1:\n",
    "        # Statistics!\n",
    "                \n",
    "        # Point density\n",
    "        num_points = square_points.shape[0]\n",
    "        pt_density_list.append(num_points / (4 * feet_from_point**2))        \n",
    "        \n",
    "        # Flight path specifics\n",
    "        flight_list = create_flight_list(square_points)\n",
    "        # Create SampleSquare from all flight passes\n",
    "        ss = SampleSquare(flight_list, x = center_point[0], \\\n",
    "                          y=center_point[1],feet_from_point=feet_from_point)\n",
    "        # Collect SampleSquares\n",
    "        SampleFlightList.append(ss)\n",
    "        \n",
    "    else:\n",
    "        pts_thrown_out +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_out(SampleFlightList,pt_density_list,feet_from_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df = pd.DataFrame([flight.error_decomp_laefer for flight in SampleFlightList],columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "\n",
    "cw_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flight pass height distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all heights by flight id\n",
    "from collections import defaultdict\n",
    "\n",
    "flight_id_dict = defaultdict(list)\n",
    "\n",
    "for sample_num in range(len(SampleFlightList)):\n",
    "\n",
    "    dd = dict([(fp.flight_id,fp.h) for fp in SampleFlightList[sample_num].flight_list_laefer[2:]])\n",
    "    for key in dd.keys():\n",
    "        flight_id_dict[key].append(dd[key])\n",
    "\n",
    "h_dist = []\n",
    "for key in flight_id_dict.keys():\n",
    "    mean_h = np.mean([abs(v) for v in flight_id_dict[key]])\n",
    "    h_dist.append(1000*mean_h)\n",
    "    print(\"{:2}: {:2.4f}\".format(key,mean_h))\n",
    "\n",
    "# Plot distribution of mean abs(heights)\n",
    "plt.hist(h_dist,density=True)\n",
    "plt.title(\"Dublin Horizontal Surfaces\",fontsize=12)\n",
    "plt.xlabel(\"Mean absolute height (mm)\",fontsize=12)\n",
    "plt.ylabel(\"Distribution of flight passes\",fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pt_density_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find the bottom right point - Water front parking lot\n",
    "\n",
    "# # Norm from any 3 points on plane\n",
    "# a = np.array([316640.62207,234591.931152,2.344])\n",
    "# b = np.array([316647.333984,234614.423828,2.35])\n",
    "# c = np.array([316662.176025,234602.286133,2.353])\n",
    "# norm = np.cross(c - b,(a-b))\n",
    "\n",
    "# bottom_vec = (np.cross(norm,(pt2 - pt1)))/np.linalg.norm(np.cross(norm,(pt2 - pt1)))\n",
    "# bottom_right_pt = pt1 + bottom_vec*v_length\n",
    "# bottom_right_pt\n",
    "\n",
    "\n",
    "\n",
    "# ### Horizontal - Trinity College\n",
    "# pt1 = np.array([316056.643066,234068.340088,3.63])\n",
    "# pt2 = np.array([316057.231934,234095.118896,3.649])\n",
    "# u_length = np.linalg.norm(pt2-pt1)\n",
    "# v_length = 35\n",
    "# pt3 = np.array([3.16091635e+05, 2.34067571e+05, 3.63853685e+00]) # Backed into from previous 2D v calculation\n",
    "# uv_inv,w,unit_u,unit_v = rectangle(pt1[:2],pt2[:2],u_length,v_length)\n",
    "\n",
    "# rectangle_points = pd.read_hdf(file_dir+pt_files_horizontal[1])\n",
    "# rectangle_points = rectangle_points[(rectangle_points['z_scaled']<6)& \\\n",
    "#                                                   (rectangle_points['z_scaled']>0)]\n",
    "\n",
    "# rectangle_points['flight_id'] = rectangle_points['pt_src_id']\n",
    "\n",
    "\n",
    "# # Water front parking lot\n",
    "# pt1 = np.array([316638.8955996,234588.800781,2.344])\n",
    "# pt2 = np.array([316641.493896,234618.171875,2.344])\n",
    "# u_length = np.linalg.norm(pt2-pt1)\n",
    "# v_length = 22\n",
    "# pt3 = np.array([3.16660810e+05, 2.34586862e+05, 2.35108175e+00]) # Backed into from previous 2D v calculation\n",
    "# uv_inv,w,unit_u,unit_v = rectangle(pt1[:2],pt2[:2],u_length,v_length)\n",
    "\n",
    "# rectangle_points = pd.read_hdf(file_dir+pt_files_horizontal[0])\n",
    "# rectangle_points = rectangle_points[(rectangle_points['z_scaled']<6)& \\\n",
    "#                                                   (rectangle_points['z_scaled']>0)]\n",
    "\n",
    "# rectangle_points['flight_id'] = rectangle_points['pt_src_id']\n",
    "\n",
    "# ### Horizontal - Parking lot #1\n",
    "\n",
    "# pt1 = np.array([315745.696045,233566.8999,33.483002])\n",
    "# pt2 = np.array([315749.807007,233580.496094,33.527])\n",
    "# u_length = np.linalg.norm(pt2-pt1)\n",
    "# v_length = 18\n",
    "# pt3 = np.array([3.15762912e+05, 2.33561697e+05, 3.27362030e+01]) # Backed into from previous 2D v calculation\n",
    "# uv_inv,w,unit_u,unit_v = rectangle(pt1[:2],pt2[:2],u_length,v_length)\n",
    "\n",
    "\n",
    "# a = np.array([315749.807007,233580.496094,33.527])\n",
    "# b = np.array([315751.82605,233572.446045,33.54999])\n",
    "# c = np.array([315757.93396,233557.280029,33.483002])\n",
    "\n",
    "# rectangle_points = pd.read_hdf(file_dir+pt_files_horizontal[2])\n",
    "\n",
    "# rectangle_points['flight_id'] = rectangle_points['pt_src_id']\n",
    "\n",
    "\n",
    "\n",
    "### Horizontal - Parking lot #2\n",
    "\n",
    "# pt1 = np.array([315704.744019,233566.291992,33.449001])\n",
    "# pt2 = np.array([315714.766968,233597.696045,33.535999])\n",
    "# u_length = np.linalg.norm(pt2-pt1)\n",
    "# v_length = 10\n",
    "# pt3 = np.array([315714.271, 233563.251, 3.34565345e+01]) # Backed into from previous 2D v calculation\n",
    "# uv_inv,w,unit_u,unit_v = rectangle(pt1[:2],pt2[:2],u_length,v_length)\n",
    "\n",
    "\n",
    "# a = np.array([315714.766968,233597.696045,33.535999])\n",
    "# b = np.array([315724.612061,233592.666016,33.541])\n",
    "# c = np.array([315714.959961,233571.768066,33.498001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical density\n",
    "Identifying point at corner of building to quantify the vertical point density.  \n",
    "Center point: \t40.645854, \t-74.025299  \n",
    "Easting - 977229.375  \n",
    "Northing - 174579.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''flight_id_mapping = {\n",
    "\t\"F_150326_122941\":7,\n",
    "\t\"F_150326_123430\":8,\n",
    "\t\"F_150326_123922\": 9,\n",
    "\t\"F_150326_124415\":10,\n",
    "\t\"F_150326_154909\":32,\n",
    "\t\"F_150326_155238\":33,\n",
    "\t\"F_ 150326_155529\":34,\n",
    "\t\"F_150326_155833\":35\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the bottom right point\n",
    "# a = (np.cross(norm,(top_left_pt - bottom_left_pt)))/np.linalg.norm(np.cross(norm,(top_left_pt - bottom_left_pt)))\n",
    "# bottom_right_pt = bottom_left_pt + a*v_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vert_density(square_points, \n",
    "                 middle_pt, \n",
    "                 right_pt, \n",
    "                 left_pt, \n",
    "                 bottom_left_pt,\n",
    "                 u_length,\n",
    "                 v_length,\n",
    "                 feet_from_pt,\n",
    "                 SampleFlightList=[],\n",
    "                 pt_density_list=[],\n",
    "                 sd_wall=[],\n",
    "                 wall_face=None\n",
    "                 ): \n",
    "    \n",
    "    # Calculate norm_vector from 3 points, to define plane and extract the wall face\n",
    "    norm = np.cross(middle_pt - right_pt,(left_pt-right_pt))\n",
    "    norm = norm / np.linalg.norm(norm)\n",
    "\n",
    "    # Extract the wall face, above 6.5m and below 34m to avoid roof and ground points\n",
    "    wall_face = grab_wall_face(square_points,norm, middle_pt,6.5,34,5e-1)\n",
    "\n",
    "    # Fit a plane, create norm_vector, calculate dist_from_plane\n",
    "    norm_vector,_,wall_face,_ = plane_fit(wall_face) \n",
    "    \n",
    "    # Sample points in wall\n",
    "    #Note 0.28 border_v comes from: (3.5/2) (half-meter feet_from_point) / v_length (with some buffer)\n",
    "    feet_from_pt_v = 1\n",
    "    feet_from_pt_u = 1\n",
    "    border = [0,0]\n",
    "    border[0] = 1.05*(feet_from_pt_u / u_length)\n",
    "    border[1] = 1.05*(feet_from_pt_v / v_length)\n",
    "\n",
    "    center_points = center_point_sample(10000,\n",
    "                        bottom_left_pt,top_left_pt,bottom_right_pt,\n",
    "                        u_length=u_length,v_length=v_length,border=border)\n",
    "    \n",
    "    # Main Loop through the sample points\n",
    "    pts_thrown_out = 0\n",
    "\n",
    "    for center_point in center_points:\n",
    "        square_points,pt_density = in_vertical_square(wall_face,\n",
    "                                                    norm_vector,\n",
    "                                                    center_point,\n",
    "                                                    feet_from_pt_v,\n",
    "                                                    feet_from_pt_u)\n",
    "        flight_count = len(square_points['flight_id'].unique())\n",
    "        \n",
    "        # Statistics!\n",
    "\n",
    "        # Point density\n",
    "        num_points = square_points.shape[0]\n",
    "        pt_density_list.append(pt_density)        \n",
    "        \n",
    "\n",
    "        # Fit a plane\n",
    "        if square_points.shape[0] > 0:\n",
    "            norm_vector,_,square_points,_ = plane_fit(square_points)\n",
    "            flight_list = create_flight_list(square_points)\n",
    "        else:\n",
    "            flight_list=None\n",
    "\n",
    "        # Flight path specifics\n",
    "        ss = SampleSquare(flight_list, x = center_point[0], \\\n",
    "                          y=center_point[1],z=center_point[2],feet_from_point=[feet_from_pt_v,feet_from_pt_u])\n",
    "        SampleFlightList.append(ss)    \n",
    "    \n",
    "    # Print outs\n",
    "    print(\"Pts in dataset: {}\".format(wall_face.shape[0]))\n",
    "    \n",
    "    print(\"Vertical face point density over {:d} samples\".format(len(pt_density_list)))\n",
    "    print(\"*\"*30)\n",
    "    print(\"Avg density: {:2.4f} (SD: {:2.4f})\".format(np.mean(pt_density_list),np.std(pt_density_list)))\n",
    "    \n",
    "    return SampleFlightList, wall_face, pt_density_list, sd_wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point count in new square from las_points_bank_of_ireland.lz: 23213\n",
      "Total point count in square: 23213\n",
      "Size of square: 68.89 sq ft\n",
      "Point density: 336.96 points / sq ft\n"
     ]
    }
   ],
   "source": [
    "# Main wall on Bank of Ireland\n",
    "middle_pt = np.array([316566.945068,234635.687012,17.288])\n",
    "\n",
    "# Extract from all files, the points within feet_from_pt in the xy-plane of the middle wall point\n",
    "square_points_vertical = grab_points(pt_files_vertical,file_dir,middle_pt[0],middle_pt[1],4.15)\n",
    "square_points_vertical['flight_id'] = square_points_vertical['pt_src_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the norm\n",
    "middle_pt = np.array([316566.945068,234635.687012,17.288])\n",
    "right_pt = np.array([316572.521973,234635.230957,29.448999])\n",
    "left_pt = np.array([316563.1521, 234635.970215, 22.895])\n",
    "bottom_left_pt= np.array([316563.1521, 234635.970215, 8.895])\n",
    "top_left_pt = np.array([316563.1521, 234635.970215, 33.895])\n",
    "bottom_right_pt = np.array([316571.4272615415,234635.3285753328,8.895])\n",
    "feet_from_pt = 4.15\n",
    "u_length = 25\n",
    "v_length = 8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregators\n",
    "pt_density_list= []\n",
    "sd_wall=[]\n",
    "SampleFlightList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSEV: \",(.0166/.0291)-1)\n",
    "print(\"C: \",.0072/.025-1)\n",
    "print(\"W: \",.01457/.0149-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/python-virtual-environments/data/lib/python3.6/site-packages/pandas/core/indexing.py:376: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/home/michael/python-virtual-environments/data/lib/python3.6/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pts in dataset: 6713\n",
      "Vertical face point density over 10000 samples\n",
      "******************************\n",
      "Avg density: 29.8052 (SD: 4.2907)\n"
     ]
    }
   ],
   "source": [
    "SampleFlightList, wall_face, pt_density_list, sd_wall = \\\n",
    "vert_density(square_points_vertical, \n",
    "                 middle_pt, \n",
    "                 right_pt, \n",
    "                 left_pt, \n",
    "                 bottom_left_pt, \n",
    "                 u_length,\n",
    "                 v_length,\n",
    "                 feet_from_pt,\n",
    "                 SampleFlightList,    \n",
    "                 pt_density_list,\n",
    "                 sd_wall\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Density for flight id 7: pts_bins\n",
      "3     0.000000\n",
      "6     0.000000\n",
      "9     0.000000\n",
      "12    0.000000\n",
      "15    0.000000\n",
      "18    0.000000\n",
      "21    0.000000\n",
      "24    0.000000\n",
      "27    0.000000\n",
      "30    0.040161\n",
      "33    0.000000\n",
      "Name: X, dtype: float64\n",
      "\n",
      "\n",
      "Density for flight id 8: pts_bins\n",
      "3     0.000000\n",
      "6     2.449799\n",
      "9     2.088353\n",
      "12    1.887550\n",
      "15    2.851406\n",
      "18    2.570281\n",
      "21    2.570281\n",
      "24    2.449799\n",
      "27    2.610442\n",
      "30    2.329317\n",
      "33    0.401606\n",
      "Name: X, dtype: float64\n",
      "\n",
      "\n",
      "Density for flight id 9: pts_bins\n",
      "3      0.000000\n",
      "6      9.156627\n",
      "9      9.156627\n",
      "12     9.437751\n",
      "15     9.678715\n",
      "18    10.080321\n",
      "21     9.959839\n",
      "24    10.240964\n",
      "27    10.200803\n",
      "30    10.040161\n",
      "33     1.807229\n",
      "Name: X, dtype: float64\n",
      "\n",
      "\n",
      "Density for flight id 32: pts_bins\n",
      "3     0.000000\n",
      "6     0.000000\n",
      "9     0.000000\n",
      "12    0.000000\n",
      "15    0.000000\n",
      "18    0.000000\n",
      "21    0.000000\n",
      "24    0.000000\n",
      "27    0.000000\n",
      "30    0.040161\n",
      "33    0.040161\n",
      "Name: X, dtype: float64\n",
      "\n",
      "\n",
      "Density for flight id 33: pts_bins\n",
      "3      0.000000\n",
      "6     13.654618\n",
      "9     13.132530\n",
      "12    13.574297\n",
      "15    13.212851\n",
      "18    13.654618\n",
      "21    13.895582\n",
      "24    11.124498\n",
      "27     6.706827\n",
      "30     2.771084\n",
      "33     0.160643\n",
      "Name: X, dtype: float64\n",
      "\n",
      "\n",
      "Density for flight id 34: pts_bins\n",
      "3     0.000000\n",
      "6     5.783133\n",
      "9     5.702811\n",
      "12    5.903614\n",
      "15    5.823293\n",
      "18    6.184739\n",
      "21    6.265060\n",
      "24    6.345382\n",
      "27    6.265060\n",
      "30    6.465863\n",
      "33    0.843373\n",
      "Name: X, dtype: float64\n",
      "\n",
      "\n",
      "Density for flight id 35: pts_bins\n",
      "3     0.000000\n",
      "6     0.000000\n",
      "9     0.000000\n",
      "12    0.000000\n",
      "15    0.000000\n",
      "18    0.000000\n",
      "21    0.000000\n",
      "24    0.000000\n",
      "27    0.000000\n",
      "30    0.040161\n",
      "33    0.000000\n",
      "Name: X, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/python-virtual-environments/data/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_ids = wall_face['pt_src_id'].unique()\n",
    "wall_face['pts_bins'] = pd.cut((wall_face['z_scaled']-3.5), \\\n",
    "                                      bins=range(0,36,3), \\\n",
    "                                      labels=range(3,36,3))\n",
    "\n",
    "for f in flight_ids:\n",
    "    flight_pts = wall_face[wall_face['pt_src_id']==f]\n",
    "    # Num of points\n",
    "    print(\"\\n\\nDensity for flight id {}:\".format(f),flight_pts.groupby('pts_bins')['X'].count()/(3*v_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33    4908\n",
       "9     4814\n",
       "34    4436\n",
       "8     3979\n",
       "35    2668\n",
       "7     1280\n",
       "32     949\n",
       "10     179\n",
       "Name: pt_src_id, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_points_vertical['pt_src_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg number of flight paths per square: 3.94\n"
     ]
    }
   ],
   "source": [
    "avg_flight_paths_laefer = []\n",
    "for flight in SampleFlightList:\n",
    "    try:\n",
    "        avg_flight_paths_laefer.append(len(flight.flight_list_laefer)-2)\n",
    "    except AttributeError:\n",
    "        avg_flight_paths_laefer.append(0)\n",
    "\n",
    "print(\"Avg number of flight paths per square: {:2.2f}\".format(np.mean(avg_flight_paths_laefer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>laefer_C</th>\n",
       "      <th>laefer_W</th>\n",
       "      <th>laefer_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.007222</td>\n",
       "      <td>0.014568</td>\n",
       "      <td>0.016664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003894</td>\n",
       "      <td>0.008548</td>\n",
       "      <td>0.008657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.008448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.005352</td>\n",
       "      <td>0.010446</td>\n",
       "      <td>0.011939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.006793</td>\n",
       "      <td>0.011545</td>\n",
       "      <td>0.013852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.008411</td>\n",
       "      <td>0.012940</td>\n",
       "      <td>0.015688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.052574</td>\n",
       "      <td>0.057174</td>\n",
       "      <td>0.058200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           laefer_C      laefer_W   laefer_rmse\n",
       "count  10000.000000  10000.000000  10000.000000\n",
       "mean       0.007222      0.014568      0.016664\n",
       "std        0.003894      0.008548      0.008657\n",
       "min        0.001116      0.007784      0.008448\n",
       "25%        0.005352      0.010446      0.011939\n",
       "50%        0.006793      0.011545      0.013852\n",
       "75%        0.008411      0.012940      0.015688\n",
       "max        0.052574      0.057174      0.058200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw = []\n",
    "for flight in SampleFlightList:\n",
    "    try:\n",
    "        cw.append(flight.error_decomp_laefer)\n",
    "    except AttributeError:\n",
    "        print(\"Missing\")\n",
    "#     cw_df = pd.DataFrame(cw,columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "    cw_df = pd.DataFrame(cw,columns=['laefer_C','laefer_W','laefer_rmse'])\n",
    "\n",
    "(cw_df).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flight pass height distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8: 0.0193\n",
      " 9: 0.0055\n",
      "33: 0.0023\n",
      "34: 0.0032\n",
      " 7: 0.3011\n",
      "32: 0.2749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Distribution of flight passes')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Collect all heights by flight id\n",
    "from collections import defaultdict\n",
    "\n",
    "flight_id_dict = defaultdict(list)\n",
    "\n",
    "for sample_num in range(len(SampleFlightList)):\n",
    "\n",
    "    dd = dict([(fp.flight_id,fp.h) for fp in SampleFlightList[sample_num].flight_list_laefer[2:]])\n",
    "    for key in dd.keys():\n",
    "        flight_id_dict[key].append(dd[key])\n",
    "\n",
    "h_dist = []\n",
    "for key in flight_id_dict.keys():\n",
    "    mean_h = np.mean([abs(v) for v in flight_id_dict[key]])\n",
    "    h_dist.append(1000*mean_h)\n",
    "    print(\"{:2}: {:2.4f}\".format(key,mean_h))\n",
    "\n",
    "# Plot distribution of mean abs(heights)\n",
    "plt.hist(h_dist)\n",
    "plt.title(\"Dublin Horizontal Surfaces\",fontsize=12)\n",
    "plt.xlabel(\"Mean absolute height (mm)\",fontsize=12)\n",
    "plt.ylabel(\"Distribution of flight passes\",fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where on the  wall are the points from each flight pass? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=[20,22])\n",
    "for i,fid in enumerate(wall_face['flight_id'].unique()):\n",
    "    plt.subplot(4,3,i+1)\n",
    "    pts = wall_face[wall_face['flight_id']==fid]\n",
    "    hist = pd.cut(wall_face[wall_face['flight_id']==fid]['z_scaled'],bins=range(0,120,5),labels=range(5,120,5))\n",
    "#     plt.hist(hist,orientation='horizontal')\n",
    "    plt.plot(pts['x_scaled'],pts['z_scaled'],'x')\n",
    "    plt.yticks(np.arange(0,36,3))\n",
    "    plt.ylabel(\"Wall height (m)\")\n",
    "#     plt.xlabel(\"Point number (not spatial)\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.title(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_face['pt_src_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap by flight pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square_points_list, SampleFlightList, wall_face_list, pt_density_list, sd_wall_list\n",
    "h_dict = {\n",
    " 7:[],\n",
    " 8:[],\n",
    " 9:[],\n",
    " 32:[],\n",
    " 33:[],\n",
    " 34:[],\n",
    "}\n",
    "# Collect h for each flight pass in each sample square\n",
    "for sample_num in range(10000):\n",
    "    h_list = [fp.h for fp in SampleFlightList[sample_num].flight_list_laefer[2:]]\n",
    "    num_pt_list = [fp.num_points for fp in SampleFlightList[sample_num].flight_list_laefer[2:]]\n",
    "    flight_ids = [fp.flight_id for fp in SampleFlightList[sample_num].flight_list_laefer[2:]]\n",
    "    total_pts = SampleFlightList[sample_num].flight_list_laefer[0].num_points\n",
    "    for a in h_dict.keys():\n",
    "        if a in flight_ids:\n",
    "            ix = flight_ids.index(a)\n",
    "            h_dict[a].append(h_list[ix])\n",
    "        else:\n",
    "            h_dict[a].append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean height for each flight pass\n",
    "print(\"F_Id\\t Mean abs height\\n\",\"*\"*23)\n",
    "[print(\"{}: {:6.3f}\".format(k,np.nanmean([abs(h) for h in h_dict[k]]))) for k in h_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix of mean height differences across flight passes (would expect larger diffs for different directions)\n",
    "def create_h_matrix(h_dict):\n",
    "    h_matrix = np.zeros([len(h_dict),len(h_dict)])\n",
    "    for i,key1 in enumerate(h_dict.keys()):\n",
    "        for j,key2 in enumerate(h_dict.keys()):\n",
    "            h_matrix[i,j] = np.nanmean(abs(np.array(h_dict[key1]) - np.array(h_dict[key2])))\n",
    "    return h_matrix\n",
    "\n",
    "def h_heatmap(h_matrix,h_dict,fontsize=15,label='Flight ID'):\n",
    "    # Heatmap of the matrix\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.imshow(h_matrix, cmap='YlOrRd',vmin=0,vmax=0.6)\n",
    "    plt.xticks(np.arange(0,h_matrix.shape[0]),h_dict.keys(),fontsize=fontsize)\n",
    "    plt.yticks(np.arange(0,h_matrix.shape[0]),h_dict.keys(),fontsize=fontsize)\n",
    "    plt.ylabel(label,fontsize=fontsize)\n",
    "    plt.xlabel(label,fontsize=fontsize)\n",
    "    plt.ylim(h_matrix.shape[0]-0.5,-0.5)\n",
    "    plt.title(\"Mean Absolute h difference\",fontsize=fontsize)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "h_matrix = create_h_matrix(h_dict)\n",
    "h_heatmap(h_matrix,h_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass_count = []\n",
    "# for flight in SampleFlightList:\n",
    "#     try:\n",
    "#         pass_count.append(len(flight.flight_list_nyc)-2)\n",
    "#     except AttributeError:\n",
    "#         pass_count.append(0)\n",
    "# print(\"NYC Mean Flight passes: {:2.4f}\".format(np.mean(pass_count)))\n",
    "# pass_arr = np.array(pass_count)\n",
    "# print(\"Mean Non-Zero Flight passes: {:2.4f}\".format(np.mean(pass_arr[pass_arr>0])))\n",
    "\n",
    "\n",
    "# pass_count = []\n",
    "# for flight in SampleFlightList:\n",
    "#     try:\n",
    "#         pass_count.append(len(flight.flight_list_usgs)-2)\n",
    "#     except AttributeError:\n",
    "#         pass_count.append(0)\n",
    "\n",
    "# print(\"USGS Mean Flight passes: {:2.4f}\".format(np.mean(pass_count)))\n",
    "# pass_arr = np.array(pass_count)\n",
    "# print(\"Mean Non-Zero Flight passes: {:2.4f}\".format(np.mean(pass_arr[pass_arr>0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing points by scan angle\n",
    "\n",
    "Count the missing scan points based on scan angle between consecutive points.  Goal is to 1) compare the % of missing points for horizontal vs vertical surfaces, and 2) compare the % of missing points at different wall heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_face_list[0].to_pickle(\"../../Data/parking_lot/wall_points_laefer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pull_first_scan_gap(wall_face_laefer):\n",
    "    # Separate return num, only keep the first returns, add scan_gap, sort\n",
    "    wall_face_laefer['num_returns'] = np.floor(wall_face_laefer['flag_byte']/16).astype(int)\n",
    "    wall_face_laefer['return_num'] = wall_face_laefer['flag_byte']%16\n",
    "    first_return_wall = wall_face_laefer[wall_face_laefer['return_num']==1]\n",
    "    first_return_wall.sort_values(by=['gps_time'],inplace=True)\n",
    "    first_return_wall.reset_index(inplace=True)\n",
    "    first_return_wall.loc[1:,'scan_gap'] = [first_return_wall.loc[i+1,'scan_angle'] - first_return_wall.loc[i,'scan_angle'] for i in range(first_return_wall.shape[0]-1)]\n",
    "    first_return_wall.loc[0,'scan_gap'] = 0\n",
    "    return first_return_wall\n",
    "\n",
    "# Wall\n",
    "wall_face_laefer = wall_face_list[0]\n",
    "first_return_wall = pull_first_scan_gap(wall_face_laefer)\n",
    "# Rectangle\n",
    "rectangle_face_laefer = pd.read_pickle(file_dir+\"rectangle_points_laefer.pkl\")\n",
    "first_return_rectangle = pull_first_scan_gap(rectangle_face_laefer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan gap of -4,-5,-6 is normal, -10,-11,-15 are a missed point\n",
    "w = pd.DataFrame(first_return_rectangle['scan_gap'].value_counts())\n",
    "w.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan gap of -4,-5,-6 is normal, -10,-11,-15 are a missed point\n",
    "w = pd.DataFrame(first_return_wall[first_return_wall['flight_id']=='180819']['scan_gap'].value_counts())\n",
    "w.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the wall height into bins, compare % missing points at different heights\n",
    "\n",
    "first_return_wall['pts_bins'] = pd.cut((first_return_wall['z_scaled']-9)/3.28084, \\\n",
    "                                       bins=range(0,40,3),labels=range(3,40,3))\n",
    "\n",
    "first_return_wall['missed_point'] = np.zeros(first_return_wall.shape[0])\n",
    "first_return_wall['good_point'] = np.zeros(first_return_wall.shape[0])\n",
    "for index, row in first_return_wall.iterrows():\n",
    "    if (row['scan_gap'] >-17) & (row['scan_gap']< -6):\n",
    "        first_return_wall.loc[index,'missed_point']=1\n",
    "    if (row['scan_gap'] <-1) & (row['scan_gap'] > -7):\n",
    "        first_return_wall.loc[index,'good_point']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_return_wall[first_return_wall['z_scaled']<18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = first_return_wall[first_return_wall['flight_id']=='181004'].groupby('pts_bins').mean()\n",
    "a = first_return_wall.groupby('pts_bins').mean()\n",
    "\n",
    "a['miss_pct'] = a['missed_point']/a['good_point']\n",
    "a['miss_pct'][:-2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['miss_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(list(a['miss_pct'][:-2]),list(a['miss_pct'][:-2].index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intensity up and down the wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wall_face_laefer = wall_face_list[0]\n",
    "flight_ids = ['181004','180819']\n",
    "wall_face_laefer['pts_bins'] = pd.cut((wall_face_laefer['z_scaled']-9)/3.28084,bins=range(0,40,3),labels=range(3,40,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_face_laefer['intensity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_pts = wall_face_laefer[wall_face_laefer['flight_id']==flight_ids[1]]\n",
    "print(\"shape\",flight_pts.shape)\n",
    "flight_pts.groupby('pts_bins')['intensity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intensity on the parking lot horizontal surface\n",
    "rectangle_points_laefer = pd.read_pickle(file_dir+\"rectangle_points_laefer.pkl\")\n",
    "rectangle_points_laefer[rectangle_points_laefer['flight_id']=='181004']['intensity'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density up and down the wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wall_face_laefer = wall_face_list[0]\n",
    "plt.figure(figsize=[20,22])\n",
    "for i,fid in enumerate(wall_face_laefer['flight_id'].unique()):\n",
    "    plt.subplot(4,3,i+1)\n",
    "    pts = wall_face_laefer[wall_face_laefer['flight_id']==fid]\n",
    "    hist = pd.cut(wall_face_laefer[wall_face_laefer['flight_id']==fid]['z_scaled'],bins=range(0,120,5),labels=range(5,120,5))\n",
    "#     plt.hist(hist,orientation='horizontal')\n",
    "    plt.plot(range(pts.shape[0]),pts['z_scaled']/3.28084,'x')\n",
    "    plt.yticks(np.arange(0,36,3))\n",
    "    plt.ylabel(\"Wall height (m)\")\n",
    "    plt.xlabel(\"Point number (not spatial)\")\n",
    "    plt.title(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_ids = ['181004','180819','164445','180632']\n",
    "pts_fid = wall_face_laefer[wall_face_laefer['flight_id']==flight_ids[1]]['z_scaled'].copy()\n",
    "pts_fid = pts_fid/3.28084\n",
    "pts_bins = pd.cut(pts_fid,bins=range(15,36,3),labels=range(18,36,3))\n",
    "pts_density = pts_bins.value_counts()/(3*(6.899845795386761/3.28084))\n",
    "pts_density.sort_index(inplace=True)\n",
    "plt.plot(pts_density,range(18,36,3),'-o')\n",
    "plt.xlabel(\"Vertical Density (pts/m^2)\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.ylabel(\"Height on wall (m)\",fontsize=15)\n",
    "plt.yticks(fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_fid = wall_face_laefer['z_scaled'].copy()\n",
    "pts_fid = pts_fid/3.28084\n",
    "pts_bins = pd.cut(pts_fid,bins=[0,16,32],labels=('low','high'))\n",
    "pts_density = pts_bins.value_counts()/(1*(6.899845795386761/3.28084))\n",
    "pts_density.sort_index(inplace=True)\n",
    "plt.bar(['low','high'],pts_density)\n",
    "plt.xlabel(\"Vertical Density (pts/m^2)\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.ylabel(\"Height on wall (m)\",fontsize=15)\n",
    "plt.yticks(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_fid = wall_face_laefer['z_scaled'].copy()\n",
    "pts_fid = pts_fid/3.28084\n",
    "pts_bins = pd.cut(pts_fid,bins=range(9,36,3),labels=range(12,36,3))\n",
    "pts_density = pts_bins.value_counts()/(2*(14.899845795386761/3.28084))\n",
    "pts_density.sort_index(inplace=True)\n",
    "plt.plot(pts_density,range(12,36,3),'-o')\n",
    "plt.xlabel(\"Vertical Density (pts/m^2)\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.ylabel(\"Height on wall (m)\",fontsize=15)\n",
    "plt.yticks(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy up the wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_fid = [sf.z for sf in SampleFlightList]\n",
    "pts_fid = [pt/3.28084 for pt in pts_fid]\n",
    "pts_bins = pd.cut(pts_fid,bins=range(8,36,2),labels=range(10,36,2))\n",
    "\n",
    "# Create acc_df Dataframe of accuracy and height bins for a specific flight id\n",
    "# acc_df = pd.DataFrame([ss.flight_list_laefer[0].sd_dist for ss in SampleFlightList],columns=['total_rmse'])\n",
    "acc_df = pd.DataFrame(pts_bins,columns=['bin'])\n",
    "\n",
    "acc_df['z'] = pts_fid\n",
    "# plt.plot(acc_df[acc_df['bin']==30]['z'])\n",
    "\n",
    "# Flight id specific accuracy\n",
    "fid = '181004' # Farther away \n",
    "# fid = '180819' # About 100m away\n",
    "acc_list = []\n",
    "for j in SampleFlightList:\n",
    "    dd = {j.flight_list_laefer[i].flight_id:i for i in range(len(j.flight_list_laefer))}\n",
    "    ix = dd[fid]\n",
    "    acc_list.append(j.flight_list_laefer[ix].sd_dist/3.28084)\n",
    "len(acc_list)\n",
    "\n",
    "acc_df['fid_rmse'] = acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(np.arange(12-3,33-3,2),acc_df.groupby('bin')['fid_rmse'].mean().iloc[1:-1])\n",
    "plt.ylabel(\"Wall Height (m)\")\n",
    "plt.xlabel(\"Single Flight RMSE (m)\")\n",
    "plt.title(\"Flight ID: \"+str(fid))\n",
    "print(acc_df['bin'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(np.arange(12-3,33-3,2),acc_df.groupby('bin')['fid_rmse'].mean().iloc[1:-1])\n",
    "plt.ylabel(\"Wall Height (m)\")\n",
    "plt.xlabel(\"Single Flight RMSE (m)\")\n",
    "plt.title(\"Flight ID: \"+str(fid))\n",
    "print(acc_df['bin'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What causes C and W?\n",
    "What's the distribution of h's that generate C for vertical surfaces?  Outlier, or consistent misalignment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(\"{}:\\t{:2.4f}\\t{:2} points\\t{:2.4f}\".format(flight_ids[i],h_list[i]**2*num_pt_list[i],num_pt_list[i],h_list[i])) for i in range(len(h_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = {\n",
    " '164239':'n-s  ',\n",
    " '164445':'n-s  ',\n",
    " '164640':'n-s  ',\n",
    " '172753':'e-w  ',\n",
    " '172928':'e-w  ',\n",
    " '173110':'e-w  ',\n",
    " '180632':'sw-ne',\n",
    " '180819':'sw-ne',\n",
    " '181004':'sw-ne',\n",
    " '200212':'se-nw',\n",
    " '200600':'se-nw',\n",
    " '200742':'se-nw',\n",
    " '200938':'se-nw' \n",
    "}\n",
    "dir_list = ['n-s  ','e-w  ','sw-ne','se-nw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square_points_list, SampleFlightList, wall_face_list, pt_density_list, sd_wall_list\n",
    "h_dict = {\n",
    " '164239':[],\n",
    " '164445':[],\n",
    " '164640':[],\n",
    " '172753':[],\n",
    " '172928':[],\n",
    " '173110':[],\n",
    " '180632':[],\n",
    " '180819':[],\n",
    " '181004':[],\n",
    " '200212':[],\n",
    " '200600':[],\n",
    " '200742':[],\n",
    " '200938':[] \n",
    "}\n",
    "# Collect h for each flight pass in each sample square\n",
    "for sample_num in range(2500):\n",
    "    h_list = [fp.h for fp in SampleFlightList[sample_num].flight_list_laefer[2:]]\n",
    "#     num_pt_list = [fp.num_points for fp in SampleFlightList[sample_num].flight_list_laefer[2:]]\n",
    "    flight_ids = [fp.flight_id for fp in SampleFlightList[sample_num].flight_list_laefer[2:]]\n",
    "#     total_pts = SampleFlightList[sample_num].flight_list_laefer[0].num_points\n",
    "    for a in h_dict.keys():\n",
    "        if a in flight_ids:\n",
    "            ix = flight_ids.index(a)\n",
    "            h_dict[a].append(h_list[ix])\n",
    "        else:\n",
    "            h_dict[a].append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean height for each flight pass\n",
    "print(\"F_Id\\t Mean abs height\\n\",\"*\"*23)\n",
    "[print(\"{}: {:6.3f}\".format(k,np.nanmean([abs(h) for h in h_dict[k]]))) for k in h_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "h_dir_dict = defaultdict(list)\n",
    "for ss in range(len(h_dict['164239'])):\n",
    "    for di in dir_list:\n",
    "        direction_h_sum = 0\n",
    "        direction_count = 0\n",
    "\n",
    "        for fp in h_dict.keys():\n",
    "            if direction[fp] == di:\n",
    "                direction_h_sum += h_dict[fp][ss]\n",
    "                direction_count +=1    \n",
    "        h_dir_dict[di].append(direction_h_sum/direction_count)\n",
    "dir_list = ['n-s  ','e-w  ','sw-ne','se-nw']\n",
    "# Mean height for each direction\n",
    "print(\"Direct\\tMean abs height\\n\",\"*\"*22)\n",
    "[print(\"{}: {:6.3f}\".format(k,np.nanmean([abs(h) for h in h_dir_dict[k]]))) for k in h_dir_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix of mean height differences across flight passes (would expect larger diffs for different directions)\n",
    "def create_h_matrix(h_dict):\n",
    "    h_matrix = np.zeros([len(h_dict),len(h_dict)])\n",
    "    for i,key1 in enumerate(h_dict.keys()):\n",
    "        for j,key2 in enumerate(h_dict.keys()):\n",
    "            h_matrix[i,j] = np.nanmean(abs(np.array(h_dict[key1]) - np.array(h_dict[key2])))\n",
    "    return h_matrix\n",
    "\n",
    "def h_heatmap(h_matrix,h_dict,fontsize=15,label='Flight ID'):\n",
    "    # Heatmap of the matrix\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.imshow(h_matrix, cmap='YlOrRd')\n",
    "    plt.xticks(np.arange(0,h_matrix.shape[0]),h_dict.keys(),rotation=90,fontsize=fontsize)\n",
    "    plt.yticks(np.arange(0,h_matrix.shape[0]),h_dict.keys(),fontsize=fontsize)\n",
    "    plt.ylabel(label,fontsize=fontsize)\n",
    "    plt.xlabel(label,fontsize=fontsize)\n",
    "    plt.ylim(h_matrix.shape[0]-0.5,-0.5)\n",
    "    plt.title(\"Mean Absolute h difference\",fontsize=fontsize)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "h_matrix = create_h_matrix(h_dict)\n",
    "h_heatmap(h_matrix,h_dict)  \n",
    "# h_matrix = create_h_matrix(h_dir_dict)\n",
    "# h_heatmap(h_matrix,h_dir_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_matrix = create_h_matrix(h_dir_dict)\n",
    "h_heatmap(h_matrix,h_dir_dict,label=\"Flight Direction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the wall face, find normal vector, calculate vertical density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_1 = np.array([37.7,10.04])\n",
    "pt_2 = np.array([27.094,18.439])\n",
    "wall_pt = (31.77,14.90,43.00)\n",
    "\n",
    "# East? Facing Wall (farther from the little stump)\n",
    "# pt_1 = np.array([20.59,15.02])\n",
    "# pt_2 = np.array([10.34,2.93])\n",
    "# wall_pt = (19.414,12.379,73.863)\n",
    "\n",
    "wall_face = grab_wall_face(square_points_bldg,pt_1,pt_2,20,100,1e-2)\n",
    "wall_face_nyc = grab_wall_face(square_points_nyc,pt_1,pt_2,20,100,5e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wall_face.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_face_nyc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vector,points,wall_face,pts_on_plane = plane_fit(wall_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_vector)\n",
    "print(norm_vector_nyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vector_nyc,points,wall_face_nyc,pts_on_plane_nyc = plane_fit(wall_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(wall_face, x='x_plot', y='y_plot', z='z_plot',\n",
    "              color='flight_id',size='size_num',size_max = 12)\n",
    "\n",
    "fig.update_layout( \n",
    "    scene = dict(xaxis = dict(title=\"Easting (feet)\"),\n",
    "                 yaxis = dict(title=\"Northing (feet)\"),\n",
    "                 zaxis = dict(title=\"Vertical (feet)\"),\n",
    "                ),\n",
    "    width=900,\n",
    "    height=900,\n",
    "    margin=dict(r=20, l=10, b=10, t=10),\n",
    "    showlegend=False,\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point in middle of wall - in xyz_plot coordinates (less the min of each coordinate)\n",
    "# It's best to highlight a point in the plot above and use that.\n",
    "\n",
    "feet_from_pt = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate density for both datasets   \n",
    "vertical_point_density(square_points_nyc,norm_vector_nyc,wall_pt,feet_from_pt)\n",
    "vertical_point_density(square_points_bldg,norm_vector,wall_pt,feet_from_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(vertical_square, x='x_plot', y='y_plot', z='z_plot',\n",
    "              color='flight_id', size='size_num',size_max = 8)\n",
    "\n",
    "fig.update_layout( \n",
    "    scene = dict(xaxis = dict(title=\"Easting (feet)\"),\n",
    "                 yaxis = dict(title=\"Northing (feet)\"),\n",
    "                 zaxis = dict(title=\"Vertical (feet)\"),\n",
    "                ),\n",
    "    width=900,\n",
    "    height=900,\n",
    "    margin=dict(r=20, l=10, b=10, t=10),\n",
    "    showlegend=False,\n",
    "    xaxis = {\"title\":{\"text\":\"Cat\"}})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing LAS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write square_points_bldg to file\n",
    "inFile = File(file_dir+'10552_NYU_M2 - Scanner 1 - 190511_164039_1 - originalpoints.laz', mode='r')\n",
    "# Convert DF into tuples that laspy wants\n",
    "void = [(tuple(r[columns_point_cloud]),) for i,r in square_points_laefer.iterrows()]\n",
    "# Export\n",
    "outFile1 = File(\"../../Data/parking_lot/flat_parking_lot_laefer.las\", mode = \"w\",header = inFile.header)\n",
    "outFile1.points = void\n",
    "outFile1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYC data\n",
    "# Write square_points_bldg to file\n",
    "inFile_nyc = File(nyc_file_dir+'975172.las', mode='r')\n",
    "# Convert DF into tuples that laspy wants\n",
    "void = [(tuple(r[columns_point_cloud]),) for i,r in square_points_nyc.iterrows()]\n",
    "# Export\n",
    "outFile1 = File(\"../../Data/parking_lot/flat_parking_lot_nyc.las\", mode = \"w\",header = inFile.header)\n",
    "outFile1.points = void\n",
    "outFile1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting charts from previous updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vector,points,square_points,_ = plane_fit(square_points)\n",
    "\n",
    "# Add distance from flat plane with norm (x,y,z) = (0,0,1)\n",
    "square_points['dist_from_flat']=np.array([np.dot(point,np.array([0,0,1])) for point in points])\n",
    "\n",
    "# remove data points >5 feet below plane.\n",
    "outliers = square_points[square_points['dist_from_plane']<-5].index\n",
    "square_points = square_points.drop(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scan_angle_dist_from_plane(df,distance_metric):\n",
    "    x = abs(df['scan_angle'])*.006\n",
    "    y = df[distance_metric]\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.plot(x,y,'xb')\n",
    "    z = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(x,p(x),\"r--\")\n",
    "    plt.xlabel(\"Scan angle (degrees)\")\n",
    "    plt.ylabel(\"Point distance from plane\")\n",
    "    print(\"y={:2.8f}x+{:2.8f}\".format(z[0],z[1]))\n",
    "    plt.title(\"Scan Angle vs Distance to Fitted Plane\")\n",
    "plot_scan_angle_dist_from_plane(square_points,'dist_from_plane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(square_points)),square_points['scan_angle'],'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scan_angle_dist_from_plane(square_points,'dist_from_flat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart from slides showing points per run\n",
    "labels = [pt[0][11:-4] for pt in pts_from_scan]\n",
    "num_points = [pt[1]+.01 for pt in pts_from_scan]\n",
    "plt.figure(figsize=(25,20))\n",
    "plt.bar(labels,num_points,)\n",
    "plt.xticks(rotation=45,fontsize=20)\n",
    "plt.yticks(np.arange(0, max(num_points), step=(max(num_points)/10)),fontsize=20)\n",
    "plt.ylabel(\"Number of points from run\",fontsize=20)\n",
    "plt.xlabel(\"Run ID\",fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USGS: Converting Lat-Lon and adding flight id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting lat-lon to state plane\n",
    "from pyproj import Proj, transform\n",
    "y1 = np.array(usgs_square_points['x_scaled'])\n",
    "x1 = np.array(usgs_square_points['y_scaled'])\n",
    "inProj = Proj('epsg:4269')\n",
    "outProj = Proj('epsg:3628')\n",
    "x2,y2 = transform(inProj,outProj,x1,y1)\n",
    "usgs_square_points['latitude'] = usgs_square_points['y_scaled'].copy()\n",
    "usgs_square_points['longitude'] = usgs_square_points['x_scaled'].copy()\n",
    "usgs_square_points['x_scaled'] = x2\n",
    "usgs_square_points['y_scaled'] = y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_hdf(\"../../Data/parking_lot/las_points_180819.lz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['intensity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1:,'scan_gap'] = [df.loc[i+1,'scan_angle'] - df.loc[i,'scan_angle'] for i in range(df.shape[0]-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:1000000,'return_num'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df['num_returns'] = np.floor(df['flag_byte']/16).astype(int)\n",
    "df['return_num'] = df['flag_byte']%16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
