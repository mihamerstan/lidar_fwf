{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from laspy.file import File\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "%matplotlib notebook\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points, full waveform:  9365485\n"
     ]
    }
   ],
   "source": [
    "# Load the data using laspy\n",
    "inFile = File('../../Data/170204/10552_NYU_M2 - Scanner 1 - 190511_170204_1 - originalpoints.laz', mode='r')\n",
    "\n",
    "# raw is a 1-D numpy array, each entry is a point\n",
    "raw = inFile.get_points()\n",
    "\n",
    "print(\"Number of points, full waveform: \",len(raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponds to LAS 1.4 Point Data Record Format 9\n",
    "# X coordinate of the point (must be adjusted by offset and scale factor)\n",
    "columns_fwf =[ \n",
    "    'X', \n",
    "    'Y',\n",
    "    'Z',\n",
    "    'intensity', #Intensity of the return, scaled to a 0-65,535 scale\n",
    "    'flag_byte', #Return number, # of returns, Scan direction flag (+ or -), Edge of flight line flag\n",
    "    'classification_flags', #Only if the point has been classified: vegetation, etc.\n",
    "    'classification_byte', #Various flags about the point\n",
    "    'user_data', \n",
    "    'scan_angle', # Down is 0.0, each unit is 0.006 degrees, \n",
    "    #so value between -30,000 and 30,000, or (180deg/0.006deg)\n",
    "    #Spec says this incorporates the roll of the aircraft\n",
    "    'pt_src_id', #Unique ID for the source of the point\n",
    "    'gps_time', #GPS Week Time (seconds, reset each week) or Adj Std GPS Time\n",
    "    'wave_packet_desc_index', # Indicates which waveform packet descriptor is applied.\n",
    "    'byte_offset_to_waveform_data', # Locates the WF data in EVLR or .wdp file.\n",
    "    'wavefm_pkt_size', # Size of the waveform packet\n",
    "    'return_point_waveform_loc', # Time in picoseconds \n",
    "    'x_t', # Form parametric location: X = X_0 + x_t*t\n",
    "    'y_t', # (X_0,Y_0,Z_0) is the anchor point associated with the waveform\n",
    "    'z_t' ]\n",
    "\n",
    "# Corresponds to LAS 1.4 Point Data Record Format 6\n",
    "columns_point_cloud = [\n",
    "    'X',\n",
    "    'Y',\n",
    "    'Z',\n",
    "    'intensity',\n",
    "    'flag_byte',\n",
    "    'classification_flags',\n",
    "    'classification_byte',\n",
    "    'user_data',\n",
    "    'scan_angle',\n",
    "    'pt_src_id',\n",
    "    'gps_time']\n",
    "\n",
    "# Corresponds to LAS 1.2 Point Data Record Format 1\n",
    "columns_dublin_pt_cloud = [\n",
    "    'X',\n",
    "    'Y',\n",
    "    'Z',\n",
    "    'intensity',\n",
    "    'return_number_byte',\n",
    "    'classification_byte',\n",
    "    'scan_angle',\n",
    "    'user_data',\n",
    "    'pt_src_id',\n",
    "    'gps_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_to_df(raw,column_names):\n",
    "    '''function takes raw output of laspy.File.get_points() and column names, and returns a pandas Dataframe'''\n",
    "    raw_list = [a[0].tolist() for a in raw]\n",
    "    df = pd.DataFrame(raw_list,columns = column_names)\n",
    "    return df\n",
    "\n",
    "def scale_and_offset(df,header,append_to_df=False):\n",
    "    '''Function takes as input the dataframe output of raw_to_df and the laspy header file.\n",
    "       Output is a nx3 dataframe with adjusted X,Y, and Z coordinates, from the formula: \n",
    "       X_adj = X*X_scale + X_offset.\n",
    "       Brooklyn LiDAR readings appear to be in feet, and use NAVD 88 in the vertical and \n",
    "       New York Long Island State Plane Coordinate System NAD 33 in the horizontal.'''\n",
    "    offset = header.offset\n",
    "    scale = header.scale\n",
    "    scaled_xyz = df[['X','Y','Z']]*scale + offset\n",
    "    if append_to_df:\n",
    "        df['x_scaled'] = scaled_xyz['X']\n",
    "        df['y_scaled'] = scaled_xyz['Y']\n",
    "        df['z_scaled'] = scaled_xyz['Z'] \n",
    "        return df\n",
    "    else:\n",
    "        return scaled_xyz\n",
    "\n",
    "#INACTIVE FUNCTIONS\n",
    "def split_and_strip(raw):\n",
    "    '''Function takes the output ndarray of laspy File.get_points(), \n",
    "        splits each point on commas, \n",
    "        outputs a list of lists.'''\n",
    "    output_list = []\n",
    "    for row in raw:\n",
    "        stripped = [a.strip(\"( , )\") for a in str(row).split(',')]\n",
    "        output_list.append(stripped)\n",
    "    return output_list\n",
    "\n",
    "def row_clean(string_list):\n",
    "    '''Function takes as input a list of lists, the output of split_and_strip().  Cleans the entries for spaces,\n",
    "    returns a numpy array where each row is a point.'''\n",
    "    output_list = []\n",
    "    for row in string_list:        \n",
    "        output_list.append(list(map(float,row[:-1])))\n",
    "    output_arr = np.array(output_list)\n",
    "    return output_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes for point cloud and fwf\n",
    "df = raw_to_df(raw,columns_point_cloud)\n",
    "\n",
    "# Generate adjusted coordinates for point cloud.  FWF is identical.\n",
    "las_points = scale_and_offset(df,inFile.header,append_to_df=True)\n",
    "las_points.to_pickle(\"../../Data/pickles/las_points_170204.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#las_points = pd.read_pickle(\"../../Data/parking_lot//las_points_164239.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flat surface\n",
    "Identifying points in a parking lot to assess how consistently flat they are.  \n",
    "Center point: 40.645872, -74.025991  \n",
    "Easting - 977037.343  \n",
    "Northing - 174586.034     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract points within a square around the desired point\n",
    "pt_x = 977037.343\n",
    "pt_y = 174586.034\n",
    "feet_from_point = 4\n",
    "\n",
    "square_points = las_points[ (las_points['x_scaled'] < pt_x + feet_from_point)\n",
    "           &(las_points['x_scaled'] > pt_x - feet_from_point) \n",
    "           &(las_points['y_scaled'] < pt_y + feet_from_point)\n",
    "           &(las_points['y_scaled'] > pt_y - feet_from_point)\n",
    "          ]\n",
    "print(\"Point count in square: {:d}\".format(square_points.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "square_points[['x_scaled','y_scaled','z_scaled']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(x=square_points['x_scaled'], \n",
    "                                   y=square_points['y_scaled'], \n",
    "                                   z=square_points['z_scaled'],\n",
    "                                   mode='markers',\n",
    "                                  marker=dict(size=4,\n",
    "                                              color=2))])\n",
    "\n",
    "fig.update_layout(\n",
    "    scene = dict(\n",
    "        xaxis = dict(nticks=4, range=[977030,977045],),\n",
    "                     yaxis = dict(nticks=4, range=[174581,174591],),\n",
    "                     zaxis = dict(nticks=4, range=[7,8],),),\n",
    "    width=700,\n",
    "    margin=dict(r=20, l=10, b=10, t=10))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearby Points\n",
    "Looking at points around the end of the scan angle (nearby_df), as well points near the middle of the scan angle, directly down (down_df).  There seems to be some noise in the points at the end of the scan angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A handful of points at the end of the scan angle of file las_points_164239.pkl\n",
    "nearby_points = list(range(32645,32653))+list(range(33760,33767))+list(range(34870,34877))\n",
    "nearby_df = las_points.iloc[nearby_points]\n",
    "# Time range\n",
    "print(\"Time range: \",nearby_df['gps_time'].max() - nearby_df['gps_time'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for points between -1 and 1 degrees scan angle\n",
    "down_df = las_points[(las_points['scan_angle']<60)&(las_points['scan_angle']>-60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helicopter scan lines\n",
    "plt.plot(down_df['gps_time'][10000:10100],down_df['y_scaled'][10000:10100],'xb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nearby_df[['x_scaled','y_scaled','z_scaled']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking for specific Lat/Lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lat_lon_to_dec(degrees,minutes,seconds):\n",
    "    return degrees + (minutes/60) + (seconds/3600)\n",
    "lat = convert_lat_lon_to_dec(40,38,38.8)\n",
    "lon = convert_lat_lon_to_dec(74,1,33.0)*-1\n",
    "print(\"Latitude: {:2.4f}\".format(lat))\n",
    "print(\"Longitude: {:2.4f}\".format(lon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling the Brooklyn data\n",
    "Looking at maximum coordiates, points per scan, scans per run, distance between points, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find max North, South, East, West points\n",
    "Max North: 164039\n",
    "Max South: 163206\n",
    "Max East: 172201\n",
    "Max West: 194702"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_cardinal_direction(filename,direction):\n",
    "    '''Fucntion determines the maximum coordinate in the file in the given direction.'''\n",
    "    # Load the file\n",
    "    inFile = File(filename, mode='r')\n",
    "    if direction == \"North\":\n",
    "        return inFile.header.max[1]\n",
    "    elif direction == \"South\":\n",
    "        return inFile.header.min[1]\n",
    "    elif direction == \"East\":\n",
    "        return inFile.header.max[0]\n",
    "    elif direction == \"West\":\n",
    "        return inFile.header.min[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_north_file = '10552_NYU_M2 - Scanner 1 - 190511_164039_1 - originalpoints.laz'\n",
    "max_south_file = '10552_NYU_M2 - Scanner 1 - 190511_163206_1 - originalpoints.laz'\n",
    "max_east_file = '10552_NYU_M2 - Scanner 1 - 190511_172201_1 - originalpoints.laz'\n",
    "max_west_file = '10552_NYU_M3 - Scanner 1 - 190511_194702_1 - originalpoints.laz'\n",
    "\n",
    "maxes=[]\n",
    "\n",
    "# for card in zip([max_north_file,max_south_file,max_east_file,max_west_file],['North','South','East','West']):\n",
    "#     maxes.append(max_cardinal_direction('../../Data/max_coordinate_point_clouds/'+card[0],card[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inFile = File('../../Data/max_coordinate_point_clouds/10552_NYU_M2 - Scanner 1 - 190511_164039_1 - originalpoints.laz', mode='r')\n",
    "# raw = inFile.get_points()\n",
    "# df = raw_to_df(raw,columns_point_cloud)\n",
    "# las_points = scale_and_offset(df,inFile.header,append_to_df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point density in time and space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_per_scan(scan_angle):\n",
    "    '''takes scan_angle as Series, counts the number of \"jumps\" in the scan angle, indicating start of a new scan\n",
    "    then divides the number of points in scan_angle to return points / scan'''\n",
    "    delta_angle = [scan_angle.iloc[i+1]-scan_angle.iloc[i] for i in range(len(scan_angle)-1)]\n",
    "    print(\"Done\")\n",
    "    scan_count = sum(abs(np.array(delta_angle)) > scan_angle.max())\n",
    "    print(\"Number of scans: {}\".format(scan_count))\n",
    "    print(\"Points per scan: {:2.2f}\".format(len(scan_angle)/scan_count))\n",
    "    return len(scan_angle)/scan_count, scan_count\n",
    "\n",
    "def scans_per_second(gps_time_series,scan_count):\n",
    "    run_time = gps_time_series.max() - gps_time_series.min()\n",
    "    print(\"Scans per second: {:2.2f}\".format(scan_count/run_time))\n",
    "    print(\"Points per second: {:2.2f}\".format(len(gps_time_series)/run_time))\n",
    "    return scan_count/run_time\n",
    "\n",
    "def small_angle_no_jumps(df,max_angle=330):\n",
    "    '''This function extracts only the points with scan angle below max_angle.  \n",
    "        scan_angle is scaled to .006 degrees per unit.'''\n",
    "    \n",
    "    small_angle = df[abs(df['scan_angle'])<max_angle]\n",
    "    return small_angle\n",
    "\n",
    "def mean_euclidean_distance(df):\n",
    "    '''Calculate the mean distance between consecutive points in a dataframe, skipping the jumps between scans.'''\n",
    "    df['x_dist_to_next'] = np.zeros(len(df))\n",
    "    df['y_dist_to_next'] = np.zeros(len(df))\n",
    "    df['x_dist_to_next'][1:] = np.array([df['x_scaled'].iloc[i] - df['x_scaled'].iloc[i-1] for i in range(1,len(df))])\n",
    "    df['y_dist_to_next'][1:] = np.array([df['y_scaled'].iloc[i] - df['y_scaled'].iloc[i-1] for i in range(1,len(df))])\n",
    "    \n",
    "    # Remove jumps in scan angle\n",
    "    no_jump = df[abs(df['angle_change'])<20]\n",
    "    \n",
    "    eucl_dist_to_next = np.sqrt(no_jump['x_dist_to_next']**2+no_jump['y_dist_to_next']**2)\n",
    "    print(\"Avg Euclidean distance between points: {:2.2f}\".format(eucl_dist_to_next.mean()))\n",
    "    return eucl_dist_to_next.mean()\n",
    "\n",
    "def distance_between_points(df,small_angle_max = 330):\n",
    "    '''Wrapper for mean_euclidean_distance that also looks at points restricted to small angles near \n",
    "        directly 0, or the downward direction.'''\n",
    "    #Add angle_change to identify jumps to new scans.\n",
    "    df['angle_change'] = np.zeros(len(df))\n",
    "    df['angle_change'].iloc[1:] = [df['scan_angle'].iloc[i]-df['scan_angle'].iloc[i-1] for i in range(1,len(df))]\n",
    "    mean_distance_overall = mean_euclidean_distance(df)\n",
    "    # Small scan_angle\n",
    "    small_angle_df = small_angle_no_jumps(df,max_angle = small_angle_max)\n",
    "    mean_distance_small_angle = mean_euclidean_distance(small_angle_df)\n",
    "    \n",
    "def create_use_range(filename,column_names = columns_fwf):\n",
    "    '''Function takes .laz filename, returns a 2 million point datafame from the .laz file \n",
    "    Also adds scaled xyz coordinates.'''\n",
    "    \n",
    "    inFile = File('../../Data/dublin_sample/'+filename, mode='r')\n",
    "    print(\"inFile Done\")\n",
    "    raw = inFile.get_points()\n",
    "    print(\"get_points done\")\n",
    "    df = raw_to_df(raw[2000000:3000000],column_names)\n",
    "    print(\"df done\")\n",
    "    del(raw)\n",
    "    las_points = scale_and_offset(df,inFile.header,append_to_df=True)\n",
    "    print(\"las_points created\")\n",
    "    print(\"Timespan: {:2.2} seconds\".format(las_points['gps_time'].max()-las_points['gps_time'].min()))\n",
    "    use_range = las_points\n",
    "    return use_range\n",
    "\n",
    "def process_use_range(use_range,filename=\"dublin\",small_angle_max = 330):\n",
    "    '''Runs the profiling on the provided use_range.'''\n",
    "    \n",
    "    print(\"\\n\",filename,\"\\n---------------------------------\")\n",
    "    pts_per_scan, scan_count = points_per_scan(use_range['scan_angle'])\n",
    "    scans_per_second(use_range['gps_time'],scan_count)    \n",
    "    distance_between_points(use_range,small_angle_max = small_angle_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profiling for 4 Brooklyn datasets\n",
    "\n",
    "max_north_file = '10552_NYU_M2 - Scanner 1 - 190511_164039_1 - originalpoints.laz'\n",
    "max_south_file = '10552_NYU_M2 - Scanner 1 - 190511_163206_1 - originalpoints.laz'\n",
    "max_east_file = '10552_NYU_M2 - Scanner 1 - 190511_172201_1 - originalpoints.laz'\n",
    "max_west_file = '10552_NYU_M3 - Scanner 1 - 190511_194702_1 - originalpoints.laz'\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "for filename in [max_north_file,max_south_file,max_east_file,max_west_file]:\n",
    "    inFile = File('../../Data/max_coordinate_point_clouds/'+filename, mode='r')\n",
    "    raw = inFile.get_points()\n",
    "    df = raw_to_df(raw,columns_point_cloud)\n",
    "    las_points = scale_and_offset(df,inFile.header,append_to_df=True)\n",
    "    use_range = las_points[2000000:6000000]\n",
    "    print(\"\\n\",filename,\"\\n---------------------------------\")\n",
    "    print(\"Timespan: {:2.2} seconds\".format(las_points['gps_time'].max()-las_points['gps_time'].min()))\n",
    "    pts_per_scan, scan_count = points_per_scan(use_range['scan_angle'])\n",
    "    scans_per_second(use_range['gps_time'],scan_count)\n",
    "    \n",
    "    distance_between_points(use_range)\n",
    "    \n",
    "pd.reset_option('mode.chained_assignment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Brooklyn profiling output\n",
    " 10552_NYU_M2 - Scanner 1 - 190511_164039_1 - originalpoints.laz \n",
    "---------------------------------\n",
    "Done\n",
    "Number of scans: 1553\n",
    "Points per scan: 2575.66\n",
    "Scans per second: 133.26\n",
    "Points per second: 343224.78\n",
    "Avg Euclidean distance between points: 2.52\n",
    "Avg Euclidean distance between points: 0.92\n",
    "\n",
    " 10552_NYU_M2 - Scanner 1 - 190511_163206_1 - originalpoints.laz \n",
    "---------------------------------\n",
    "Done\n",
    "Number of scans: 1974\n",
    "Points per scan: 2026.34\n",
    "Scans per second: 133.31\n",
    "Points per second: 270123.17\n",
    "Avg Euclidean distance between points: 0.90\n",
    "Avg Euclidean distance between points: 1.05\n",
    "\n",
    " 10552_NYU_M2 - Scanner 1 - 190511_172201_1 - originalpoints.laz \n",
    "---------------------------------\n",
    "Done\n",
    "Number of scans: 2276\n",
    "Points per scan: 1757.47\n",
    "Scans per second: 133.29\n",
    "Points per second: 234249.32\n",
    "Avg Euclidean distance between points: 0.97\n",
    "Avg Euclidean distance between points: 1.19\n",
    "\n",
    " 10552_NYU_M3 - Scanner 1 - 190511_194702_1 - originalpoints.laz \n",
    "---------------------------------\n",
    "Done\n",
    "Number of scans: 1593\n",
    "Points per scan: 2510.99\n",
    "Scans per second: 133.25\n",
    "Points per second: 334601.09\n",
    "Avg Euclidean distance between points: 2.71\n",
    "Avg Euclidean distance between points: 0.88\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profiling for 4 Dublin datasets\n",
    "# Note This did not really work...the Dublin files have weird scan angle patterns.\n",
    "\n",
    "dublin_files = [\n",
    "    'F_150326_120854.laz',\n",
    "    'F_150326_122941.laz',\n",
    "    'F_150326_145523.laz',\n",
    "    'F_150326_150906.laz'\n",
    "]\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "for filename in dublin_files:\n",
    "    use_range = create_use_range(filename,columns_dublin_pt_cloud)\n",
    "    process_use_range(use_range,filename,small_angle_max = 2)\n",
    "    \n",
    "pd.reset_option('mode.chained_assignment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find points at similar scan angles across all scans.\n",
    "consecutive = use_range[(use_range['scan_angle']<206)&(use_range['scan_angle']>200)]\n",
    "\n",
    "def euclidean_dist_consecutive_scans(consecutive):\n",
    "    '''Function takes a dataframe of points within a very tight scan_angle, but across many scans.\n",
    "        Function determines points on consecutive scans, then calculates the x-y distance between \n",
    "        those points on consecutive scans and prints out the average across the full dataframe.'''\n",
    "    euc_dist_list = []\n",
    "    for i in range(1,len(consecutive)):\n",
    "        record_dist = consecutive.iloc[i].name - consecutive.iloc[i-1].name\n",
    "        if (record_dist>1000) & (record_dist < 3000):\n",
    "            euc_dist = np.sqrt((consecutive['x_scaled'].iloc[i]-consecutive['x_scaled'].iloc[i-1])**2+\n",
    "                           (consecutive['y_scaled'].iloc[i]-consecutive['y_scaled'].iloc[i-1])**2)\n",
    "            euc_dist_list.append(euc_dist)\n",
    "    print(\"Mean euclidean distance between consecutive scans: {2.2f}\".format(np.mean(euc_dist_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
